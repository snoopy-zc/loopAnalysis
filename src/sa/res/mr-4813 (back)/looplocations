//#functions containing loops In Scope     #loops totally
2146 2920
org.apache.hadoop.fs.s3.S3FileSystem.renameRecursive(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;)Z 1 274 
org.apache.hadoop.metrics.spi.CompositeContext.flush()V 1 102 
org.apache.hadoop.util.LineReader.readDefaultLine(Lorg/apache/hadoop/io/Text;II)I 2 213 204 
org.apache.hadoop.io.WritableComparator.hashBytes([BII)I 1 164 
org.apache.hadoop.metrics2.impl.SinkQueue.dequeue()Ljava/lang/Object; 1 104 
org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations$BlockWithLocations.readFields(Ljava/io/DataInput;)V 1 75 
org.apache.hadoop.mapreduce.v2.app.webapp.SingleCounterBlock.populateMembers(Lorg/apache/hadoop/mapreduce/v2/app/AppContext;)V 2 126 144 
org.apache.hadoop.record.compiler.JRecord$CppRecord.<init>(Lorg/apache/hadoop/record/compiler/JRecord;Ljava/lang/String;Ljava/util/ArrayList;)V 1 489 
org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.nonOccursString(Ljava/lang/String;)Ljava/lang/String; 1 237 
org.apache.hadoop.yarn.webapp.view.JQueryUI.initThemeSwitcher(Ljava/util/List;)V 1 193 
org.apache.hadoop.mapred.JobClient.getQueueAclsForCurrentUser()[Lorg/apache/hadoop/mapred/QueueAclsInfo; 1 1185 
org.apache.hadoop.fs.HarFileSystem$HarStatus.<init>(Lorg/apache/hadoop/fs/HarFileSystem;Ljava/lang/String;)V 1 550 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.addBlock(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/protocol/Block;Ljava/lang/String;)V 4 2187 2190 2193 2199 
org.apache.hadoop.hdfs.server.namenode.NNStorage.getFsImageName(J)Ljava/io/File; 1 494 
org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit.getLocations()[Ljava/lang/String; 2 102 99 
org.apache.hadoop.mapred.JobClient.jobsToComplete()[Lorg/apache/hadoop/mapred/JobStatus; 1 837 
org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.checkAppNumCompletedLimit()V 1 218 
org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$DelegationTokenCancelThread.run()V 1 149 
org.apache.hadoop.mapred.ReduceTask$SkippingReduceValuesIterator.mayBeSkip()V 2 274 273 
org.apache.hadoop.mapred.IndexCache.readIndexFileToCache(Lorg/apache/hadoop/fs/Path;Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/mapred/IndexCache$IndexInformation; 1 105 
org.apache.hadoop.mapred.JobEndNotifier$1.run()V 1 53 
org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor.logOutput(Ljava/lang/String;)V 1 166 
org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorReducer.reduce(Lorg/apache/hadoop/io/Text;Ljava/lang/Iterable;Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 1 65 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.getVolumeMap(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/datanode/ReplicasMap;)V 1 858 
org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$DelegationTokenCancelThread.cancelToken(Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/conf/Configuration;)V 1 134 
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getAdditionalDatanode(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;ILjava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/LocatedBlock; 1 416 
org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.appendPrefix(Lorg/apache/hadoop/metrics2/MetricsRecord;Ljava/lang/StringBuilder;)V 1 94 
org.apache.hadoop.yarn.webapp.view.JQueryUI.initProgressBars(Ljava/util/List;)V 1 184 
org.apache.hadoop.hdfs.server.namenode.BackupImage.tryConvergeJournalSpool()Z 1 252 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.getFinishTime()J 1 458 
org.apache.hadoop.mapreduce.task.reduce.Fetcher.connect(Ljava/net/URLConnection;I)V 1 482 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stopSources()V 1 406 
org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 672 
org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.getOutputBytes(Ljava/util/List;)J 1 619 
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalizerStatusPBImpl.initResources()V 1 111 
org.apache.hadoop.mapred.join.JoinRecordReader.next(Lorg/apache/hadoop/io/WritableComparable;Lorg/apache/hadoop/mapred/join/TupleWritable;)Z 1 59 
org.apache.hadoop.fs.FileContext$Util.copy(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;ZZ)Z 1 2140 
org.apache.hadoop.hdfs.server.datanode.DataNode$BlockPoolManager.refreshNamenodes(Lorg/apache/hadoop/conf/Configuration;)V 4 328 333 339 345 
org.apache.hadoop.io.compress.CompressionCodecFactory.main([Ljava/lang/String;)V 3 300 315 279 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.countLiveNodes(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;)I 1 2275 
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTree()Lorg/apache/hadoop/yarn/util/ProcfsBasedProcessTree; 4 168 185 199 208 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.completeBlock(Lorg/apache/hadoop/hdfs/server/namenode/INodeFile;Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;)Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo; 1 469 
org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run()V 2 208 219 
org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.loadAllKeys(Ljava/io/DataInputStream;)V 1 273 
org.apache.hadoop.mapreduce.JobStatus.readFields(Ljava/io/DataInput;)V 1 472 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitBlockSynchronization(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;JJZZ[Lorg/apache/hadoop/hdfs/protocol/DatanodeID;)V 2 2394 2403 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$SummarizedJob.<init>(Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$JobInfo;)V 2 600 596 
org.apache.hadoop.fs.FileContext$Util.globStatusInternal(Ljava/net/URI;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)[Lorg/apache/hadoop/fs/FileStatus; 2 2008 2027 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$FilteredJob.<init>(Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$JobInfo;Ljava/lang/String;)V 2 777 774 
org.apache.hadoop.record.compiler.generated.ParseException.getMessage()Ljava/lang/String; 3 133 129 143 
org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.<init>(Lorg/apache/hadoop/mapreduce/JobID;Ljava/lang/String;Ljava/lang/String;JLjava/lang/String;Ljava/util/Map;Ljava/lang/String;)V 1 61 
org.apache.hadoop.hdfs.server.datanode.DataStorage.linkBlocks(Ljava/io/File;Ljava/io/File;ILorg/apache/hadoop/fs/HardLink;)V 2 703 730 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processDirectory(Ljava/io/DataInputStream;Lorg/apache/hadoop/hdfs/tools/offlineImageViewer/ImageVisitor;Z)I 1 398 
org.apache.hadoop.mapred.lib.MultipleOutputs.close()V 1 536 
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$MultiPathFilter.toString()Ljava/lang/String; 1 689 
org.apache.hadoop.mapred.join.CompositeInputFormat.compose(Ljava/lang/String;Ljava/lang/Class;[Lorg/apache/hadoop/fs/Path;)Ljava/lang/String; 1 171 
org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run()V 1 66 
org.apache.hadoop.hdfs.web.JsonUtil.toJsonArray([Lorg/apache/hadoop/security/token/Token;)[Ljava/lang/Object; 1 112 
org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.run()V 5 321 331 343 355 319 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.buildBuckets(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/metrics2/lib/MutableGaugeInt; 1 192 
org.apache.hadoop.hdfs.server.datanode.BlockSender.waitForMinLength(Lorg/apache/hadoop/hdfs/server/datanode/ReplicaBeingWritten;J)V 1 374 
org.apache.hadoop.mapred.LocalJobRunner$Job.run()V 5 377 398 416 450 450 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.isZero([BII)Z 2 324 336 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.decimalCompare1([BII)I 1 284 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.parseKey(Ljava/lang/String;Ljava/util/StringTokenizer;)Lorg/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper$KeyDescription; 2 232 261 
org.apache.hadoop.mapred.Counters.makeCompactString()Ljava/lang/String; 2 96 95 
org.apache.hadoop.http.HttpServer.openListener()V 1 669 
org.apache.hadoop.fs.viewfs.ViewFileSystem.setWriteChecksum(Z)V 1 527 
org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser.<init>(Lorg/apache/hadoop/conf/Configuration;)V 1 53 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.blockSort()V 1 1613 
org.apache.hadoop.hdfs.server.datanode.DataXceiver.run()V 1 147 
org.apache.hadoop.mapred.Queue.getLeafQueues()Ljava/util/Map; 1 257 
org.apache.hadoop.mapreduce.split.JobSplitWriter.writeNewSplits(Lorg/apache/hadoop/conf/Configuration;[Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/fs/FSDataOutputStream;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo; 1 118 
org.apache.hadoop.mapreduce.split.JobSplitWriter.writeJobSplitMetaInfo(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/permission/FsPermission;I[Lorg/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo;)V 1 167 
org.apache.hadoop.mapreduce.split.JobSplitWriter.writeOldSplits([Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/fs/FSDataOutputStream;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$SplitMetaInfo; 1 143 
org.apache.hadoop.mapreduce.lib.partition.InputSampler.writePartitionFile(Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/mapreduce/lib/partition/InputSampler$Sampler;)V 2 337 335 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogGroup.planAllInProgressRecovery()V 2 405 413 
org.apache.hadoop.ipc.Server$Listener.doStop()V 1 640 
org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.readFields(Ljava/io/DataInput;)V 1 170 
org.apache.hadoop.fs.FileUtil.replaceFile(Ljava/io/File;Ljava/io/File;)V 1 705 
org.apache.hadoop.hdfs.web.resources.EnumSetParam.toString(Ljava/util/EnumSet;)Ljava/lang/String; 1 33 
org.apache.hadoop.yarn.util.FSDownload.changePermissions(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;)V 1 218 
org.apache.hadoop.util.StringUtils.camelize(Ljava/lang/String;)Ljava/lang/String; 1 786 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.waitIfAutoSyncScheduled()V 1 227 
org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping.cacheGroupsAdd(Ljava/util/List;)V 1 83 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.shouldForceSync()Z 1 251 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.logSync()V 3 377 402 420 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper.generateDecommissioningReport()Lorg/apache/hadoop/hdfs/server/namenode/ClusterJspHelper$DecommissionStatus; 1 125 
org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(Lorg/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand$RecoveringBlock;)V 1 1883 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.compare([BII[BII)I 1 93 
org.apache.hadoop.util.ShutdownHookManager$1.run()V 1 52 
org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.getNextBPScanner(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/datanode/BlockPoolSliceScanner; 3 138 136 128 
org.apache.hadoop.conf.Configuration.addDefaultResource(Ljava/lang/String;)V 1 554 
org.apache.hadoop.hdfs.server.namenode.NNStorage.newNamespaceID()I 1 544 
org.apache.hadoop.hdfs.server.namenode.NNStorage.getNumStorageDirs(Lorg/apache/hadoop/hdfs/server/namenode/NNStorage$NameNodeDirType;)I 1 351 
org.apache.hadoop.hdfs.server.common.Storage$DirIterator.hasNext()Z 1 135 
org.apache.hadoop.io.WritableComparator.readVLong([BI)J 1 223 
org.apache.hadoop.hdfs.BlockReaderUtil.readAll(Lorg/apache/hadoop/hdfs/BlockReader;[BII)I 1 32 
org.apache.hadoop.hdfs.server.namenode.FSImage.waitForThreads(Ljava/util/List;)V 2 789 788 
org.apache.hadoop.hdfs.server.namenode.FSImage.renameCheckpoint(J)V 1 878 
org.apache.hadoop.hdfs.server.namenode.NNStorage.getDirectories(Lorg/apache/hadoop/hdfs/server/namenode/NNStorage$NameNodeDirType;)Ljava/util/Collection; 1 368 
org.apache.hadoop.hdfs.server.namenode.NNStorage.readAndInspectDirs()Lorg/apache/hadoop/hdfs/server/namenode/FSImageStorageInspector; 1 1031 
org.apache.hadoop.hdfs.protocol.DirectoryListing.readFields(Ljava/io/DataInput;)V 1 114 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedUpdateCount([Lorg/apache/hadoop/hdfs/server/namenode/INode;IJJ)V 1 1508 
org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(Ljava/util/List;)J 1 679 
org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(Lorg/apache/hadoop/metrics2/impl/MetricsBuffer;)V 2 144 142 
org.apache.hadoop.hdfs.server.namenode.NNStorage.getFiles(Lorg/apache/hadoop/hdfs/server/namenode/NNStorage$NameNodeDirType;Ljava/lang/String;)Ljava/util/List; 1 724 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.printStatistics(Z)V 2 478 486 
org.apache.hadoop.io.WritableUtils.readStringArray(Ljava/io/DataInput;)[Ljava/lang/String; 1 168 
org.apache.hadoop.io.WritableUtils.writeStringArray(Ljava/io/DataOutput;[Ljava/lang/String;)V 1 137 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.countActiveJournals()I 1 707 
org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.bestNode(Lorg/apache/hadoop/hdfs/DFSClient;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;Ljava/util/TreeSet;)Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 572 
org.apache.hadoop.hdfs.server.datanode.BPOfferService.triggerHeartbeatForTests()V 1 117 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.getProcessTree()Lorg/apache/hadoop/mapreduce/util/ProcfsBasedProcessTree; 4 184 201 215 224 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.pullNewlyAllocatedContainers()Ljava/util/List; 1 269 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.getCumulativeCpuTime()J 1 455 
org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex([B)Ljava/lang/String; 1 138 
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetClusterNodesResponsePBImpl.initLocalNodeManagerInfosList()V 1 104 
org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(Lorg/apache/hadoop/metrics2/impl/SinkQueue$Consumer;)V 1 86 
org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader.getSelectQuery()Ljava/lang/String; 1 63 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printFailedAttempts(Lorg/apache/hadoop/mapreduce/jobhistory/HistoryViewer$FilteredJob;)V 2 434 429 
org.apache.hadoop.mapreduce.lib.db.IntegerSplitter.split(JJJ)Ljava/util/List; 1 120 
org.apache.hadoop.mapred.ClientServiceDelegate.getProxy()Lorg/apache/hadoop/mapreduce/v2/api/MRClientProtocol; 1 149 
org.apache.hadoop.hdfs.DFSOutputStream.waitAndQueueCurrentPacket()V 1 1315 
org.apache.hadoop.mapreduce.JobSubmitter.populateTokenCache(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/security/Credentials;)V 1 570 
org.apache.hadoop.util.QuickSort.sortInternal(Lorg/apache/hadoop/util/IndexedSortable;IILorg/apache/hadoop/util/Progressable;I)V 7 75 74 99 105 116 119 73 
org.apache.hadoop.mapreduce.lib.input.NLineInputFormat.getSplitsForFile(Lorg/apache/hadoop/fs/FileStatus;Lorg/apache/hadoop/conf/Configuration;I)Ljava/util/List; 1 106 
org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery()Z 2 900 892 
org.apache.hadoop.mapreduce.TypeConverter.fromYarn(Lorg/apache/hadoop/mapreduce/v2/api/records/TaskReport;)Lorg/apache/hadoop/mapreduce/TaskReport; 2 348 362 
org.apache.hadoop.record.compiler.generated.Rcc.Input()Lorg/apache/hadoop/record/compiler/JFile; 1 122 
org.apache.hadoop.mapred.Task$GcTimeUpdater.getElapsedGc()J 1 839 
org.apache.hadoop.io.SequenceFile$CompressedBytes.writeUncompressedBytes(Ljava/io/DataOutputStream;)V 1 684 
org.apache.hadoop.hdfs.server.balancer.Balancer.isGoodBlockCandidate(Lorg/apache/hadoop/hdfs/server/balancer/Balancer$Source;Lorg/apache/hadoop/hdfs/server/balancer/Balancer$BalancerDatanode;Lorg/apache/hadoop/hdfs/server/balancer/Balancer$BalancerBlock;)Z 2 1207 1219 
org.apache.hadoop.hdfs.server.namenode.Checkpointer.rollForwardByApplyingLogs(Lorg/apache/hadoop/hdfs/server/protocol/RemoteEditLogManifest;Lorg/apache/hadoop/hdfs/server/namenode/FSImage;)V 1 279 
org.apache.hadoop.mapred.join.CompositeRecordReader.close()V 1 445 
org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.remoteIterToList(Lorg/apache/hadoop/fs/RemoteIterator;)Ljava/util/List; 1 464 
org.apache.hadoop.security.SaslInputStream.unsignedBytesToInt([B)I 1 75 
org.apache.hadoop.hdfs.server.datanode.FSDataset.deleteBlockPool(Ljava/lang/String;Z)V 2 2594 2603 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.addToInvalidates(Lorg/apache/hadoop/hdfs/protocol/Block;)V 1 793 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.canLoadVersion(I)Z 1 135 
org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.purge(Ljava/lang/String;)V 1 198 
org.apache.hadoop.mapred.Queue.getInnerQueues()Ljava/util/Map; 1 229 
org.apache.hadoop.mapred.lib.CombineFileRecordReader.next(Ljava/lang/Object;Ljava/lang/Object;)Z 1 62 
org.apache.hadoop.mapreduce.lib.db.DBOutputFormat.constructQuery(Ljava/lang/String;[Ljava/lang/String;)Ljava/lang/String; 2 145 155 
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.dump()V 2 384 376 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.createTaskFailedEvent(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl;Ljava/util/List;Lorg/apache/hadoop/mapreduce/v2/api/records/TaskState;Lorg/apache/hadoop/mapreduce/v2/api/records/TaskAttemptId;)Lorg/apache/hadoop/mapreduce/jobhistory/TaskFailedEvent; 1 670 
org.apache.hadoop.mapreduce.v2.app.taskclean.TaskCleanerImpl$1.run()V 1 62 
org.apache.hadoop.mapreduce.v2.app.webapp.AttemptsPage$FewAttemptsBlock.getTaskAttempts()Ljava/util/Collection; 2 62 60 
org.apache.hadoop.hdfs.tools.DFSAdmin.printTopology()I 3 741 760 756 
org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer.reduce(Lorg/apache/hadoop/io/Text;Ljava/lang/Iterable;Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 1 98 
org.apache.hadoop.util.AsyncDiskService.shutdownNow()Ljava/util/List; 1 153 
org.apache.hadoop.hdfs.server.blockmanagement.Host2NodesMap.remove(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)Z 1 113 
org.apache.hadoop.mapred.StatisticsCollector$TimeWindowStatUpdater.update()V 2 279 285 
org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl$RequestResourcesTransition.transition(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/container/ContainerImpl;Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/container/ContainerEvent;)Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/container/ContainerState; 2 484 497 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.sampleMetrics()Lorg/apache/hadoop/metrics2/impl/MetricsBuffer; 1 361 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.checkDirs()V 1 660 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.showRequests()V 2 290 284 
org.apache.hadoop.io.WritableUtils.displayByteArray([B)V 1 198 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.scheduleAllReduces()V 1 502 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printAllTaskAttempts(Lorg/apache/hadoop/mapreduce/TaskType;)V 2 213 211 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.localizeFiles(Lorg/apache/hadoop/yarn/server/nodemanager/api/LocalizationProtocol;Ljava/util/concurrent/CompletionService;Lorg/apache/hadoop/security/UserGroupInformation;)V 3 241 264 236 
org.apache.hadoop.metrics.ganglia.GangliaContext31.emitMetric(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V 2 119 137 
org.apache.hadoop.mapreduce.v2.hs.webapp.dao.JobInfo.<init>(Lorg/apache/hadoop/mapreduce/v2/app/job/Job;)V 2 114 123 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.getRemaining()J 1 843 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper$DecommissionStatus.countDecommissionDatanodes()V 1 784 
org.apache.hadoop.mapred.MapRunner.run(Lorg/apache/hadoop/mapred/RecordReader;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 52 
org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(J[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)Lorg/apache/hadoop/hdfs/protocol/LocatedBlock; 1 1097 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getUserAclInfo(Lorg/apache/hadoop/security/UserGroupInformation;)Lorg/apache/hadoop/yarn/api/records/QueueUserACLInfo; 1 321 
org.apache.hadoop.mapred.FileInputFormat.fakeRacks([Lorg/apache/hadoop/fs/BlockLocation;I)[Ljava/lang/String; 1 626 
org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.unregister()V 1 176 
org.apache.hadoop.fs.viewfs.InodeTree$INodeLink.getTargetLink()Lorg/apache/hadoop/fs/Path; 1 195 
org.apache.hadoop.metrics.jvm.JvmMetrics.doThreadUpdates()V 1 152 
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoUnderConstruction.initializeBlockRecovery(J)V 1 237 
org.apache.hadoop.hdfs.server.datanode.DataNode.syncBlock(Lorg/apache/hadoop/hdfs/server/protocol/BlockRecoveryCommand$RecoveringBlock;Ljava/util/List;)V 5 1958 1979 1991 2007 2028 
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetQueueUserAclsInfoResponsePBImpl.initLocalQueueUserAclsList()V 1 106 
org.apache.hadoop.mapreduce.lib.db.IntegerSplitter.split(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List; 1 66 
org.apache.hadoop.hdfs.server.namenode.FSImage.saveDigestAndRenameCheckpointImage(JLorg/apache/hadoop/io/MD5Hash;)V 1 991 
org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getDelegationTokens(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/security/Credentials;)V 2 104 110 
org.apache.hadoop.mapred.JobQueueClient.displayQueueAclsInfoForCurrentUser()V 2 207 202 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.convertLastBlockToUnderConstruction(Lorg/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction;)Lorg/apache/hadoop/hdfs/protocol/LocatedBlock; 1 508 
org.apache.hadoop.fs.FileContext$Util.listStatus([Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)[Lorg/apache/hadoop/fs/FileStatus; 1 1657 
org.apache.hadoop.hdfs.server.balancer.Balancer.chooseSource(Lorg/apache/hadoop/hdfs/server/balancer/Balancer$BalancerDatanode;Ljava/util/Iterator;Z)Z 1 1026 
org.apache.hadoop.hdfs.tools.offlineImageViewer.DelimitedImageVisitor.reset()V 1 96 
org.apache.hadoop.fs.AbstractFileSystem.printStatistics()V 1 198 
org.apache.hadoop.mapreduce.JobSubmitter.readTokensFromFiles(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/security/Credentials;)V 1 545 
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 53 
org.apache.hadoop.io.WritableUtils.readCompressedStringArray(Ljava/io/DataInput;)[Ljava/lang/String; 1 184 
org.apache.hadoop.metrics2.util.MetricsCache.update(Lorg/apache/hadoop/metrics2/MetricsRecord;Z)Lorg/apache/hadoop/metrics2/util/MetricsCache$Record; 2 167 172 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.getProcessList()Ljava/util/List; 1 478 
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.selectContainerTokenIdentifier(Lorg/apache/hadoop/security/UserGroupInformation;)Lorg/apache/hadoop/yarn/security/ContainerTokenIdentifier; 1 288 
org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder.checkEOF()Z 1 122 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.toString()Ljava/lang/String; 1 561 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.getCumulativeRssmem(I)J 1 435 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.getCumulativeVmem(I)J 1 412 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processOverReplicatedBlock(Lorg/apache/hadoop/hdfs/protocol/Block;SLorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)V 1 1946 
org.apache.hadoop.fs.shell.FsUsage$TableBuilder.setRightAlign([I)V 1 208 
org.apache.hadoop.mapred.lib.TokenCountMapper.map(Ljava/lang/Object;Lorg/apache/hadoop/io/Text;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 52 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.invalidateCorruptReplicas(Lorg/apache/hadoop/hdfs/protocol/Block;)V 1 1840 
org.apache.hadoop.mapred.MapReduceChildJVM.getVMCommand(Ljava/net/InetSocketAddress;Lorg/apache/hadoop/mapred/Task;Lorg/apache/hadoop/mapreduce/ID;)Ljava/util/List; 2 201 246 
org.apache.hadoop.hdfs.server.namenode.NameNode.format(Lorg/apache/hadoop/conf/Configuration;Z)Z 1 582 
org.apache.hadoop.ipc.ProtocolSignature.getFingerprints([Ljava/lang/reflect/Method;)[I 1 123 
org.apache.hadoop.mapreduce.lib.chain.ChainReducer.run(Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 1 206 
org.apache.hadoop.yarn.security.ContainerTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 43 
org.apache.hadoop.hdfs.tools.DelegationTokenFetcher$1.run()Ljava/lang/Object; 5 153 163 173 186 195 
org.apache.hadoop.fs.FileUtil.fullyDeleteContents(Ljava/io/File;)Z 1 114 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.verifyBlock(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;)V 1 396 
org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit.write(Ljava/io/DataOutput;)V 2 126 129 
org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService.getAMInfos()Ljava/util/List; 1 167 
org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.loadGangliaConf(Lorg/apache/hadoop/metrics2/sink/ganglia/AbstractGangliaSink$GangliaConfType;)V 1 166 
org.apache.hadoop.hdfs.RemoteBlockReader.skip(J)J 1 145 
org.apache.hadoop.conf.Configuration.getValByRegex(Ljava/lang/String;)Ljava/util/Map; 1 2214 
org.apache.hadoop.util.StringUtils.stringToURI([Ljava/lang/String;)[Ljava/net/URI; 1 216 
org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.incrAllCounters(Lorg/apache/hadoop/mapreduce/counters/CounterGroupBase;)V 1 201 
org.apache.hadoop.hdfs.server.datanode.DataNode.isDatanodeUp()Z 1 1548 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.parseInts(Ljava/lang/String;)Ljava/util/ArrayList; 1 179 
org.apache.hadoop.mapreduce.QueueInfo.write(Ljava/io/DataOutput;)V 2 222 226 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.getWeight(Ljava/util/List;)D 1 383 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.computeRatio()V 1 371 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.removeKey(Lorg/apache/hadoop/util/bloom/Key;[Ljava/util/List;)V 1 362 
org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser.deprecatedConf(Lorg/apache/hadoop/conf/Configuration;)Z 2 111 110 
org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser.createQueues(Lorg/apache/hadoop/conf/Configuration;)Ljava/util/List; 1 62 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeBlocks(Ljava/util/List;)V 2 1977 1972 
org.apache.hadoop.fs.s3.S3InputStream.<init>(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/s3/FileSystemStore;Lorg/apache/hadoop/fs/s3/INode;Lorg/apache/hadoop/fs/FileSystem$Statistics;)V 1 72 
org.apache.hadoop.hdfs.server.namenode.TransferFsImage.downloadEditsToStorage(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/protocol/RemoteEditLog;Lorg/apache/hadoop/hdfs/server/namenode/NNStorage;)V 1 82 
org.apache.hadoop.fs.FileUtil.copy(Ljava/io/File;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;ZLorg/apache/hadoop/conf/Configuration;)Z 1 327 
org.apache.hadoop.metrics.spi.CompositeContext.registerUpdater(Lorg/apache/hadoop/metrics/Updater;)V 1 155 
org.apache.hadoop.hdfs.DFSInputStream.chooseDataNode(Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;)Lorg/apache/hadoop/hdfs/DFSInputStream$DNAddrPair; 1 602 
org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(Ljava/net/InetSocketAddress;Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;Lorg/apache/hadoop/security/token/Token;JJIZLjava/lang/String;)Lorg/apache/hadoop/hdfs/BlockReader; 1 763 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.getWordLengths([BII)[I 1 102 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.getStartOffset([BII[ILorg/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper$KeyDescription;)I 1 124 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.getEndOffset([BII[ILorg/apache/hadoop/mapreduce/lib/partition/KeyFieldHelper$KeyDescription;)I 1 145 
org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.write(Ljava/io/DataOutput;)V 1 75 
org.apache.hadoop.fs.Hdfs.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 4 280 293 307 299 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper.getDecommissionNodeClusterState(Ljava/util/Map;)V 2 171 188 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getJobAttempts(Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/v2/hs/webapp/dao/AMAttemptsInfo; 1 208 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobCounterInfo.getCounters(Lorg/apache/hadoop/mapreduce/v2/app/AppContext;Lorg/apache/hadoop/mapreduce/v2/app/job/Job;)V 1 82 
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.updateKeepAliveApplications(Ljava/util/List;)V 1 405 
org.apache.hadoop.hdfs.server.common.Storage$DirIterator.next()Lorg/apache/hadoop/hdfs/server/common/Storage$StorageDirectory; 1 151 
org.apache.hadoop.mapred.SortedRanges$SkipRangeIterator.doNext()V 1 349 
org.apache.hadoop.io.MD5Hash.setDigest(Ljava/lang/String;)V 1 214 
org.apache.hadoop.mapred.TaskReport.getRunningTaskAttempts()Ljava/util/Collection; 1 130 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Ljava/util/HashMap;JILjava/util/List;)Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 275 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(ILjava/lang/String;Ljava/util/HashMap;JILjava/util/List;)V 1 389 
org.apache.hadoop.hdfs.server.blockmanagement.PendingReplicationBlocks.metaSave(Ljava/io/PrintWriter;)V 1 251 
org.apache.hadoop.util.HeapSort.downHeap(Lorg/apache/hadoop/util/IndexedSortable;III)V 1 34 
org.apache.hadoop.yarn.webapp.view.InfoBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 43 
org.apache.hadoop.mapred.Queue.copySchedulingInfo(Lorg/apache/hadoop/mapred/Queue;)V 1 164 
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskReportsResponsePBImpl.initTaskReports()V 1 106 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.doneApplication(Lorg/apache/hadoop/yarn/api/records/ApplicationAttemptId;Lorg/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptState;)V 1 315 
org.apache.hadoop.yarn.event.AsyncDispatcher$1.run()V 1 66 
org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run()V 2 663 652 
org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getAllPartialJobs()Ljava/util/Map; 1 132 
org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder$UnsafeComparer.compareTo([BII[BII)I 2 190 225 
org.apache.hadoop.util.hash.JenkinsHash.main([Ljava/lang/String;)V 1 258 
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl.initServiceData()V 1 321 
org.apache.hadoop.hdfs.DFSUtil.getAddresses(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;[Ljava/lang/String;)Ljava/util/List; 1 374 
org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(Lorg/apache/hadoop/hdfs/server/datanode/DataNode;Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/protocol/NamespaceInfo;Ljava/util/Collection;Lorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$StartupOption;)V 1 226 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.getPartition(Ljava/lang/Object;Ljava/lang/Object;I)I 1 106 
org.apache.hadoop.hdfs.LeaseRenewer.clientsString()Ljava/lang/String; 1 499 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogLoadPlan.doRecovery()V 1 499 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogLoadPlan.getEditsFiles()Ljava/util/List; 1 506 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.getInProgressFileInputStream()Lorg/apache/hadoop/hdfs/server/namenode/EditLogInputStream; 1 1154 
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobReportPBImpl.addAMInfosToProto()V 1 307 
org.apache.hadoop.conf.Configuration.addDeprecation(Ljava/lang/String;[Ljava/lang/String;Ljava/lang/String;)V 1 318 
org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl.initLocalChildQueuesList()V 1 216 
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.toString()Ljava/lang/String; 1 459 
org.apache.hadoop.hdfs.DFSUtil.isDefaultNamenodeAddress(Lorg/apache/hadoop/conf/Configuration;Ljava/net/InetSocketAddress;[Ljava/lang/String;)Z 1 566 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.getValidLocations(Lorg/apache/hadoop/hdfs/protocol/Block;)Ljava/util/List; 1 525 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer.write([BII)V 2 1360 1301 
org.apache.hadoop.hdfs.server.datanode.FSDataset.getBlockReport(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/BlockListAsLongs; 1 1890 
org.apache.hadoop.fs.FSInputChecker.read([BII)I 1 193 
org.apache.hadoop.security.authorize.AccessControlList.getString(Ljava/util/Set;)Ljava/lang/String; 1 361 
org.apache.hadoop.yarn.api.records.impl.pb.AMResponsePBImpl.initLocalFinishedContainerList()V 1 252 
org.apache.hadoop.mapreduce.tools.CLI.displayJobList([Lorg/apache/hadoop/mapreduce/JobStatus;Ljava/io/PrintWriter;)V 1 584 
org.apache.hadoop.fs.viewfs.ViewFileSystem.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 360 
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.removeApplicationFromRenewal(Lorg/apache/hadoop/yarn/api/records/ApplicationId;)V 1 415 
org.apache.hadoop.io.compress.CompressionCodecFactory.<init>(Lorg/apache/hadoop/conf/Configuration;)V 1 166 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.generateMTFValues()V 7 1936 1946 1950 1962 1976 1957 2003 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper.readOutput(Ljava/net/URL;)Ljava/lang/String; 1 871 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues()V 2 949 947 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks.getUnderReplicatedBlockCount()I 1 114 
org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.waitForInit(Ljava/lang/String;)V 1 106 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper.updateUnknownStatus(Ljava/util/Map;Ljava/util/List;)V 2 242 239 
org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(Lorg/apache/hadoop/fs/Path;Ljava/net/InetSocketAddress;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/util/List;Ljava/util/List;)V 1 156 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalDatanode(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;Ljava/util/HashMap;ILjava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/LocatedBlock; 1 1572 
org.apache.hadoop.net.AbstractDNSToSwitchMapping.dumpTopology()Ljava/lang/String; 1 120 
org.apache.hadoop.mapred.Task.done(Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/Task$TaskReporter;)V 1 977 
org.apache.hadoop.util.LineReader.readCustomLine(Lorg/apache/hadoop/io/Text;II)I 2 262 254 
org.apache.hadoop.hdfs.server.namenode.NameNode.confirmPrompt(Ljava/lang/String;)Z 2 701 698 
org.apache.hadoop.mapred.join.CompositeRecordReader.fillJoinCollector(Lorg/apache/hadoop/io/WritableComparable;)V 1 384 
org.apache.hadoop.hdfs.server.balancer.Balancer$Cli.parse([Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/balancer/Balancer$Parameters; 1 1499 
org.apache.hadoop.hdfs.server.balancer.Balancer.run(Ljava/util/List;Lorg/apache/hadoop/hdfs/server/balancer/Balancer$Parameters;Lorg/apache/hadoop/conf/Configuration;)I 6 1396 1420 1404 1401 1420 1420 
org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit.readFields(Ljava/io/DataInput;)V 2 151 155 
org.apache.hadoop.hdfs.util.DirectBufferPool.getBuffer(I)Ljava/nio/ByteBuffer; 1 63 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseExcessReplicates(Ljava/util/Collection;Lorg/apache/hadoop/hdfs/protocol/Block;SLorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicy;)V 3 1989 2005 2017 
org.apache.hadoop.ipc.ProtocolSignature.getFingerprint(Ljava/lang/reflect/Method;)I 1 106 
org.apache.hadoop.fs.AbstractFileSystem.clearStatistics()V 1 189 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.getPaths(Ljava/util/List;)Ljava/util/List; 1 489 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.createUserLocalDirs(Ljava/util/List;Ljava/lang/String;)V 1 337 
org.apache.hadoop.util.DataChecksum.verifyChunkedSums(Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;Ljava/lang/String;J)V 1 298 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.createUserCacheDirs(Ljava/util/List;Ljava/lang/String;)V 1 371 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsJobBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 3 104 119 139 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.createAppDirs(Ljava/util/List;Ljava/lang/String;Ljava/lang/String;)V 1 413 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.createAppLogDirs(Ljava/lang/String;Ljava/util/List;)V 1 438 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.runLocalization(Ljava/net/InetSocketAddress;)I 1 164 
org.apache.hadoop.mapred.QueueConfigurationParser.parseResource(Lorg/w3c/dom/Element;)Lorg/apache/hadoop/mapred/Queue; 1 212 
org.apache.hadoop.fs.FileSystem.collectDelegationTokens(Ljava/lang/String;Lorg/apache/hadoop/security/Credentials;Ljava/util/List;)V 1 475 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.close()V 1 477 
org.apache.hadoop.mapred.DeprecatedQueueConfigurationParser.getQueueAcls(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Ljava/util/Map; 1 142 
org.apache.hadoop.conf.Configuration.readFields(Ljava/io/DataInput;)V 1 2182 
org.apache.hadoop.util.UTF8ByteArrayUtils.findBytes([BII[B)I 2 56 54 
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$OneBlockInfo.<init>(Lorg/apache/hadoop/fs/Path;JJ[Ljava/lang/String;[Ljava/lang/String;)V 2 618 627 
org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;JZ)Z 2 1007 1063 
org.apache.hadoop.net.DNS.getIPs(Ljava/lang/String;)[Ljava/lang/String; 1 115 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.getFullPathName(Lorg/apache/hadoop/hdfs/server/namenode/INode;)Ljava/lang/String; 2 1535 1541 
org.apache.hadoop.mapred.jobcontrol.JobControl.castToJobList(Ljava/util/List;)Ljava/util/ArrayList; 1 44 
org.apache.hadoop.fs.s3.S3FileSystem.delete(Lorg/apache/hadoop/fs/Path;Z)Z 2 298 313 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$TaskAttemptFetchFailureTransition.transition(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl;Lorg/apache/hadoop/mapreduce/v2/app/job/event/JobEvent;)V 2 1302 1295 
org.apache.hadoop.record.compiler.generated.RccTokenManager.jjMoveNfa_1(II)I 4 93 121 133 86 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadLocalNameINodes(JLjava/io/DataInputStream;)V 1 249 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadFullNameINodes(JLjava/io/DataInputStream;)V 1 298 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDatanodes(Ljava/io/DataInputStream;)V 1 409 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadFilesUnderConstruction(Ljava/io/DataInputStream;)V 1 425 
org.apache.hadoop.fs.ftp.FTPFileSystem.delete(Lorg/apache/commons/net/ftp/FTPClient;Lorg/apache/hadoop/fs/Path;Z)Z 1 310 
org.apache.hadoop.mapreduce.v2.security.client.ClientHSTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 44 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogGroup.getLastTxId()J 1 324 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.getFinishTime(Lorg/apache/hadoop/mapreduce/v2/api/records/TaskAttemptId;)J 1 472 
org.apache.hadoop.io.retry.RetryPolicies$RemoteExceptionDependentRetry.<init>(Lorg/apache/hadoop/io/retry/RetryPolicy;Ljava/util/Map;)V 1 251 
org.apache.hadoop.metrics2.util.MetricsCache$Record.metrics()Ljava/util/Set; 1 116 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.createStatus()Lorg/apache/hadoop/yarn/server/nodemanager/api/protocolrecords/LocalizerStatus; 1 296 
org.apache.hadoop.fs.FileContext$Util.globStatus(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)[Lorg/apache/hadoop/fs/FileStatus; 2 1950 1947 
org.apache.hadoop.hdfs.server.namenode.INodeDirectory.computeContentSummary([J)[J 2 393 409 
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.recoverCreate(Z)V 1 780 
org.apache.hadoop.fs.FSInputChecker.checksum2long([B)J 1 337 
org.apache.hadoop.hdfs.DFSUtil.getConfValue(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;[Ljava/lang/String;)Ljava/lang/String; 1 338 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getNumLiveDataNodes()I 1 707 
org.apache.hadoop.io.MapFile$Reader.seekInternal(Lorg/apache/hadoop/io/WritableComparable;Z)I 1 616 
org.apache.hadoop.hdfs.server.namenode.NNStorage.getFsImageNameCheckpoint(J)[Ljava/io/File; 1 481 
org.apache.hadoop.mapreduce.v2.hs.CompletedTask.loadAllTaskAttempts()V 1 146 
org.apache.hadoop.mapreduce.TypeConverter.toYarn(Lorg/apache/hadoop/mapreduce/Counters;)Lorg/apache/hadoop/mapreduce/v2/api/records/Counters; 2 272 267 
org.apache.hadoop.mapreduce.v2.app.webapp.TasksBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 69 
org.apache.hadoop.metrics.spi.AbstractMetricsContext.getAllRecords()Ljava/util/Map; 2 338 333 
org.apache.hadoop.mapred.ReduceTask.runOldReducer(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/Task$TaskReporter;Lorg/apache/hadoop/mapred/RawKeyValueIterator;Lorg/apache/hadoop/io/RawComparator;Ljava/lang/Class;Ljava/lang/Class;)V 1 446 
org.apache.hadoop.mapreduce.lib.join.Parser$CNode.getSplits(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 3 438 453 451 
org.apache.hadoop.conf.Configuration.get(Ljava/lang/String;)Ljava/lang/String; 1 703 
org.apache.hadoop.fs.BlockLocation.readFields(Ljava/io/DataInput;)V 3 255 263 271 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeResourceMonitor.run()V 1 2604 
org.apache.hadoop.hdfs.server.namenode.INodeDirectory.spaceConsumedInTree(Lorg/apache/hadoop/hdfs/server/namenode/INode$DirCounts;)Lorg/apache/hadoop/hdfs/server/namenode/INode$DirCounts; 1 379 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper.generateClusterHealthReport()Lorg/apache/hadoop/hdfs/server/namenode/ClusterJspHelper$ClusterStatus; 1 79 
org.apache.hadoop.mapreduce.TypeConverter.fromYarnNodes(Ljava/util/List;)[Lorg/apache/hadoop/mapreduce/TaskTrackerInfo; 1 412 
org.apache.hadoop.util.AsyncDiskService.awaitTermination(J)Z 1 131 
org.apache.hadoop.mapreduce.v2.app.webapp.TaskPage$AttemptsBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 76 
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.checkState()Lorg/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob$State; 1 294 
org.apache.hadoop.hdfs.server.namenode.NNStorage.findFile(Lorg/apache/hadoop/hdfs/server/namenode/NNStorage$NameNodeDirType;Ljava/lang/String;)Ljava/io/File; 1 706 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfInfo.<init>(Lorg/apache/hadoop/mapreduce/v2/app/job/Job;)V 1 48 
org.apache.hadoop.mapreduce.lib.chain.Chain.setup(Lorg/apache/hadoop/conf/Configuration;)V 1 823 
org.apache.hadoop.mapred.YARNRunner.createApplicationSubmissionContext(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;Lorg/apache/hadoop/security/Credentials;)Lorg/apache/hadoop/yarn/api/records/ApplicationSubmissionContext; 2 360 401 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues4()V 6 1198 1195 1205 1218 1216 1213 
org.apache.hadoop.mapreduce.task.reduce.MergeThread.startMerge(Ljava/util/Set;)V 1 62 
org.apache.hadoop.util.bloom.CountingBloomFilter.add(Lorg/apache/hadoop/util/bloom/Key;)V 1 113 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.publishMetrics(Lorg/apache/hadoop/metrics2/impl/MetricsBuffer;)V 1 388 
org.apache.hadoop.hdfs.server.namenode.INodeFile.collectSubtreeBlocksAndClear(Ljava/util/List;)I 1 162 
org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.getHost()Lorg/apache/hadoop/mapreduce/task/reduce/MapHost; 2 297 304 
org.apache.hadoop.util.Shell.runCommand()V 1 188 
org.apache.hadoop.yarn.webapp.WebApps$Builder.start(Lorg/apache/hadoop/yarn/webapp/WebApp;)Lorg/apache/hadoop/yarn/webapp/WebApp; 2 199 202 
org.apache.hadoop.mapreduce.lib.join.JoinRecordReader.nextKeyValue()Z 1 66 
org.apache.hadoop.io.compress.CompressionCodecFactory.getCodecClasses(Lorg/apache/hadoop/conf/Configuration;)Ljava/util/List; 1 109 
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.kill()V 1 199 
org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 723 
org.apache.hadoop.fs.HarFileSystem.makeRelative(Ljava/lang/String;Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path; 1 312 
org.apache.hadoop.mapred.join.MultiFilterRecordReader.next(Lorg/apache/hadoop/io/WritableComparable;Lorg/apache/hadoop/io/Writable;)Z 1 81 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stopSinks()V 1 417 
org.apache.hadoop.fs.RawLocalFileSystem.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 328 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.computeProgress()V 1 591 
org.apache.hadoop.mapreduce.lib.db.TextSplitter.stringToBigDecimal(Ljava/lang/String;)Ljava/math/BigDecimal; 1 188 
org.apache.hadoop.mapred.Task.updateCounters()V 2 928 939 
org.apache.hadoop.mapred.Task.commit(Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/Task$TaskReporter;Lorg/apache/hadoop/mapreduce/OutputCommitter;)V 1 1105 
org.apache.hadoop.mapred.Task$TaskReporter.stopCommunicationThread()V 1 758 
org.apache.hadoop.mapred.Task.sendDone(Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;)V 1 1085 
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle(Lorg/apache/hadoop/yarn/server/nodemanager/ContainerManagerEvent;)V 2 578 587 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;Ljava/util/HashMap;)Lorg/apache/hadoop/hdfs/protocol/LocatedBlock; 1 1533 
org.apache.hadoop.security.authorize.AccessControlList.cleanupList(Ljava/util/List;)V 1 237 
org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(Ljava/io/DataOutputStream;Ljava/io/OutputStream;Lorg/apache/hadoop/hdfs/util/DataTransferThrottler;)J 1 620 
org.apache.hadoop.security.authorize.AccessControlList.addToSet(Ljava/util/Set;Ljava/util/List;)V 1 255 
org.apache.hadoop.hdfs.server.balancer.Balancer.cleanGlobalBlockList()V 1 1251 
org.apache.hadoop.mapred.PeriodicStatsAccumulator.extend(DI)V 1 166 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer.spillSingleRecord(Ljava/lang/Object;Ljava/lang/Object;I)V 1 1622 
org.apache.hadoop.conf.Configuration.handleDeprecation()V 1 457 
org.apache.hadoop.ipc.Server$Listener.<init>(Lorg/apache/hadoop/ipc/Server;)V 1 353 
org.apache.hadoop.hdfs.DFSUtil$ErrorSimulator.initializeErrorSimulationEvent(I)V 1 151 
org.apache.hadoop.mapred.QueueConfigurationParser.createHierarchy(Ljava/lang/String;Lorg/w3c/dom/Element;)Lorg/apache/hadoop/mapred/Queue; 2 264 328 
org.apache.hadoop.fs.ftp.FTPFileSystem.getFileStatus(Lorg/apache/commons/net/ftp/FTPClient;Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/FileStatus; 1 411 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadINode(Ljava/io/DataInputStream;)Lorg/apache/hadoop/hdfs/server/namenode/INode; 1 349 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.loadDirectory(Ljava/io/DataInputStream;)I 1 273 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.<init>(Lorg/apache/hadoop/hdfs/server/namenode/NNStorage;)V 1 138 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.isParent([[B[[B)Z 1 482 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Loader.getParent([[B)[[B 1 497 
org.apache.hadoop.hdfs.server.namenode.FSImageSerialization.readINodeUnderConstruction(Ljava/io/DataInputStream;)Lorg/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction; 2 95 112 
org.apache.hadoop.mapreduce.lib.chain.Chain.startAllThreads()V 1 509 
org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(ILorg/apache/hadoop/hdfs/server/namenode/EditLogInputStream;ZJ)I 3 151 125 421 
org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.listFilteredStatus(Lorg/apache/hadoop/fs/FileContext;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)Ljava/util/List; 1 450 
org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.filteredStat2Paths(Ljava/util/List;ZLjava/util/concurrent/atomic/AtomicBoolean;)[Lorg/apache/hadoop/fs/Path; 2 480 489 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processMisReplicatedBlocks()V 1 1865 
org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService.parse()V 1 205 
org.apache.hadoop.mapred.Task$TaskReporter.incrCounter(Ljava/lang/String;Ljava/lang/String;J)V 1 653 
org.apache.hadoop.hdfs.server.datanode.FSDataset$BlockPoolSlice.addToReplicasMap(Lorg/apache/hadoop/hdfs/server/datanode/ReplicasMap;Ljava/io/File;Z)V 1 424 
org.apache.hadoop.mapreduce.lib.input.MultipleInputs.getInputFormatMap(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/Map; 1 105 
org.apache.hadoop.io.SortedMapWritable.putAll(Ljava/util/Map;)V 1 142 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.getDfsUsed()J 1 819 
org.apache.hadoop.fs.ChecksumFileSystem.copyToLocalFile(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;Z)V 1 622 
org.apache.hadoop.util.bloom.HashFunction.hash(Lorg/apache/hadoop/util/bloom/Key;)[I 1 117 
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl.initEnv()V 1 384 
org.apache.hadoop.io.ArrayWritable.toArray()Ljava/lang/Object; 1 81 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource.toString()Ljava/lang/String; 1 120 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handleInitContainerResources(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/event/ContainerLocalizationRequestEvent;)V 2 342 339 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handleCacheCleanup(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/event/LocalizationEvent;)V 1 353 
org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.ancestorsHaveExecutePermissions(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;)Z 1 237 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.setupQueueConfigs(Lorg/apache/hadoop/yarn/api/records/Resource;FFFFIFIIIILorg/apache/hadoop/yarn/api/records/QueueState;Ljava/util/Map;)V 1 248 
org.apache.hadoop.mapred.join.WrappedRecordReader.skip(Lorg/apache/hadoop/io/WritableComparable;)V 1 107 
org.apache.hadoop.mapred.ReduceTask.getMapFiles(Lorg/apache/hadoop/fs/FileSystem;Z)[Lorg/apache/hadoop/fs/Path; 2 182 187 
org.apache.hadoop.hdfs.server.datanode.FSDataset.getVolumeInfo()Ljava/util/Collection; 1 2557 
org.apache.hadoop.mapreduce.Mapper.run(Lorg/apache/hadoop/mapreduce/Mapper$Context;)V 1 143 
org.apache.hadoop.fs.s3native.NativeS3FileSystem.rename(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;)Z 3 646 645 657 
org.apache.hadoop.yarn.webapp.view.JQueryUI.initAccordions(Ljava/util/List;)V 1 117 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run()V 2 1454 1453 
org.apache.hadoop.record.meta.StructTypeID.read(Lorg/apache/hadoop/record/RecordInput;Ljava/lang/String;)V 1 100 
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices.getNodeContainers()Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/ContainersInfo; 1 149 
org.apache.hadoop.io.IOUtils.copyBytes(Ljava/io/InputStream;Ljava/io/OutputStream;JZ)V 1 128 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfoPerBlockPool.addAll(Lorg/apache/hadoop/hdfs/server/datanode/DirectoryScanner$ScanInfoPerBlockPool;)V 1 114 
org.apache.hadoop.util.StringUtils.byteToHexString([BII)Ljava/lang/String; 1 163 
org.apache.hadoop.util.bloom.BloomFilter.write(Ljava/io/DataOutput;)V 1 203 
org.apache.hadoop.hdfs.util.LightWeightGSet.printDetails(Ljava/io/PrintStream;)V 2 238 234 
org.apache.hadoop.io.MapWritable.write(Ljava/io/DataOutput;)V 1 159 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.bsFinishedWithStream()V 1 909 
org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcMemInfoFile(Z)V 1 168 
org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcCpuInfoFile()V 1 226 
org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcStatFile()V 1 273 
org.apache.hadoop.mapred.Task$FileSystemStatisticUpdater.updateCounters()V 1 904 
org.apache.hadoop.mapred.join.CompositeRecordReader.getProgress()F 1 459 
org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(Ljava/lang/String;)[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 965 
org.apache.hadoop.mapreduce.lib.db.DBInputFormat.getSplits(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 1 258 
org.apache.hadoop.util.Progress.get()F 1 171 
org.apache.hadoop.mapred.Task.statusUpdate(Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;)V 1 1028 
org.apache.hadoop.yarn.service.CompositeService.stop(I)V 1 96 
org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(Ljava/util/List;)Ljava/util/List; 2 174 183 
org.apache.hadoop.fs.HardLink$HardLinkCGWin.getLinkMultArgLength(Ljava/io/File;[Ljava/lang/String;Ljava/io/File;)I 1 344 
org.apache.hadoop.fs.HardLink$HardLinkCGUnix.getLinkMultArgLength(Ljava/io/File;[Ljava/lang/String;Ljava/io/File;)I 1 234 
org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader.fillJoinCollector(Lorg/apache/hadoop/io/WritableComparable;)V 3 94 105 109 
org.apache.hadoop.hdfs.server.datanode.DataNode.logRecoverBlock(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeID;)V 1 2045 
org.apache.hadoop.io.UTF8.utf8Length(Ljava/lang/String;)I 1 267 
org.apache.hadoop.io.UTF8.writeChars(Ljava/io/DataOutput;Ljava/lang/String;II)V 1 284 
org.apache.hadoop.mapred.QueueConfigurationParser.validate(Lorg/w3c/dom/Node;)V 1 386 
org.apache.hadoop.mapred.QueueConfigurationParser.populateProperties(Lorg/w3c/dom/Element;)Ljava/util/Properties; 1 345 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat$MultiPathFilter.accept(Lorg/apache/hadoop/fs/Path;)Z 1 92 
org.apache.hadoop.fs.FileSystem.clearStatistics()V 1 2548 
org.apache.hadoop.hdfs.DFSUtil.bytes2byteArray([BIB)[[B 4 248 254 267 266 
org.apache.hadoop.yarn.util.StringHelper.ujoin(Ljava/lang/String;[Ljava/lang/String;)Ljava/lang/String; 1 151 
org.apache.hadoop.record.compiler.generated.Rcc.driver([Ljava/lang/String;)I 2 59 82 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(Lorg/apache/hadoop/mapreduce/Job;[Lorg/apache/hadoop/fs/Path;)V 1 372 
org.apache.hadoop.util.bloom.DynamicBloomFilter.toString()Ljava/lang/String; 1 238 
org.apache.hadoop.io.ObjectWritable.writeObject(Ljava/io/DataOutput;Ljava/lang/Object;Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;Z)V 1 160 
org.apache.hadoop.fs.s3native.NativeS3FileSystem.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 3 468 484 467 
org.apache.hadoop.yarn.server.resourcemanager.webapp.NavBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 41 
org.apache.hadoop.io.MapFile$Reader.readIndex()V 1 469 
org.apache.hadoop.io.MapFile$Reader.binarySearch(Lorg/apache/hadoop/io/WritableComparable;)I 1 649 
org.apache.hadoop.conf.Configuration.handleDeprecation(Ljava/lang/String;)[Ljava/lang/String; 2 433 442 
org.apache.hadoop.conf.Configuration.getProps()Ljava/util/Properties; 1 1741 
org.apache.hadoop.conf.Configuration.substituteVars(Ljava/lang/String;)Ljava/lang/String; 1 662 
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKStore$ZKRMState.getAppInfo(Ljava/lang/String;)Lorg/apache/hadoop/yarn/server/resourcemanager/recovery/Store$ApplicationInfo; 1 439 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor$BlockQueue.poll(I)Ljava/util/List; 1 88 
org.apache.hadoop.mapred.QueueManager.getJobQueueInfos()[Lorg/apache/hadoop/mapred/JobQueueInfo; 1 408 
org.apache.hadoop.record.compiler.generated.SimpleCharStream.adjustBeginLineColumn(II)V 2 418 433 
org.apache.hadoop.metrics.spi.Util.parse(Ljava/lang/String;I)Ljava/util/List; 1 59 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.getCapacity()J 1 835 
org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.readFields(Ljava/io/DataInput;)V 1 66 
org.apache.hadoop.mapreduce.lib.partition.InputSampler$RandomSampler.getSample(Lorg/apache/hadoop/mapreduce/InputFormat;Lorg/apache/hadoop/mapreduce/Job;)[Ljava/lang/Object; 3 206 222 215 
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.readFields(Ljava/io/DataInput;)V 2 283 280 
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.removeExpiredToken()V 1 359 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processINodesUC(Ljava/io/DataInputStream;Lorg/apache/hadoop/hdfs/tools/offlineImageViewer/ImageVisitor;Z)V 2 282 263 
org.apache.hadoop.io.ArrayPrimitiveWritable.readIntArray(Ljava/io/DataInput;)V 1 324 
org.apache.hadoop.mapred.ClientServiceDelegate.getTaskDiagnostics(Lorg/apache/hadoop/mapreduce/TaskAttemptID;)[Ljava/lang/String; 1 374 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsJobsBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 70 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.releaseBackupStream(Lorg/apache/hadoop/hdfs/server/protocol/NamenodeRegistration;)V 1 983 
org.apache.hadoop.fs.GlobPattern.set(Ljava/lang/String;)V 1 81 
org.apache.hadoop.hdfs.web.JsonUtil.toTokenList([Ljava/lang/Object;)Ljava/util/List; 1 139 
org.apache.hadoop.hdfs.web.ParamFilter.containsUpperCase(Ljava/lang/Iterable;)Z 2 64 63 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(Lorg/apache/hadoop/yarn/api/records/Resource;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerNode;)Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSAssignment; 1 523 
org.apache.hadoop.io.compress.BlockDecompressorStream.getCompressedData()I 1 118 
org.apache.hadoop.io.DataInputByteBuffer$Buffer.read([BII)I 1 47 
org.apache.hadoop.fs.FSInputStream.readFully(J[BII)V 1 70 
org.apache.hadoop.fs.FileSystem.globStatus(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)[Lorg/apache/hadoop/fs/FileStatus; 2 1522 1520 
org.apache.hadoop.mapreduce.util.CountersStrings.toEscapedCompactString(Lorg/apache/hadoop/mapreduce/counters/CounterGroupBase;)Ljava/lang/String; 2 112 133 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.allocate(Lorg/apache/hadoop/yarn/api/records/ApplicationAttemptId;Ljava/util/List;Ljava/util/List;)Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/Allocation; 1 231 
org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler$PingChecker.run()V 2 158 151 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogValue.write(Ljava/io/DataOutputStream;)V 3 151 182 168 
org.apache.hadoop.record.Buffer.toString()Ljava/lang/String; 1 230 
org.apache.hadoop.hdfs.server.datanode.BPOfferService.run()V 1 626 
org.apache.hadoop.util.Shell$ShellCommandExecutor.parseExecResult(Ljava/io/BufferedReader;)V 1 334 
org.apache.hadoop.hdfs.tools.offlineEditsViewer.XmlEditsVisitor.printIndents()V 1 165 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.writeApplicationACLs(Ljava/util/Map;)V 1 252 
org.apache.hadoop.metrics.file.FileContext.emitRecord(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/metrics/spi/OutputRecord;)V 2 130 137 
org.apache.hadoop.mapred.join.CompositeInputFormat.compose(Ljava/lang/String;Ljava/lang/Class;[Ljava/lang/String;)Ljava/lang/String; 1 155 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.removeNode(Lorg/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNode;)V 1 691 
org.apache.hadoop.util.bloom.DynamicBloomFilter.addRow()V 1 277 
org.apache.hadoop.util.bloom.BloomFilter.add(Lorg/apache/hadoop/util/bloom/Key;)V 1 125 
org.apache.hadoop.hdfs.tools.DFSck.doWork([Ljava/lang/String;)I 2 255 298 
org.apache.hadoop.hdfs.LeaseRenewer.closeClient(Lorg/apache/hadoop/hdfs/DFSClient;)V 1 364 
org.apache.hadoop.util.Progress.getInternal()F 1 202 
org.apache.hadoop.hdfs.server.namenode.NNStorage.reportErrorOnFile(Ljava/io/File;)V 1 895 
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKStore$ZKRMState.listStoredNodes()Ljava/util/List; 1 388 
org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(Ljava/lang/String;Ljava/lang/String;Ljava/util/List;Lorg/apache/hadoop/hdfs/server/namenode/NNStorage;Z)Lorg/apache/hadoop/io/MD5Hash; 5 227 247 251 259 259 
org.apache.hadoop.hdfs.DFSInputStream.bestNode([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;Ljava/util/AbstractMap;)Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 1043 
org.apache.hadoop.hdfs.DFSInputStream.openInfo()V 1 130 
org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector.<init>(Lorg/apache/hadoop/mapred/join/CompositeRecordReader;I)V 1 167 
org.apache.hadoop.mapred.Queue.isHierarchySameAs(Lorg/apache/hadoop/mapred/Queue;)Z 1 368 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(Ljava/lang/String;Ljava/util/HashMap;JILjava/util/List;)Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 344 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.isGoodTarget(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;JIZLjava/util/List;)Z 1 475 
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getCumulativeRssmem(I)J 1 333 
org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Ljava/util/Collection;)Ljava/util/Collection; 1 89 
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoUnderConstruction.setExpectedLocations([Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)V 1 168 
org.apache.hadoop.mapred.BackupStore.reset()V 1 192 
org.apache.hadoop.hdfs.server.common.Storage.is203LayoutVersion(I)Z 1 970 
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.purge()V 1 360 
org.apache.hadoop.hdfs.server.namenode.NNStorage.setStorageDirectories(Ljava/util/Collection;Ljava/util/Collection;)V 3 271 268 291 
org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager$Monitor.run()V 1 67 
org.apache.hadoop.hdfs.server.datanode.FSDataset.getGenerationStampFromFile([Ljava/io/File;Ljava/io/File;)J 1 965 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.addFalsePositive(Ljava/util/List;)V 1 175 
org.apache.hadoop.io.IOUtils.skipFully(Ljava/io/InputStream;J)V 1 185 
org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionVisitor.finish()V 1 105 
org.apache.hadoop.yarn.webapp.view.TextView.echo([Ljava/lang/Object;)V 1 45 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks.<init>()V 1 88 
org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector.close()V 1 291 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getJobTasks(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/v2/app/webapp/dao/TasksInfo; 1 253 
org.apache.hadoop.conf.Configuration.get(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/String; 1 853 
org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader.nextKeyValue()Z 1 89 
org.apache.hadoop.fs.FileSystem.printStatistics()V 1 2559 
org.apache.hadoop.hdfs.protocol.datatransfer.ReplaceDatanodeOnFailure.get(Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/hdfs/protocol/datatransfer/ReplaceDatanodeOnFailure; 1 97 
org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerLogsPage$ContainersLogsBlock.getContainerLogDirs(Lorg/apache/hadoop/yarn/api/records/ContainerId;Lorg/apache/hadoop/yarn/server/nodemanager/LocalDirsHandlerService;)Ljava/util/List; 1 303 
org.apache.hadoop.record.Utils.fromXMLBuffer(Ljava/lang/String;)Lorg/apache/hadoop/record/Buffer; 1 208 
org.apache.hadoop.metrics.spi.CompositeContext.stopMonitoring()V 1 126 
org.apache.hadoop.hdfs.server.namenode.INodeFile.appendBlocks([Lorg/apache/hadoop/hdfs/server/namenode/INodeFile;I)V 2 125 130 
org.apache.hadoop.metrics.ContextFactory.getAttributeNames()[Ljava/lang/String; 1 87 
org.apache.hadoop.io.ArrayPrimitiveWritable.readFloatArray(Ljava/io/DataInput;)V 1 336 
org.apache.hadoop.io.SequenceFile$Metadata.toString()Ljava/lang/String; 1 800 
org.apache.hadoop.yarn.server.resourcemanager.NodesListManager.printConfiguredHosts()V 2 82 85 
org.apache.hadoop.hdfs.protocol.LocatedBlocks.insertRange(ILjava/util/List;)V 1 144 
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessList()Ljava/util/List; 1 376 
org.apache.hadoop.http.HtmlQuoting.unquoteHtmlChars(Ljava/lang/String;)Ljava/lang/String; 1 165 
org.apache.hadoop.metrics.spi.CompositeContext$MetricsRecordDelegator.invoke(Ljava/lang/Object;Ljava/lang/reflect/Method;[Ljava/lang/Object;)Ljava/lang/Object; 1 194 
org.apache.hadoop.io.DataOutputByteBuffer$Buffer.reset()V 1 96 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.checkDirs()Ljava/util/List; 2 877 896 
org.apache.hadoop.mapred.TaskReport.setRunningTaskAttempts(Ljava/util/Collection;)V 1 119 
org.apache.hadoop.io.file.tfile.Utils.upperBound(Ljava/util/List;Ljava/lang/Object;)I 1 511 
org.apache.hadoop.yarn.service.CompositeService.start()V 1 66 
org.apache.hadoop.fs.shell.CommandFormat.<init>(II[Ljava/lang/String;)V 1 58 
org.apache.hadoop.fs.shell.CommandFormat.parse(Ljava/util/List;)V 1 88 
org.apache.hadoop.hdfs.DFSInputStream.read(J[BII)I 1 851 
org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.startContainer(Lorg/apache/hadoop/yarn/api/protocolrecords/StartContainerRequest;)Lorg/apache/hadoop/yarn/api/protocolrecords/StartContainerResponse; 1 406 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks$BlockIterator.update()V 1 349 
org.apache.hadoop.mapred.JobQueueClient.printJobQueueInfo(Lorg/apache/hadoop/mapred/JobQueueInfo;Ljava/io/Writer;Ljava/lang/String;)V 1 137 
org.apache.hadoop.mapred.Queue.getJobQueueInfo()Lorg/apache/hadoop/mapred/JobQueueInfo; 2 309 317 
org.apache.hadoop.hdfs.DFSUtil.byteArray2String([[B)Ljava/lang/String; 1 209 
org.apache.hadoop.record.compiler.generated.Rcc.ModuleName()Ljava/lang/String; 1 208 
org.apache.hadoop.mapreduce.lib.join.TupleWritable.write(Ljava/io/DataOutput;)V 2 173 176 
org.apache.hadoop.yarn.webapp.view.JQueryUI.initDataTables(Ljava/util/List;)V 1 130 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.listCorruptFileBlocks(Ljava/lang/String;Ljava/lang/String;)Ljava/util/Collection; 1 4037 
org.apache.hadoop.metrics2.impl.MetricsRecordImpl.context()Ljava/lang/String; 1 72 
org.apache.hadoop.mapreduce.tools.CLI.listEvents(Lorg/apache/hadoop/mapreduce/Job;II)V 1 469 
org.apache.hadoop.security.SaslRpcClient$SaslClientCallbackHandler.handle([Ljavax/security/auth/callback/Callback;)V 1 247 
org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue()V 1 103 
org.apache.hadoop.hdfs.DFSUtil.getNameServiceIdFromAddress(Lorg/apache/hadoop/conf/Configuration;Ljava/net/InetSocketAddress;[Ljava/lang/String;)Ljava/lang/String; 2 491 490 
org.apache.hadoop.io.file.tfile.BCFile$DataIndex.write(Ljava/io/DataOutput;)V 1 898 
org.apache.hadoop.hdfs.protocol.BlockListAsLongs.<init>(Ljava/util/List;Ljava/util/List;)V 2 101 109 
org.apache.hadoop.fs.FileSystem.processDeleteOnExit()V 1 1251 
org.apache.hadoop.mapreduce.tools.CLI.displayTasks(Lorg/apache/hadoop/mapreduce/Job;Ljava/lang/String;Ljava/lang/String;)V 1 554 
org.apache.hadoop.ipc.AvroRpcEngine$BufferListWritable.readFields(Ljava/io/DataInput;)V 1 84 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper$NamenodeMXBeanHelper.getLiveNodeStatus(Ljava/util/Map;Ljava/lang/String;Ljava/lang/String;)V 1 391 
org.apache.hadoop.util.bloom.CountingBloomFilter.delete(Lorg/apache/hadoop/util/bloom/Key;)V 1 146 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobFileInfo(Ljava/util/List;Lorg/apache/hadoop/mapreduce/v2/api/records/JobId;)Lorg/apache/hadoop/mapreduce/v2/hs/HistoryFileManager$HistoryFileInfo; 1 668 
org.apache.hadoop.io.ArrayPrimitiveWritable.readBooleanArray(Ljava/io/DataInput;)V 1 302 
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.sanitizeEnv(Ljava/util/Map;Lorg/apache/hadoop/fs/Path;Ljava/util/List;)V 1 537 
org.apache.hadoop.io.DefaultStringifier.storeArray(Lorg/apache/hadoop/conf/Configuration;[Ljava/lang/Object;Ljava/lang/String;)V 1 161 
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl.initCommands()V 1 160 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.assignInitialVerificationTimes()Z 3 526 524 573 
org.apache.hadoop.conf.Configuration.loadResources(Ljava/util/Properties;Ljava/util/ArrayList;Z)V 2 1792 1802 
org.apache.hadoop.conf.Configuration.getRaw(Ljava/lang/String;)Ljava/lang/String; 1 745 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.createLocatedBlockList([Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;JJILorg/apache/hadoop/hdfs/security/token/block/BlockTokenSecretManager$AccessMode;)Ljava/util/List; 2 541 556 
org.apache.hadoop.mapred.BackupStore.mark()V 1 155 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.addBlockPool(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)V 1 918 
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.readFields(Ljava/io/DataInput;)V 1 234 
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoUnderConstruction.getExpectedLocations()[Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 180 
org.apache.hadoop.yarn.server.nodemanager.webapp.AllContainersPage$AllContainersBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 84 
org.apache.hadoop.util.hash.JenkinsHash.hash([BII)I 1 90 
org.apache.hadoop.fs.FileUtil.copyMerge(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;ZLorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)Z 1 290 
org.apache.hadoop.util.bloom.CountingBloomFilter.and(Lorg/apache/hadoop/util/bloom/Filter;)V 1 173 
org.apache.hadoop.record.compiler.generated.ParseException.add_escapes(Ljava/lang/String;)Ljava/lang/String; 1 176 
org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(Ljava/io/DataOutputStream;Ljava/io/DataInputStream;Ljava/io/DataOutputStream;Ljava/lang/String;Lorg/apache/hadoop/hdfs/util/DataTransferThrottler;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)V 1 749 
org.apache.hadoop.mapred.JobConf.deleteLocalFiles(Ljava/lang/String;)V 1 477 
org.apache.hadoop.mapred.TaskReport.downgradeArray([Lorg/apache/hadoop/mapreduce/TaskReport;)[Lorg/apache/hadoop/mapred/TaskReport; 1 87 
org.apache.hadoop.hdfs.tools.GetConf.<clinit>()V 1 119 
org.apache.hadoop.util.Shell$1.run()V 1 171 
org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenRenewer.run()V 1 156 
org.apache.hadoop.util.StringUtils.toStartupShutdownString(Ljava/lang/String;[Ljava/lang/String;)Ljava/lang/String; 1 581 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.getListing(Ljava/lang/String;[BZ)Lorg/apache/hadoop/hdfs/protocol/DirectoryListing; 1 1276 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.write([BII)V 1 868 
org.apache.hadoop.util.StringUtils.escapeString(Ljava/lang/String;C[C)Ljava/lang/String; 1 499 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.findBackupJournalAndStream(Lorg/apache/hadoop/hdfs/server/protocol/NamenodeRegistration;)Lorg/apache/hadoop/hdfs/server/namenode/FSEditLog$JournalAndStream; 1 1001 
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager$ExpiredTokenRemover.run()V 1 393 
org.apache.hadoop.ipc.Client$Connection.run()V 1 753 
org.apache.hadoop.mapred.IndexCache.freeIndexInformation()V 1 179 
org.apache.hadoop.util.StringUtils.split(Ljava/lang/String;CC)[Ljava/lang/String; 2 387 395 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printCounters(Ljava/lang/StringBuffer;Lorg/apache/hadoop/mapreduce/Counters;Lorg/apache/hadoop/mapreduce/Counters;Lorg/apache/hadoop/mapreduce/Counters;)V 2 180 172 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration.setAcls(Ljava/lang/String;Ljava/util/Map;)V 1 257 
org.apache.hadoop.hdfs.web.resources.EnumSetParam$Domain.parse(Ljava/lang/String;)Ljava/util/EnumSet; 1 76 
org.apache.hadoop.conf.ReconfigurationUtil.getChangedProperties(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/conf/Configuration;)Ljava/util/Collection; 2 44 56 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.TaskInfo.getSuccessfulAttempt(Lorg/apache/hadoop/mapreduce/v2/app/job/Task;)Lorg/apache/hadoop/mapreduce/v2/app/job/TaskAttempt; 1 115 
org.apache.hadoop.mapred.join.MultiFilterRecordReader.createValue()Lorg/apache/hadoop/io/Writable; 1 99 
org.apache.hadoop.util.StringUtils.getStringCollection(Ljava/lang/String;)Ljava/util/Collection; 1 329 
org.apache.hadoop.mapreduce.lib.join.TupleWritable.writeBitSet(Ljava/io/DataOutput;ILjava/util/BitSet;)V 3 249 264 257 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory()V 1 587 
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$3.run()Ljava/lang/Boolean; 1 444 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.printBlockReport(Ljava/lang/StringBuilder;Z)V 1 696 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handleDestroyApplicationResources(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/Application;)V 1 418 
org.apache.hadoop.fs.FsShell.printInfo(Ljava/io/PrintStream;Ljava/lang/String;Z)V 2 197 206 
org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.listCorruptFileBlocks()V 1 233 
org.apache.hadoop.hdfs.ByteRangeInputStream.contains(Ljava/util/Map;Ljava/lang/String;Ljava/lang/String;)Z 2 164 162 
org.apache.hadoop.hdfs.server.datanode.DataNode.parseArguments([Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Z 1 1713 
org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.nextKeyValue()Z 1 69 
org.apache.hadoop.io.MapFile$Reader.finalKey(Lorg/apache/hadoop/io/WritableComparable;)V 1 544 
org.apache.hadoop.fs.FileUtil.copy(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/FileStatus;Ljava/io/File;ZLorg/apache/hadoop/conf/Configuration;)Z 1 372 
org.apache.hadoop.util.StringUtils.join(Ljava/lang/CharSequence;Ljava/lang/Iterable;)Ljava/lang/String; 1 769 
org.apache.hadoop.yarn.util.Apps.setEnvFromInputString(Ljava/util/Map;Ljava/lang/String;)V 1 68 
org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorCombiner.reduce(Lorg/apache/hadoop/io/Text;Ljava/util/Iterator;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 2 62 67 
org.apache.hadoop.io.WritableUtils.writeVLong(Ljava/io/DataOutput;J)V 2 284 293 
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getCumulativeCpuTime()J 1 353 
org.apache.hadoop.fs.FileSystem.globPathsLevel([Lorg/apache/hadoop/fs/Path;[Ljava/lang/String;I[Z)[Lorg/apache/hadoop/fs/Path; 1 1624 
org.apache.hadoop.io.WritableUtils.readVLong(Ljava/io/DataInput;)J 1 314 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getLiveNodes()Ljava/lang/String; 1 4368 
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp.readBlocks(Ljava/io/DataInputStream;I)[Lorg/apache/hadoop/hdfs/protocol/Block; 1 290 
org.apache.hadoop.ipc.WritableRpcEngine$Invocation.write(Ljava/io/DataOutput;)V 1 140 
org.apache.hadoop.fs.AbstractFileSystem.create(Lorg/apache/hadoop/fs/Path;Ljava/util/EnumSet;[Lorg/apache/hadoop/fs/Options$CreateOpts;)Lorg/apache/hadoop/fs/FSDataOutputStream; 1 474 
org.apache.hadoop.hdfs.server.datanode.BlockReceiver.checksum2long([B)J 1 831 
org.apache.hadoop.yarn.state.StateMachineFactory.addTransition(Ljava/lang/Enum;Ljava/lang/Enum;Ljava/util/Set;Lorg/apache/hadoop/yarn/state/SingleArcTransition;)Lorg/apache/hadoop/yarn/state/StateMachineFactory; 1 200 
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfoUnderConstruction.addReplicaIfNotPresent(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/protocol/Block;Lorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$ReplicaState;)V 1 253 
org.apache.hadoop.yarn.util.AbstractLivelinessMonitor$PingChecker.run()V 2 106 98 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector.<init>(Lorg/apache/hadoop/mapreduce/lib/join/CompositeRecordReader;I)V 1 200 
org.apache.hadoop.hdfs.server.datanode.RoundRobinVolumesPolicy.chooseVolume(Ljava/util/List;J)Lorg/apache/hadoop/hdfs/server/datanode/FSDatasetInterface$FSVolumeInterface; 1 47 
org.apache.hadoop.security.NetgroupCache.add(Ljava/lang/String;Ljava/util/List;)V 1 116 
org.apache.hadoop.mapreduce.QueueState.<clinit>()V 1 39 
org.apache.hadoop.mapred.JobQueueInfo.getChildren()Ljava/util/List; 1 105 
org.apache.hadoop.record.compiler.CodeBuffer.append(Ljava/lang/String;)V 1 70 
org.apache.hadoop.fs.FileUtil.unZip(Ljava/io/File;Ljava/io/File;)V 2 533 517 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(Lorg/apache/hadoop/yarn/api/records/Resource;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerNode;)Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSAssignment; 1 611 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues0(II)V 3 998 1008 993 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues1(II)I 11 1043 1040 1070 1088 1094 1092 1105 1121 1050 1131 1039 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues2(II)V 3 1145 1154 1149 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues3(II)V 2 1174 1170 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues5(II)V 4 1249 1247 1259 1246 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues6(II)V 8 1285 1297 1295 1310 1308 1322 1293 1280 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.sendMTFValues7(I)V 3 1363 1356 1350 
org.apache.hadoop.hdfs.server.namenode.NNStorage.reportErrorsOnDirectories(Ljava/util/List;)V 1 815 
org.apache.hadoop.hdfs.protocol.LocatedBlocks.readFields(Ljava/io/DataInput;)V 1 221 
org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.compose(Ljava/lang/String;Ljava/lang/Class;[Lorg/apache/hadoop/fs/Path;)Ljava/lang/String; 1 182 
org.apache.hadoop.mapreduce.filecache.DistributedCache.checkURIs([Ljava/net/URI;[Ljava/net/URI;)Z 2 453 468 
org.apache.hadoop.fs.shell.CopyCommands$Merge.processArguments(Ljava/util/LinkedList;)V 1 84 
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getClusterNodes(Lorg/apache/hadoop/yarn/api/protocolrecords/GetClusterNodesRequest;)Lorg/apache/hadoop/yarn/api/protocolrecords/GetClusterNodesResponse; 1 369 
org.apache.hadoop.util.StringUtils.hasChar([CC)Z 1 482 
org.apache.hadoop.metrics2.lib.MetricsSourceBuilder.<init>(Ljava/lang/Object;Lorg/apache/hadoop/metrics2/lib/MutableMetricsFactory;)V 2 57 60 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.scheduleTasks(Ljava/util/Set;)V 1 650 
org.apache.hadoop.util.StringUtils.findNext(Ljava/lang/String;CCILjava/lang/StringBuilder;)I 1 443 
org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.findNewDatanode([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)I 2 784 782 
org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.toList(Ljava/util/LinkedList;)Ljava/util/List; 1 83 
org.apache.hadoop.hdfs.util.LightWeightGSet$SetIterator.nextNonemptyEntry()Lorg/apache/hadoop/hdfs/util/LightWeightGSet$LinkedElement; 1 256 
org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.write(Ljava/io/DataOutput;)V 1 152 
org.apache.hadoop.conf.Configuration.getLocalPath(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/fs/Path; 2 1633 1643 
org.apache.hadoop.fs.FsShell.printInstanceHelp(Ljava/io/PrintStream;Lorg/apache/hadoop/fs/shell/Command;)V 1 224 
org.apache.hadoop.mapreduce.lib.join.TupleWritable.readFields(Ljava/io/DataInput;)V 2 193 196 
org.apache.hadoop.hdfs.tools.offlineImageViewer.IndentedImageVisitor.printIndents()V 1 106 
org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks.dump(Ljava/io/PrintWriter;)V 1 112 
org.apache.hadoop.hdfs.web.JsonUtil.toJsonArray(Ljava/util/List;)[Ljava/lang/Object; 1 399 
org.apache.hadoop.hdfs.server.balancer.BalancingPolicy.parse(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/balancer/BalancingPolicy; 1 67 
org.apache.hadoop.fs.FileSystem.listStatus([Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)[Lorg/apache/hadoop/fs/FileStatus; 1 1431 
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices.getNodes(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/yarn/server/resourcemanager/webapp/dao/NodesInfo; 1 179 
org.apache.hadoop.mapreduce.lib.chain.Chain.joinAllThreads()V 1 516 
org.apache.hadoop.hdfs.server.namenode.LeaseManager.findLeaseWithPrefixPath(Ljava/lang/String;Ljava/util/SortedMap;)Ljava/util/List; 1 344 
org.apache.hadoop.hdfs.server.common.UpgradeObjectCollection.getDistributedUpgrades(ILorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$NodeType;)Ljava/util/SortedSet; 1 119 
org.apache.hadoop.io.WritableUtils.skipFully(Ljava/io/DataInput;I)V 1 405 
org.apache.hadoop.mapred.SortedRanges.toString()Ljava/lang/String; 1 212 
org.apache.hadoop.mapreduce.util.LinuxResourceCalculatorPlugin.readProcCpuInfoFile()V 1 226 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(Lorg/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNode;Ljava/util/List;Ljava/util/List;)V 2 554 559 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.updateClusterResource(Lorg/apache/hadoop/yarn/api/records/Resource;)V 1 701 
org.apache.hadoop.hdfs.server.datanode.BlockReceiver.readNextPacket()V 2 449 492 
org.apache.hadoop.fs.FileContext.processDeleteOnExit()V 2 265 262 
org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey()Z 1 114 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper$NamenodeMXBeanHelper.getDeadNodeStatus(Ljava/util/Map;Ljava/lang/String;Ljava/lang/String;)V 1 432 
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster$LaunchContainerRunnable.run()V 1 702 
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.init([Ljava/lang/String;)Z 1 322 
org.apache.hadoop.record.compiler.generated.Rcc.ReInit(Ljava/io/Reader;)V 1 440 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector.flush(Lorg/apache/hadoop/mapreduce/lib/join/TupleWritable;)Z 1 334 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.fillJoinCollector(Lorg/apache/hadoop/io/WritableComparable;)V 1 423 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector.reset(Lorg/apache/hadoop/io/WritableComparable;)V 1 229 
org.apache.hadoop.fs.s3.INode.serialize()Ljava/io/InputStream; 1 90 
org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileServer(Ljava/io/OutputStream;Ljava/io/File;Lorg/apache/hadoop/hdfs/util/DataTransferThrottler;)V 1 148 
org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector.flush(Lorg/apache/hadoop/mapred/join/TupleWritable;)Z 1 301 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.internalReleaseLease(Lorg/apache/hadoop/hdfs/server/namenode/LeaseManager$Lease;Ljava/lang/String;Ljava/lang/String;)Z 1 2189 
org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.write(Ljava/io/OutputStream;)V 3 639 646 644 
org.apache.hadoop.hdfs.DFSInputStream.getFinalizedBlockRange(JJ)Ljava/util/List; 1 351 
org.apache.hadoop.io.ArrayPrimitiveWritable.readLongArray(Ljava/io/DataInput;)V 1 330 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkFileProgress(Lorg/apache/hadoop/hdfs/server/namenode/INodeFile;Z)Z 1 1754 
org.apache.hadoop.fs.TrashPolicyDefault.moveToTrash(Lorg/apache/hadoop/fs/Path;)Z 2 138 122 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.allocateBlock(Ljava/lang/String;[Lorg/apache/hadoop/hdfs/server/namenode/INode;[Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)Lorg/apache/hadoop/hdfs/protocol/Block; 1 1732 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.shutdown()V 1 705 
org.apache.hadoop.io.serializer.avro.AvroReflectSerialization.getPackages()V 1 69 
org.apache.hadoop.mapreduce.lib.join.Parser$CNode.toString()Ljava/lang/String; 1 510 
org.apache.hadoop.metrics2.lib.MetricsRegistry.snapshot(Lorg/apache/hadoop/metrics2/MetricsRecordBuilder;Z)V 2 365 368 
org.apache.hadoop.fs.AbstractFileSystem.isValidName(Ljava/lang/String;)Z 1 94 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem$SafeModeMonitor.run()V 1 3265 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$PublicLocalizer.run()V 1 640 
org.apache.hadoop.io.IOUtils.cleanup(Lorg/apache/commons/logging/Log;[Ljava/io/Closeable;)V 1 209 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.initialize(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)V 1 99 
org.apache.hadoop.hdfs.server.datanode.FSDatasetAsyncDiskService.<init>([Ljava/io/File;)V 1 76 
org.apache.hadoop.ipc.Server$Responder.doRunLoop()V 4 692 687 721 730 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkReplicationFactor(Lorg/apache/hadoop/hdfs/server/namenode/INodeFile;)V 1 1714 
org.apache.hadoop.mapreduce.Job.getTaskFailureEventString()Ljava/lang/String; 1 497 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskCounterInfo.<init>(Lorg/apache/hadoop/mapreduce/v2/app/job/Task;)V 1 51 
org.apache.hadoop.conf.Configuration.loadResource(Ljava/util/Properties;Lorg/apache/hadoop/conf/Configuration$Resource;Z)Lorg/apache/hadoop/conf/Configuration$Resource; 3 1913 1934 1897 
org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream.<clinit>()V 1 52 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(Ljava/lang/String;Ljava/lang/String;[Lorg/apache/hadoop/fs/Options$Rename;)V 1 1871 
org.apache.hadoop.mapred.lib.db.DBInputFormat.getSplits(Lorg/apache/hadoop/mapred/JobConf;I)[Lorg/apache/hadoop/mapred/InputSplit; 1 172 
org.apache.hadoop.fs.FileUtil.copy(Lorg/apache/hadoop/fs/FileSystem;[Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;ZZLorg/apache/hadoop/conf/Configuration;)Z 1 209 
org.apache.hadoop.hdfs.server.datanode.DataStorage.finalizeUpgrade(Ljava/lang/String;)V 1 614 
org.apache.hadoop.io.MD5Hash.toString()Ljava/lang/String; 1 201 
org.apache.hadoop.mapred.FileInputFormat.getSplitHosts([Lorg/apache/hadoop/fs/BlockLocation;JJLorg/apache/hadoop/net/NetworkTopology;)[Ljava/lang/String; 3 496 538 512 
org.apache.hadoop.metrics2.source.JvmMetrics.getGcUsage(Lorg/apache/hadoop/metrics2/MetricsRecordBuilder;)V 1 111 
org.apache.hadoop.metrics2.source.JvmMetrics.getThreadUsage(Lorg/apache/hadoop/metrics2/MetricsRecordBuilder;)V 1 142 
org.apache.hadoop.mapred.join.Parser$WNode.parse(Ljava/util/List;Lorg/apache/hadoop/mapred/JobConf;)V 1 283 
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateRequestPBImpl.initReleases()V 1 261 
org.apache.hadoop.net.NetworkTopology.getDistance(Lorg/apache/hadoop/net/Node;Lorg/apache/hadoop/net/Node;)I 3 462 467 472 
org.apache.hadoop.net.DNS.getHosts(Ljava/lang/String;Ljava/lang/String;)[Ljava/lang/String; 1 158 
org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(Ljava/util/List;)Ljava/lang/String; 2 230 226 
org.apache.hadoop.mapred.LocalDistributedCacheManager.makeClassLoader(Ljava/lang/ClassLoader;)Ljava/lang/ClassLoader; 1 229 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader.getContainerLogsReader(Lorg/apache/hadoop/yarn/api/records/ContainerId;)Lorg/apache/hadoop/yarn/logaggregation/AggregatedLogFormat$ContainerLogsReader; 1 406 
org.apache.hadoop.hdfs.server.datanode.BPOfferService.processCommand([Lorg/apache/hadoop/hdfs/server/protocol/DatanodeCommand;)Z 1 655 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stop()V 2 198 206 
org.apache.hadoop.hdfs.web.JsonUtil.toDatanodeInfoArray([Ljava/lang/Object;)[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 350 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.hbMakeCodeLengths([C[III)V 11 226 246 239 265 295 331 255 345 341 357 230 
org.apache.hadoop.ipc.Server.bind(Ljava/net/ServerSocket;Ljava/net/InetSocketAddress;ILorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)V 1 243 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processFullNameINodes(Ljava/io/DataInputStream;Lorg/apache/hadoop/hdfs/tools/offlineImageViewer/ImageVisitor;JZ)V 1 415 
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(Ljava/lang/String;JLorg/apache/hadoop/conf/Configuration;Z)Lorg/apache/hadoop/fs/Path; 4 360 370 367 383 
org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.checkTokenName(Ljava/lang/String;)V 1 151 
org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.getNamedOutputsList(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 1 204 
org.apache.hadoop.util.bloom.DynamicBloomFilter.membershipTest(Lorg/apache/hadoop/util/bloom/Key;)Z 1 180 
org.apache.hadoop.hdfs.tools.offlineEditsViewer.StatisticsEditsVisitor.getStatisticsString()Ljava/lang/String; 1 192 
org.apache.hadoop.record.compiler.JRecord.<init>(Ljava/lang/String;Ljava/util/ArrayList;)V 1 792 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.checkDirTree()V 1 223 
org.apache.hadoop.io.ArrayPrimitiveWritable.writeFloatArray(Ljava/io/DataOutput;)V 1 290 
org.apache.hadoop.fs.shell.FsUsage$TableBuilder.printToStream(Ljava/io/PrintStream;)V 2 232 244 
org.apache.hadoop.mapreduce.counters.AbstractCounters.toString()Ljava/lang/String; 2 326 324 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.normalizeRequests(Ljava/util/List;I)V 1 89 
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.retrieveBlock(Lorg/apache/hadoop/fs/s3/Block;J)Ljava/io/File; 1 221 
org.apache.hadoop.util.HeapSort.sort(Lorg/apache/hadoop/util/IndexedSortable;IILorg/apache/hadoop/util/Progressable;)V 3 64 63 71 
org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl.initKeepAliveApplications()V 1 254 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDecomNodes()Ljava/lang/String; 1 4407 
org.apache.hadoop.hdfs.server.namenode.INodeDirectory.collectSubtreeBlocksAndClear(Ljava/util/List;)I 1 431 
org.apache.hadoop.hdfs.server.balancer.NameNodeConnector$BlockKeyUpdater.run()V 1 225 
org.apache.hadoop.hdfs.DFSInputStream.readBlockLength(Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;)J 1 157 
org.apache.hadoop.record.Utils.toXMLString(Ljava/lang/String;)Ljava/lang/String; 1 54 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogGroup.hasKnownLastTxId()Z 1 310 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run()V 3 882 882 882 
org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.valueOf(C)Lorg/apache/hadoop/util/StringUtils$TraditionalBinaryPrefix; 1 648 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getQueueUserAclInfo(Lorg/apache/hadoop/security/UserGroupInformation;)Ljava/util/List; 1 520 
org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader.createValue()Lorg/apache/hadoop/io/Writable; 1 64 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.waitForSyncToFinish()V 1 928 
org.apache.hadoop.net.SocketOutputStream.transferToFully(Ljava/nio/channels/FileChannel;JI)V 1 192 
org.apache.hadoop.security.SecurityUtil.getKerberosInfo(Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/security/KerberosInfo; 2 346 355 
org.apache.hadoop.metrics2.lib.MetricsSourceBuilder.initRegistry(Ljava/lang/Object;)Lorg/apache/hadoop/metrics2/lib/MetricsRegistry; 2 91 105 
org.apache.hadoop.metrics2.lib.MetricsSourceBuilder.add(Ljava/lang/Object;Ljava/lang/reflect/Field;)V 1 120 
org.apache.hadoop.metrics2.lib.MetricsSourceBuilder.add(Ljava/lang/Object;Ljava/lang/reflect/Method;)V 1 148 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.scan()V 4 350 382 385 334 
org.apache.hadoop.mapred.FileInputFormat.getPathStrings(Ljava/lang/String;)[Ljava/lang/String; 1 399 
org.apache.hadoop.util.StringUtils.stringToPath([Ljava/lang/String;)[Lorg/apache/hadoop/fs/Path; 1 236 
org.apache.hadoop.mapred.FileInputFormat.setInputPaths(Lorg/apache/hadoop/mapred/JobConf;[Lorg/apache/hadoop/fs/Path;)V 1 365 
org.apache.hadoop.mapreduce.v2.app.speculate.StartEndTimesBase.contextualize(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/mapreduce/v2/app/AppContext;)V 1 90 
org.apache.hadoop.yarn.util.VisualizeStateMachine.getGraphFromClasses(Ljava/lang/String;Ljava/util/List;)Lorg/apache/hadoop/yarn/util/Graph; 1 39 
org.apache.hadoop.hdfs.DFSInputStream.fetchBlockByteRange(Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;JJ[BILjava/util/Map;)V 1 659 
org.apache.hadoop.hdfs.DFSInputStream.reportCheckSumFailure(Ljava/util/Map;I)V 1 902 
org.apache.hadoop.security.NetgroupCache.getNetgroups(Ljava/lang/String;Ljava/util/List;)V 3 65 64 75 
org.apache.hadoop.mapred.JobEndNotifier.localRunnerNotification(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/JobStatus;)V 1 146 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start()V 2 178 183 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer.<init>(Lorg/apache/hadoop/mapred/MapTask;Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Task$TaskReporter;)V 1 975 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.shutdown()V 1 930 
org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$MD5Filter.MD5Hashcode([BII)J 1 282 
org.apache.hadoop.mapred.TaskAttemptListenerImpl.getMapCompletionEvents(Lorg/apache/hadoop/mapred/JobID;IILorg/apache/hadoop/mapred/TaskAttemptID;Ljava/lang/String;)Lorg/apache/hadoop/mapred/MapTaskCompletionEventsUpdate; 1 273 
org.apache.hadoop.mapreduce.tools.CLI.printTaskAttempts(Lorg/apache/hadoop/mapreduce/TaskReport;)V 1 536 
org.apache.hadoop.mapreduce.lib.db.TextSplitter.bigDecimalToString(Ljava/math/BigDecimal;)Ljava/lang/String; 1 208 
org.apache.hadoop.net.NetworkTopology.countNumOfAvailableNodes(Ljava/lang/String;Ljava/util/Collection;)I 1 578 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector.createLogLoadPlan(JJ)Lorg/apache/hadoop/hdfs/server/namenode/FSImageTransactionalStorageInspector$LogLoadPlan; 1 218 
org.apache.hadoop.mapred.TaskLog$Reader.<init>(Lorg/apache/hadoop/mapred/TaskAttemptID;Lorg/apache/hadoop/mapred/TaskLog$LogName;JJZ)V 1 341 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper$NamenodeMXBeanHelper.getLiveNodeCount(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/namenode/ClusterJspHelper$NamenodeStatus;)V 1 298 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper$NamenodeMXBeanHelper.getDeadNodeCount(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/namenode/ClusterJspHelper$NamenodeStatus;)V 1 324 
org.apache.hadoop.util.StringUtils.escapeHTML(Ljava/lang/String;)Ljava/lang/String; 1 704 
org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.failAllJobs(Ljava/lang/Throwable;)V 1 270 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.setupQueueConfigs(Lorg/apache/hadoop/yarn/api/records/Resource;FFFFLorg/apache/hadoop/yarn/api/records/QueueState;Ljava/util/Map;)V 1 179 
org.apache.hadoop.conf.Configuration.dumpConfiguration(Lorg/apache/hadoop/conf/Configuration;Ljava/io/Writer;)V 1 2094 
org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService$LogDeletionTask.run()V 1 62 
org.apache.hadoop.yarn.service.AbstractService.changeState(Lorg/apache/hadoop/yarn/service/Service$STATE;)V 1 113 
org.apache.hadoop.fs.permission.PermissionParser.applyNormalPattern(Ljava/lang/String;Ljava/util/regex/Matcher;)V 3 83 107 68 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processReport(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/protocol/BlockListAsLongs;)V 5 1393 1396 1399 1402 1408 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ScanInfoPerBlockPool.toSortedArrays()Ljava/util/Map; 1 137 
org.apache.hadoop.mapreduce.lib.db.TextSplitter.split(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List; 2 103 121 
org.apache.hadoop.metrics.spi.AbstractMetricsContext$TagMap.containsAll(Lorg/apache/hadoop/metrics/spi/AbstractMetricsContext$TagMap;)Z 1 81 
org.apache.hadoop.mapred.JobClient.arrayToStringList([Lorg/apache/hadoop/mapreduce/TaskTrackerInfo;)Ljava/util/Collection; 1 783 
org.apache.hadoop.record.compiler.CodeBuffer.append(C)V 2 82 81 
org.apache.hadoop.conf.Configuration.set(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V 1 787 
org.apache.hadoop.mapred.IndexCache.checkTotalMemoryUsed()Z 1 169 
org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService$LogDeletionTask.deleteOldLogDirsFrom(Lorg/apache/hadoop/fs/Path;JLorg/apache/hadoop/fs/FileSystem;)V 1 78 
org.apache.hadoop.record.compiler.generated.RccTokenManager.jjMoveNfa_0(II)I 4 507 537 566 500 
org.apache.hadoop.fs.FileContext$Util.getContentSummary(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/ContentSummary; 1 1584 
org.apache.hadoop.util.GenericsUtil.toArray(Ljava/lang/Class;Ljava/util/List;)[Ljava/lang/Object; 1 58 
org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.compose(Ljava/lang/String;Ljava/lang/Class;[Ljava/lang/String;)Ljava/lang/String; 1 166 
org.apache.hadoop.io.SequenceFile$Sorter$SortPass.run(Z)I 3 2745 2754 2749 
org.apache.hadoop.http.HttpServer.addFilter(Ljava/lang/String;Ljava/lang/String;Ljava/util/Map;)V 1 457 
org.apache.hadoop.mapred.SortedRanges.add(Lorg/apache/hadoop/mapred/SortedRanges$Range;)V 1 106 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogGroup.recover()V 1 445 
org.apache.hadoop.hdfs.DFSInputStream.readBuffer([BIILjava/util/Map;)I 1 489 
org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl$StatusUpdateWhenHealthyTransition.transition(Lorg/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNodeImpl;Lorg/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNodeEvent;)Lorg/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNodeState; 1 500 
org.apache.hadoop.hdfs.server.namenode.NNStorage.inspectStorageDirs(Lorg/apache/hadoop/hdfs/server/namenode/FSImageStorageInspector;)V 1 1010 
org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager.getImageTxIdToRetain(Lorg/apache/hadoop/hdfs/server/namenode/FSImageTransactionalStorageInspector;)J 1 106 
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl.doAppLogAggregation()V 3 151 166 174 
org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager.purgeCheckpointsOlderThan(Lorg/apache/hadoop/hdfs/server/namenode/FSImageTransactionalStorageInspector;J)V 1 89 
org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys.readFields(Ljava/io/DataInput;)V 1 108 
org.apache.hadoop.mapreduce.counters.AbstractCounters.getGroupNames()Ljava/lang/Iterable; 1 190 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWork(I)I 2 942 941 
org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.stop()V 4 305 316 326 346 
org.apache.hadoop.mapreduce.lib.db.FloatSplitter.split(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List; 1 81 
org.apache.hadoop.mapred.Task$TaskReporter.run()V 1 679 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeInvalidateWork(I)I 1 919 
org.apache.hadoop.mapreduce.task.reduce.MergeManager.finalMerge(Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/fs/FileSystem;Ljava/util/List;Ljava/util/List;)Lorg/apache/hadoop/mapred/RawKeyValueIterator; 1 742 
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.CounterGroupPBImpl.initCounters()V 1 138 
org.apache.hadoop.mapred.join.CompositeRecordReader.createInternalValue()Lorg/apache/hadoop/mapred/join/TupleWritable; 1 427 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(Lorg/apache/hadoop/fs/Path;)V 1 618 
org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.emitToGangliaHosts()V 1 256 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl$KillTransition.transition(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl;Lorg/apache/hadoop/mapreduce/v2/app/job/event/TaskEvent;)V 1 964 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.addFalsePositive(Ljava/util/Collection;)V 1 161 
org.apache.hadoop.yarn.applications.distributedshell.Client.init([Ljava/lang/String;)Z 1 290 
org.apache.hadoop.yarn.applications.distributedshell.Client.run()Z 5 344 367 366 546 558 
org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.setConf(Lorg/apache/hadoop/conf/Configuration;)V 1 94 
org.apache.hadoop.fs.s3.MigrationTool.migrate(Lorg/apache/hadoop/fs/s3/MigrationTool$Store;Lorg/apache/hadoop/fs/s3/FileSystemStore;)V 1 170 
org.apache.hadoop.hdfs.server.namenode.FSEditLogOpCodes.<clinit>()V 1 85 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getJobTaskAttempts(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/v2/app/webapp/dao/TaskAttemptsInfo; 1 312 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.preemptReducesIfNeeded()V 1 383 
org.apache.hadoop.ipc.Server.channelIO(Ljava/nio/channels/ReadableByteChannel;Ljava/nio/channels/WritableByteChannel;Ljava/nio/ByteBuffer;)I 1 1949 
org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.setTableStyles(Lorg/apache/hadoop/yarn/webapp/hamlet/Hamlet$HTML;Ljava/lang/String;[Ljava/lang/String;)V 1 128 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.isAnyProcessInTreeAlive()Z 1 262 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.updateResourceRequests(Ljava/util/List;)V 1 129 
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl.initRunningAttempts()V 1 221 
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.write(Ljava/io/DataOutput;)V 1 220 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker.stop()V 1 499 
org.apache.hadoop.security.UserGroupInformation$1.run()V 1 580 
org.apache.hadoop.metrics.spi.AbstractMetricsContext.remove(Lorg/apache/hadoop/metrics/spi/MetricsRecordImpl;)V 1 440 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.init()V 2 208 220 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobCounterInfo.<init>(Lorg/apache/hadoop/mapreduce/v2/app/AppContext;Lorg/apache/hadoop/mapreduce/v2/app/job/Job;)V 1 59 
org.apache.hadoop.mapred.TaskAttemptListenerImpl.statusUpdate(Lorg/apache/hadoop/mapred/TaskAttemptID;Lorg/apache/hadoop/mapred/TaskStatus;Ljava/lang/String;)Z 1 359 
org.apache.hadoop.conf.Configuration$IntegerRanges.toString()Ljava/lang/String; 1 1265 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.main([Ljava/lang/String;)V 1 347 
org.apache.hadoop.mapred.StatisticsCollector$Stat.inc(I)V 1 192 
org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses()Ljava/lang/String; 1 2165 
org.apache.hadoop.mapreduce.tools.CLI.getJobPriorityNames()Ljava/lang/String; 1 366 
org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.write(Ljava/io/DataOutput;)V 1 160 
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.listCorruptFileBlocks(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/hdfs/protocol/CorruptFileBlocks; 1 678 
org.apache.hadoop.hdfs.server.datanode.DataNode.getDataDirsFromURIs(Ljava/util/Collection;Lorg/apache/hadoop/fs/LocalFileSystem;Lorg/apache/hadoop/fs/permission/FsPermission;)Ljava/util/ArrayList; 1 1667 
org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown()V 2 1105 1137 
org.apache.hadoop.mapred.Task.getFsStatistics(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;)Ljava/util/List; 1 334 
org.apache.hadoop.mapred.MapTask$DirectMapOutputCollector.getOutputBytes(Ljava/util/List;)J 1 806 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.reportDiff(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/protocol/BlockListAsLongs;Ljava/util/Collection;Ljava/util/Collection;Ljava/util/Collection;Ljava/util/Collection;Ljava/util/Collection;)V 2 1476 1489 
org.apache.hadoop.security.SaslRpcServer$SaslGssCallbackHandler.handle([Ljavax/security/auth/callback/Callback;)V 1 261 
org.apache.hadoop.io.IOUtils.copyBytes(Ljava/io/InputStream;Ljava/io/OutputStream;I)V 1 76 
org.apache.hadoop.fs.s3.S3FileSystem.mkdirs(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/permission/FsPermission;)Z 2 134 139 
org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.removeDelegationTokenRenewalForJob(Lorg/apache/hadoop/mapreduce/JobID;)V 1 300 
org.apache.hadoop.hdfs.server.datanode.DataNode.join()V 1 1623 
org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlock(Lorg/apache/hadoop/hdfs/DFSClient;Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;Ljava/io/OutputStream;)V 2 489 540 
org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getMetrics(Lorg/apache/hadoop/metrics2/impl/MetricsCollectorImpl;Z)Ljava/lang/Iterable; 2 198 197 
org.apache.hadoop.yarn.event.AsyncDispatcher$MultiListenerHandler.handle(Lorg/apache/hadoop/yarn/event/Event;)V 1 203 
org.apache.hadoop.conf.Configuration.overlay(Ljava/util/Properties;Ljava/util/Properties;)V 1 1968 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader.getApplicationAcls()Ljava/util/Map; 2 345 336 
org.apache.hadoop.hdfs.tools.offlineEditsViewer.XmlTokenizer.getNextElementsValue(Ljava/lang/String;)Ljava/lang/String; 1 74 
org.apache.hadoop.hdfs.server.datanode.BlockReceiver.verifyChunks([BII[BI)V 1 324 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.addBlock(Lorg/apache/hadoop/hdfs/protocol/Block;Ljava/io/File;ZZ)Ljava/io/File; 2 146 163 
org.apache.hadoop.hdfs.server.datanode.DataNode$2.run()V 1 1787 
org.apache.hadoop.ipc.Server$Connection.processUnwrappedData([B)V 1 1372 
org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob.setAggregatorDescriptors([Ljava/lang/Class;)Lorg/apache/hadoop/conf/Configuration; 1 202 
org.apache.hadoop.hdfs.server.datanode.DataNode.isDatanodeFullyStarted()Z 1 2245 
org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run()V 1 227 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.saveFilesUnderConstruction(Ljava/io/DataOutputStream;)V 2 3920 3919 
org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices.getAppAttempts(Ljava/lang/String;)Lorg/apache/hadoop/yarn/server/resourcemanager/webapp/dao/AppAttemptsInfo; 1 411 
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getAllApplications(Lorg/apache/hadoop/yarn/api/protocolrecords/GetAllApplicationsRequest;)Lorg/apache/hadoop/yarn/api/protocolrecords/GetAllApplicationsResponse; 1 350 
org.apache.hadoop.mapred.join.InnerJoinRecordReader.combine([Ljava/lang/Object;Lorg/apache/hadoop/mapred/join/TupleWritable;)Z 1 47 
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.CountersPBImpl.initCounterGroups()V 1 128 
org.apache.hadoop.yarn.security.ApplicationTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 43 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.rampUpReduces(I)V 1 511 
org.apache.hadoop.mapred.QueueManager.getQueueAcls(Lorg/apache/hadoop/security/UserGroupInformation;)[Lorg/apache/hadoop/mapred/QueueAclsInfo; 2 469 466 
org.apache.hadoop.hdfs.server.blockmanagement.CorruptReplicasMap.getCorruptReplicaBlockIds(ILjava/lang/Long;)[J 3 172 188 193 
org.apache.hadoop.metrics.spi.AbstractMetricsContext.update(Lorg/apache/hadoop/metrics/spi/MetricsRecordImpl;)V 1 380 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(Lorg/apache/hadoop/yarn/api/records/Resource;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerNode;)Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSAssignment; 2 776 766 
org.apache.hadoop.io.Text.find(Ljava/lang/String;I)I 2 160 166 
org.apache.hadoop.fs.FileSystem$5.hasNext()Z 1 1728 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPaths(Lorg/apache/hadoop/mapreduce/Job;Ljava/lang/String;)V 1 354 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processOverReplicatedBlocksOnReCommission(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)V 1 2313 
org.apache.hadoop.record.compiler.generated.Rcc.ReInit(Ljava/io/InputStream;Ljava/lang/String;)V 1 422 
org.apache.hadoop.yarn.server.nodemanager.util.ProcessIdFileReader.getProcessId(Lorg/apache/hadoop/fs/Path;)Ljava/lang/String; 1 59 
org.apache.hadoop.fs.permission.FsPermission.valueOf(Ljava/lang/String;)Lorg/apache/hadoop/fs/permission/FsPermission; 1 285 
org.apache.hadoop.yarn.api.records.impl.pb.AMResponsePBImpl.initLocalNewContainerList()V 1 160 
org.apache.hadoop.ipc.AvroRpcEngine$BufferListWritable.write(Ljava/io/DataOutput;)V 1 94 
org.apache.hadoop.fs.FileUtil.getDU(Ljava/io/File;)J 1 488 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.replaceNode(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/namenode/INodeFile;Lorg/apache/hadoop/hdfs/server/namenode/INodeFile;)V 1 1237 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.updateClusterResource(Lorg/apache/hadoop/yarn/api/records/Resource;)V 1 1409 
org.apache.hadoop.hdfs.server.namenode.ListPathsServlet$2.run()Ljava/lang/Void; 4 153 181 170 164 
org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.list(Ljava/lang/String;Ljava/lang/String;ILjava/lang/String;)Lorg/apache/hadoop/fs/s3native/PartialListing; 1 165 
org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.removeExpiredKeys()V 1 183 
org.apache.hadoop.io.file.tfile.Utils.upperBound(Ljava/util/List;Ljava/lang/Object;Ljava/util/Comparator;)I 1 453 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.write(Ljava/io/DataOutput;)V 5 413 410 420 417 424 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector.replay(Lorg/apache/hadoop/mapreduce/lib/join/TupleWritable;)Z 1 311 
org.apache.hadoop.mapreduce.lib.reduce.LongSumReducer.reduce(Ljava/lang/Object;Ljava/lang/Iterable;Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 1 38 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getNumDeadDataNodes()I 1 720 
org.apache.hadoop.mapred.lib.FieldSelectionMapReduce.specToString()Ljava/lang/String; 4 116 121 127 132 
org.apache.hadoop.mapreduce.QueueInfo.readFields(Ljava/io/DataInput;)V 2 198 204 
org.apache.hadoop.fs.ChecksumFs.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 493 
org.apache.hadoop.hdfs.web.JsonUtil.toLocatedBlockList([Ljava/lang/Object;)Ljava/util/List; 1 415 
org.apache.hadoop.fs.FileSystem.rename(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;[Lorg/apache/hadoop/fs/Options$Rename;)V 1 1144 
org.apache.hadoop.hdfs.server.namenode.FSImage.finalizeUpgrade()V 1 536 
org.apache.hadoop.mapred.JobACLsManager.constructJobACLs(Lorg/apache/hadoop/conf/Configuration;)Ljava/util/Map; 1 66 
org.apache.hadoop.mapreduce.counters.AbstractCounters.write(Ljava/io/DataOutput;)V 2 261 273 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.read([BII)I 1 407 
org.apache.hadoop.mapreduce.task.reduce.Fetcher.getMapOutputURL(Lorg/apache/hadoop/mapreduce/task/reduce/MapHost;Ljava/util/List;)Ljava/net/URL; 1 452 
org.apache.hadoop.util.HostsFileReader.readFileToSet(Ljava/lang/String;Ljava/util/Set;)V 2 64 61 
org.apache.hadoop.yarn.server.nodemanager.webapp.AllApplicationsPage$AllApplicationsBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 89 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.validateExistingQueues(Ljava/util/Map;Ljava/util/Map;)V 1 266 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.getReservedContainers()Ljava/util/List; 1 440 
org.apache.hadoop.hdfs.server.datanode.FSDataset.getVolumeInfoMap()Ljava/util/Map; 1 2580 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.createMapTasks(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl;J[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo;)V 1 1069 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.getDiskReport()Ljava/util/Map; 3 433 447 459 
org.apache.hadoop.ipc.Server.join()V 1 1792 
org.apache.hadoop.hdfs.web.WebHdfsFileSystem.removeOffsetParam(Ljava/net/URL;)Ljava/net/URL; 1 668 
org.apache.hadoop.hdfs.server.datanode.DataNode$BlockPoolManager.joinAll()V 1 313 
org.apache.hadoop.fs.Path.depth()I 1 307 
org.apache.hadoop.metrics.spi.CompositeContext.startMonitoring()V 1 114 
org.apache.hadoop.fs.HarFileSystem.archivePath(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path; 1 164 
org.apache.hadoop.hdfs.server.namenode.ClusterJspHelper$NamenodeMXBeanHelper.getDecommissionNodeStatus(Ljava/util/Map;Ljava/lang/String;Ljava/lang/String;)V 1 472 
org.apache.hadoop.mapred.LocalJobRunner$Job.statusUpdate(Lorg/apache/hadoop/mapred/TaskAttemptID;Lorg/apache/hadoop/mapred/TaskStatus;)Z 1 510 
org.apache.hadoop.hdfs.server.balancer.Balancer$Source.dispatchBlocks()V 1 711 
org.apache.hadoop.metrics.spi.CompositeContext.init(Ljava/lang/String;Lorg/apache/hadoop/metrics/ContextFactory;)V 1 64 
org.apache.hadoop.yarn.webapp.hamlet.HamletGen.genImpl(Ljava/lang/Class;Ljava/lang/String;I)V 1 149 
org.apache.hadoop.util.bloom.Filter.add([Lorg/apache/hadoop/util/bloom/Key;)V 1 189 
org.apache.hadoop.io.compress.BlockCompressorStream.finish()V 1 139 
org.apache.hadoop.yarn.webapp.WebApps$Builder.inferHostClass()Ljava/lang/String; 1 240 
org.apache.hadoop.record.Utils.fromCSVBuffer(Ljava/lang/String;)Lorg/apache/hadoop/record/Buffer; 1 242 
org.apache.hadoop.hdfs.web.resources.Param.toSortedString(Ljava/lang/String;[Lorg/apache/hadoop/hdfs/web/resources/Param;)Ljava/lang/String; 1 40 
org.apache.hadoop.yarn.security.client.RMTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 43 
org.apache.hadoop.http.HttpServer.<init>(Ljava/lang/String;Ljava/lang/String;IZLorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/security/authorize/AccessControlList;Lorg/mortbay/jetty/Connector;[Ljava/lang/String;)V 2 245 253 
org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.specToString(Ljava/lang/String;Ljava/lang/String;ILjava/util/List;Ljava/util/List;)Ljava/lang/String; 2 174 179 
org.apache.hadoop.io.SortedMapWritable.write(Ljava/io/DataOutput;)V 1 201 
org.apache.hadoop.hdfs.server.namenode.INodeFile.computeFileSize(Z)J 1 191 
org.apache.hadoop.hdfs.web.JsonUtil.toJsonArray([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)[Ljava/lang/Object; 1 335 
org.apache.hadoop.mapred.FileInputFormat.listStatus(Lorg/apache/hadoop/mapred/JobConf;)[Lorg/apache/hadoop/fs/FileStatus; 3 215 213 205 
org.apache.hadoop.io.serializer.SerializationFactory.<init>(Lorg/apache/hadoop/conf/Configuration;)V 1 58 
org.apache.hadoop.io.ObjectWritable.readObject(Ljava/io/DataInput;Lorg/apache/hadoop/io/ObjectWritable;Lorg/apache/hadoop/conf/Configuration;)Ljava/lang/Object; 1 255 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concatInternal(Ljava/lang/String;[Ljava/lang/String;)V 2 854 894 
org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.toString()Ljava/lang/String; 1 137 
org.apache.hadoop.hdfs.server.blockmanagement.InvalidateBlocks.invalidateWork(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)Ljava/util/List; 1 155 
org.apache.hadoop.io.SequenceFile$Reader.seekToCurrentValue()V 1 2065 
org.apache.hadoop.security.AuthenticationFilterInitializer.initFilter(Lorg/apache/hadoop/http/FilterContainer;Lorg/apache/hadoop/conf/Configuration;)V 1 61 
org.apache.hadoop.mapred.lib.FieldSelectionMapReduce.reduce(Lorg/apache/hadoop/io/Text;Ljava/util/Iterator;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 183 
org.apache.hadoop.mapreduce.lib.partition.InputSampler.run([Ljava/lang/String;)I 2 354 406 
org.apache.hadoop.fs.shell.Command.runAll()I 2 113 110 
org.apache.hadoop.io.SequenceFile$Sorter$SortPass.flush(IILorg/apache/hadoop/io/SequenceFile$CompressionType;Lorg/apache/hadoop/io/compress/CompressionCodec;Z)V 1 2868 
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.addApplication(Lorg/apache/hadoop/yarn/api/records/ApplicationId;Lorg/apache/hadoop/security/Credentials;Z)V 1 277 
org.apache.hadoop.mapred.YarnChild.setupDistributedCacheConfig(Lorg/apache/hadoop/mapred/JobConf;)V 2 312 332 
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.AllocateRequestPBImpl.initAsks()V 1 176 
org.apache.hadoop.mapred.CleanupQueue$PathCleanupThread.addToQueue([Lorg/apache/hadoop/mapred/CleanupQueue$PathDeletionContext;)V 1 116 
org.apache.hadoop.mapred.YarnChild.main([Ljava/lang/String;)V 2 97 126 
org.apache.hadoop.hdfs.LeaseRenewer.run(I)V 2 446 431 
org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.deleteAsUser(Ljava/lang/String;Lorg/apache/hadoop/fs/Path;[Lorg/apache/hadoop/fs/Path;)V 1 288 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.addFalsePositive(Lorg/apache/hadoop/util/bloom/Key;)V 1 147 
org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer.reduce(Ljava/lang/Object;Ljava/lang/Iterable;Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 1 37 
org.apache.hadoop.record.compiler.generated.RccTokenManager.ReInitRounds()V 1 673 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.setupBlock()V 2 1025 1030 
org.apache.hadoop.record.compiler.generated.RccTokenManager.jjAddStates(II)V 1 57 
org.apache.hadoop.hdfs.server.common.Storage.listStorageDirectories()Ljava/lang/String; 1 199 
org.apache.hadoop.security.SaslInputStream.read()I 1 195 
org.apache.hadoop.util.Options.getOption(Ljava/lang/Class;[Ljava/lang/Object;)Ljava/lang/Object; 1 134 
org.apache.hadoop.io.ArrayPrimitiveWritable.writeBooleanArray(Ljava/io/DataOutput;)V 1 256 
org.apache.hadoop.io.file.tfile.TFile.main([Ljava/lang/String;)V 1 2350 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector.inspectDirectory(Lorg/apache/hadoop/hdfs/server/common/Storage$StorageDirectory;)V 2 81 116 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.checkForDeactivation()V 1 324 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.mapJournalsAndReportErrors(Lorg/apache/hadoop/hdfs/server/namenode/FSEditLog$JournalClosure;Ljava/lang/String;)V 1 1044 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseUnderReplicatedBlocks(I)Ljava/util/List; 3 963 977 984 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReplicationWorkForBlock(Lorg/apache/hadoop/hdfs/protocol/Block;I)Z 3 1081 1136 1157 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks.size()I 1 105 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.setReplication(SSLjava/lang/String;[Lorg/apache/hadoop/hdfs/protocol/Block;)V 2 1913 1921 
org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.pad()V 1 235 
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp.toBytesWritable([Lorg/apache/hadoop/fs/Options$Rename;)Lorg/apache/hadoop/io/BytesWritable; 1 1091 
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$FinalTransition.transition(Lorg/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl;Lorg/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppEvent;)V 1 530 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl;Lorg/apache/hadoop/mapreduce/v2/app/job/event/JobEvent;)Lorg/apache/hadoop/mapreduce/v2/api/records/JobState; 1 991 
org.apache.hadoop.fs.s3native.Jets3tNativeFileSystemStore.dump()V 1 211 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector.getLatestImage()Lorg/apache/hadoop/hdfs/server/namenode/FSImageStorageInspector$FSImageFile; 1 155 
org.apache.hadoop.fs.s3.S3OutputStream.nextBlockOutputStream()V 1 199 
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDiagnosticsResponsePBImpl.initDiagnostics()V 1 102 
org.apache.hadoop.record.Utils.toCSVString(Ljava/lang/String;)Ljava/lang/String; 1 120 
org.apache.hadoop.mapred.join.Parser$CNode.setKeyComparator(Ljava/lang/Class;)V 1 367 
org.apache.hadoop.fs.FileSystem.getContentSummary(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/ContentSummary; 1 1321 
org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys.write(Ljava/io/DataOutput;)V 1 95 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.setBalancerBandwidth(J)V 1 943 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.removeBlocksAssociatedTo(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)V 1 770 
org.apache.hadoop.util.bloom.Key.compareTo(Lorg/apache/hadoop/util/bloom/Key;)I 1 173 
org.apache.hadoop.mapreduce.v2.app.job.impl.MapTaskImpl.getSplitsAsString()Ljava/lang/String; 1 92 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.waitForReady()V 1 221 
org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/namenode/INodeDirectory;ZLorg/apache/hadoop/fs/permission/FsAction;Lorg/apache/hadoop/fs/permission/FsAction;Lorg/apache/hadoop/fs/permission/FsAction;Lorg/apache/hadoop/fs/permission/FsAction;)V 1 126 
org.apache.hadoop.mapred.YARNRunner.killJob(Lorg/apache/hadoop/mapreduce/JobID;)V 1 519 
org.apache.hadoop.fs.s3native.NativeS3FileSystem.mkdirs(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/permission/FsPermission;)Z 2 515 520 
org.apache.hadoop.fs.viewfs.ViewFs.getDelegationTokens(Ljava/lang/String;)Ljava/util/List; 2 580 584 
org.apache.hadoop.hdfs.server.namenode.LeaseManager.changeLease(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V 1 311 
org.apache.hadoop.ipc.Client.call(Lorg/apache/hadoop/io/Writable;Lorg/apache/hadoop/ipc/Client$ConnectionId;)Lorg/apache/hadoop/io/Writable; 1 1072 
org.apache.hadoop.conf.Configuration.getFile(Ljava/lang/String;Ljava/lang/String;)Ljava/io/File; 1 1664 
org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run()V 1 370 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printTasks(Lorg/apache/hadoop/mapreduce/TaskType;Ljava/lang/String;)V 1 396 
org.apache.hadoop.mapreduce.jobhistory.JobSubmittedEvent.getJobAcls()Ljava/util/Map; 1 99 
org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry.writeValue(Ljava/io/OutputStream;)J 1 1747 
org.apache.hadoop.mapreduce.v2.app.client.MRClientService$MRClientProtocolHandler.getTaskReports(Lorg/apache/hadoop/mapreduce/v2/api/protocolrecords/GetTaskReportsRequest;)Lorg/apache/hadoop/mapreduce/v2/api/protocolrecords/GetTaskReportsResponse; 1 375 
org.apache.hadoop.fs.FsShell$Usage.processRawArguments(Ljava/util/LinkedList;)V 1 128 
org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.write(Ljava/io/DataOutput;)V 1 109 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.getEditLogManifest(J)Lorg/apache/hadoop/hdfs/server/protocol/RemoteEditLogManifest; 2 738 756 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceRetentionSet.addResources(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/LocalResourcesTracker;)V 2 55 65 
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.init(Lorg/apache/hadoop/conf/Configuration;)V 1 88 
org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.toProtos([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;I)Ljava/util/ArrayList; 1 139 
org.apache.hadoop.record.XmlRecordOutput.putIndent()V 1 50 
org.apache.hadoop.hdfs.BlockReaderLocal.<init>(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;Lorg/apache/hadoop/security/token/Token;JJLorg/apache/hadoop/hdfs/protocol/BlockLocalPathInfo;Lorg/apache/hadoop/util/DataChecksum;ZLjava/io/FileInputStream;JLjava/io/FileInputStream;)V 2 288 298 
org.apache.hadoop.fs.FileContext$Util.globPathsLevel([Lorg/apache/hadoop/fs/Path;[Ljava/lang/String;I[Z)[Lorg/apache/hadoop/fs/Path; 1 2079 
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.incrAllCounters(Lorg/apache/hadoop/mapreduce/counters/CounterGroupBase;)V 1 206 
org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.close()V 1 500 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.clearPath(Ljava/io/File;[Ljava/lang/String;I)Z 1 274 
org.apache.hadoop.io.file.tfile.Utils.lowerBound(Ljava/util/List;Ljava/lang/Object;Ljava/util/Comparator;)I 1 422 
org.apache.hadoop.mapred.FileInputFormat.identifyHosts(ILjava/util/Map;)[Ljava/lang/String; 2 606 596 
org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader.skip(Lorg/apache/hadoop/io/WritableComparable;)V 1 151 
org.apache.hadoop.conf.Configuration$IntegerRanges.isIncluded(I)Z 1 1246 
org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.toString()Ljava/lang/String; 2 179 192 
org.apache.hadoop.fs.s3.S3OutputStream.write([BII)V 1 123 
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.dumpOutDebugInfo()V 2 223 237 
org.apache.hadoop.fs.shell.CommandFactory.addObject(Lorg/apache/hadoop/fs/shell/Command;[Ljava/lang/String;)V 1 96 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.security.LocalizerTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 43 
org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.write(Ljava/io/DataOutput;)V 1 124 
org.apache.hadoop.mapreduce.lib.chain.ChainMapper.run(Lorg/apache/hadoop/mapreduce/Mapper$Context;)V 1 156 
org.apache.hadoop.mapred.SortedRanges.remove(Lorg/apache/hadoop/mapred/SortedRanges$Range;)V 1 160 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsTasksBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 103 
org.apache.hadoop.util.UTF8ByteArrayUtils.findNthByte([BIIBI)I 1 81 
org.apache.hadoop.record.compiler.CGenerator.genCode(Ljava/lang/String;Ljava/util/ArrayList;Ljava/util/ArrayList;Ljava/lang/String;Ljava/util/ArrayList;)V 1 51 
org.apache.hadoop.ipc.Server.stop()V 1 1769 
org.apache.hadoop.hdfs.server.datanode.FSDataset.checkDataDir()V 4 2107 2105 2104 2127 
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.incrAllCounters(Lorg/apache/hadoop/mapreduce/counters/CounterGroupBase;)V 1 243 
org.apache.hadoop.yarn.util.ConverterUtils.convertToString(Ljava/util/Map;)Ljava/util/Map; 1 83 
org.apache.hadoop.security.Credentials.readFields(Ljava/io/DataInput;)V 2 226 235 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.TimeBucketMetrics.getBucketCounts(J)[I 2 73 76 
org.apache.hadoop.yarn.server.resourcemanager.webapp.CapacitySchedulerPage$QueueBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 106 
org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(Ljava/lang/String;Ljava/io/PrintStream;Lorg/apache/hadoop/conf/Configuration;)V 9 121 142 170 177 223 231 210 252 277 
org.apache.hadoop.util.bloom.CountingBloomFilter.membershipTest(Lorg/apache/hadoop/util/bloom/Key;)Z 1 187 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.hbCreateDecodeTables([I[I[I[CIII)V 7 650 649 657 662 666 671 679 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.run()V 1 272 
org.apache.hadoop.mapred.JobConf.findContainingJar(Ljava/lang/Class;)Ljava/lang/String; 1 1827 
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.handle(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/AuxServicesEvent;)V 1 175 
org.apache.hadoop.io.SequenceFile$Sorter.merge([Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;Z)Lorg/apache/hadoop/io/SequenceFile$Sorter$RawKeyValueIterator; 1 3006 
org.apache.hadoop.mapreduce.Job.waitForCompletion(Z)Z 1 1244 
org.apache.hadoop.hdfs.server.datanode.DataNode.handleDiskError(Ljava/lang/String;)V 1 1221 
org.apache.hadoop.mapred.SequenceFileInputFilter$FilterRecordReader.next(Ljava/lang/Object;Ljava/lang/Object;)Z 1 211 
org.apache.hadoop.fs.FileContext$Util.listStatus(Ljava/util/ArrayList;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)V 1 1672 
org.apache.hadoop.mapreduce.tools.CLI.listJobs(Lorg/apache/hadoop/mapreduce/Cluster;)V 1 488 
org.apache.hadoop.yarn.security.client.ClientTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 43 
org.apache.hadoop.hdfs.server.balancer.Balancer$Source.chooseNextBlockToMove()Lorg/apache/hadoop/hdfs/server/balancer/Balancer$PendingBlockMove; 1 655 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.deleteAsUser(Ljava/lang/String;Lorg/apache/hadoop/fs/Path;[Lorg/apache/hadoop/fs/Path;)V 1 279 
org.apache.hadoop.hdfs.server.balancer.Balancer$Source.filterMovedBlocks()V 1 683 
org.apache.hadoop.hdfs.server.balancer.Balancer$Source.getBlockList()J 2 621 607 
org.apache.hadoop.net.SocketOutputStream.write([BII)V 1 110 
org.apache.hadoop.ipc.Client.stop()V 2 985 991 
org.apache.hadoop.fs.FileUtil.copy(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/FileStatus;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;ZZLorg/apache/hadoop/conf/Configuration;)Z 1 249 
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl.initLocalResources()V 1 235 
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerInfo.getQueues(Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSQueue;)Lorg/apache/hadoop/yarn/server/resourcemanager/webapp/dao/CapacitySchedulerQueueInfoList; 1 82 
org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notify(Lorg/apache/hadoop/mapreduce/v2/api/records/JobReport;)V 1 174 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.addContainerReq(Lorg/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor$ContainerRequest;)V 2 266 274 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.add(Lorg/apache/hadoop/util/bloom/Key;)V 1 127 
org.apache.hadoop.io.file.tfile.Compression.getSupportedAlgorithms()[Ljava/lang/String; 1 362 
org.apache.hadoop.fs.s3native.NativeS3FileSystem.delete(Lorg/apache/hadoop/fs/Path;Z)Z 2 370 369 
org.apache.hadoop.mapred.FileInputFormat.addInputPaths(Lorg/apache/hadoop/mapred/JobConf;Ljava/lang/String;)V 1 349 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.updateRunningTime()V 1 202 
org.apache.hadoop.mapreduce.Cluster.getJobs([Lorg/apache/hadoop/mapreduce/JobStatus;)[Lorg/apache/hadoop/mapreduce/Job; 1 145 
org.apache.hadoop.hdfs.DFSOutputStream.getPipeline()[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 1201 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector.next(Lorg/apache/hadoop/mapreduce/lib/join/TupleWritable;)Z 4 263 277 286 291 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner$LogEntry.parseEntry(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/datanode/BlockPoolSliceScanner$LogEntry; 1 361 
org.apache.hadoop.util.bloom.Filter.add(Ljava/util/Collection;)V 1 176 
org.apache.hadoop.io.SequenceFile$Sorter.writeFile(Lorg/apache/hadoop/io/SequenceFile$Sorter$RawKeyValueIterator;Lorg/apache/hadoop/io/SequenceFile$Writer;)V 1 3056 
org.apache.hadoop.hdfs.server.protocol.BlockRecoveryCommand.readFields(Ljava/io/DataInput;)V 1 161 
org.apache.hadoop.mapreduce.lib.map.TokenCounterMapper.map(Ljava/lang/Object;Lorg/apache/hadoop/io/Text;Lorg/apache/hadoop/mapreduce/Mapper$Context;)V 1 44 
org.apache.hadoop.mapreduce.lib.input.NLineInputFormat.getSplits(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 1 82 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeID;)V 1 3863 
org.apache.hadoop.io.compress.CompressionCodecFactory.toString()Ljava/lang/String; 1 85 
org.apache.hadoop.io.MapFile.main([Ljava/lang/String;)V 1 848 
org.apache.hadoop.util.RunJar.unJar(Ljava/io/File;Ljava/io/File;Ljava/util/regex/Pattern;)V 1 80 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$KillTasksTransition.transition(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl;Lorg/apache/hadoop/mapreduce/v2/app/job/event/JobEvent;)V 1 1253 
org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.getMapsForHost(Lorg/apache/hadoop/mapreduce/task/reduce/MapHost;)Ljava/util/List; 2 325 335 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDeadNodes()Ljava/lang/String; 1 4388 
org.apache.hadoop.util.AsyncDiskService.<init>([Ljava/lang/String;)V 1 80 
org.apache.hadoop.mapreduce.lib.input.DelegatingInputFormat.getSplits(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 5 66 86 116 98 75 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.init(Lorg/apache/hadoop/conf/Configuration;)V 2 186 199 
org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram.getReport()Ljava/lang/String; 4 89 101 98 118 
org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.shutdownAllContainers()V 1 319 
org.apache.hadoop.hdfs.protocol.LocatedBlock.write(Ljava/io/DataOutput;)V 1 131 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getPathStrings(Ljava/lang/String;)[Ljava/lang/String; 1 404 
org.apache.hadoop.fs.viewfs.ViewFileSystem.isValidName(Ljava/lang/String;)Z 1 104 
org.apache.hadoop.hdfs.DistributedFileSystem$1.hasNext()Z 1 427 
org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.run(Lorg/apache/hadoop/mapreduce/Mapper$Context;)V 2 139 144 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource$FetchSuccessTransition.transition(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/LocalizedResource;Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/event/ResourceEvent;)V 1 244 
org.apache.hadoop.metrics2.util.Servers.parse(Ljava/lang/String;I)Ljava/util/List; 1 60 
org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram.getCombinerOutput()Ljava/util/ArrayList; 1 156 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.getProgress()F 1 491 
org.apache.hadoop.io.serializer.SerializationFactory.getSerialization(Ljava/lang/Class;)Lorg/apache/hadoop/io/serializer/Serialization; 1 97 
org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.parse(Lorg/apache/hadoop/mapreduce/jobhistory/EventReader;)Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$JobInfo; 1 128 
org.apache.hadoop.fs.FileSystem.globStatusInternal(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)[Lorg/apache/hadoop/fs/FileStatus; 1 1573 
org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService$LogDeletionTask.shouldDeleteLogDir(Lorg/apache/hadoop/fs/FileStatus;JLorg/apache/hadoop/fs/FileSystem;)Z 1 100 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.skipToNextMarker(JI)Z 1 230 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.<init>(Lorg/apache/hadoop/hdfs/server/datanode/FSDataset;Ljava/io/File;)V 1 112 
org.apache.hadoop.fs.viewfs.InodeTree.<init>(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)V 1 314 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.createLocatedBlock(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;J)Lorg/apache/hadoop/hdfs/protocol/LocatedBlock; 1 605 
org.apache.hadoop.record.compiler.generated.Rcc.ReInit(Lorg/apache/hadoop/record/compiler/generated/RccTokenManager;)V 1 456 
org.apache.hadoop.hdfs.server.namenode.FSImageSerialization.writeINodeUnderConstruction(Ljava/io/DataOutputStream;Lorg/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction;Ljava/lang/String;)V 1 141 
org.apache.hadoop.hdfs.server.balancer.Balancer.waitForMoveCompletion()V 2 1120 1120 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.update(Ljava/util/List;)Lorg/apache/hadoop/yarn/server/nodemanager/api/protocolrecords/LocalizerHeartbeatResponse; 1 785 
org.apache.hadoop.record.compiler.generated.RccTokenManager.getNextToken()Lorg/apache/hadoop/record/compiler/generated/Token; 3 739 721 735 
org.apache.hadoop.conf.Configuration.unset(Ljava/lang/String;)V 1 813 
org.apache.hadoop.mapreduce.counters.AbstractCounters.<init>(Lorg/apache/hadoop/mapreduce/counters/AbstractCounters;Lorg/apache/hadoop/mapreduce/counters/CounterGroupFactory;)V 2 111 107 
org.apache.hadoop.mapred.SortedRanges.write(Ljava/io/DataOutput;)V 1 203 
org.apache.hadoop.http.HttpServer.addGlobalFilter(Ljava/lang/String;Ljava/lang/String;Ljava/util/Map;)V 1 473 
org.apache.hadoop.http.HttpServer.getFilterInitializers(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/http/FilterInitializer; 1 291 
org.apache.hadoop.http.HttpServer.addFilterPathMapping(Ljava/lang/String;Lorg/mortbay/jetty/servlet/Context;)V 1 505 
org.apache.hadoop.hdfs.server.namenode.FileJournalManager.matchEditLogs([Ljava/io/File;)Ljava/util/List; 1 159 
org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields([Ljava/lang/String;Ljava/util/List;)I 2 107 86 
org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry.getValue([BI)I 1 1864 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.disableAndReportErrorOnJournals(Ljava/util/List;)V 1 1065 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks.remove(Lorg/apache/hadoop/hdfs/protocol/Block;I)Z 1 241 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseSourceDatanode(Lorg/apache/hadoop/hdfs/protocol/Block;Ljava/util/List;Ljava/util/List;Lorg/apache/hadoop/hdfs/server/blockmanagement/NumberReplicas;)Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 1230 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.blockHasEnoughRacks(Lorg/apache/hadoop/hdfs/protocol/Block;)Z 1 2482 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.countNodes(Lorg/apache/hadoop/hdfs/protocol/Block;)Lorg/apache/hadoop/hdfs/server/blockmanagement/NumberReplicas; 1 2238 
org.apache.hadoop.mapred.JobClient.getJobQueueInfoArray([Lorg/apache/hadoop/mapreduce/QueueInfo;)[Lorg/apache/hadoop/mapred/JobQueueInfo; 1 1049 
org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl$FinalTransition.getNodesOnWhichAttemptRan(Lorg/apache/hadoop/yarn/server/resourcemanager/rmapp/RMAppImpl;)Ljava/util/Set; 1 521 
org.apache.hadoop.hdfs.server.blockmanagement.PendingReplicationBlocks$PendingReplicationMonitor.pendingReplicationCheck()V 1 212 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.doneApplication(Lorg/apache/hadoop/yarn/api/records/ApplicationAttemptId;Lorg/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptState;)V 2 414 423 
org.apache.hadoop.util.bloom.CountingBloomFilter.readFields(Ljava/io/DataInput;)V 1 306 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDecommissioningNodes()Ljava/util/List; 1 737 
org.apache.hadoop.record.compiler.generated.Rcc.<init>(Lorg/apache/hadoop/record/compiler/generated/RccTokenManager;)V 1 448 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.compileReport(Lorg/apache/hadoop/hdfs/server/datanode/FSDatasetInterface$FSVolumeInterface;Ljava/io/File;Ljava/util/LinkedList;)Ljava/util/LinkedList; 2 531 512 
org.apache.hadoop.hdfs.protocol.LocatedBlocks.write(Ljava/io/DataOutput;)V 1 202 
org.apache.hadoop.util.Shell$ShellCommandExecutor.toString()Ljava/lang/String; 1 354 
org.apache.hadoop.hdfs.server.datanode.BPOfferService.reportReceivedBlocks()V 1 319 
org.apache.hadoop.mapreduce.Cluster.initialize(Ljava/net/InetSocketAddress;Lorg/apache/hadoop/conf/Configuration;)V 1 90 
org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.check(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;Lorg/apache/hadoop/hdfs/server/namenode/NamenodeFsck$Result;)V 4 261 254 363 304 
org.apache.hadoop.net.NetworkTopology$InnerNode.remove(Lorg/apache/hadoop/net/Node;)Z 2 192 206 
org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.validateEditLog(Lorg/apache/hadoop/hdfs/server/namenode/EditLogInputStream;)Lorg/apache/hadoop/hdfs/server/namenode/FSEditLogLoader$EditLogValidation; 1 512 
org.apache.hadoop.net.NetworkTopology.toString()Ljava/lang/String; 1 613 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.addMap(Lorg/apache/hadoop/mapreduce/v2/app/rm/ContainerRequestEvent;)V 2 675 686 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.metaSave(Ljava/io/PrintWriter;)V 2 349 319 
org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 1 61 
org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse([Lorg/apache/hadoop/hdfs/server/namenode/INode;I)V 1 160 
org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkSubAccess(Lorg/apache/hadoop/hdfs/server/namenode/INode;Lorg/apache/hadoop/fs/permission/FsAction;)V 2 176 172 
org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(Lorg/apache/hadoop/conf/Configuration;)V 2 58 76 
org.apache.hadoop.yarn.webapp.hamlet.HamletGen.genMethods(Ljava/lang/String;Ljava/lang/Class;I)V 1 184 
org.apache.hadoop.ipc.Client.getConnection(Lorg/apache/hadoop/ipc/Client$ConnectionId;Lorg/apache/hadoop/ipc/Client$Call;)Lorg/apache/hadoop/ipc/Client$Connection; 1 1185 
org.apache.hadoop.mapreduce.TypeConverter.fromYarn([Lorg/apache/hadoop/mapreduce/v2/api/records/TaskAttemptCompletionEvent;)[Lorg/apache/hadoop/mapred/TaskCompletionEvent; 1 165 
org.apache.hadoop.hdfs.server.protocol.BlockCommand.readFields(Ljava/io/DataInput;)V 3 127 135 133 
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call()Ljava/lang/Integer; 3 130 148 207 
org.apache.hadoop.record.compiler.CppGenerator.genCode(Ljava/lang/String;Ljava/util/ArrayList;Ljava/util/ArrayList;Ljava/lang/String;Ljava/util/ArrayList;)V 2 55 62 
org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(Lorg/apache/hadoop/yarn/event/Event;)V 1 273 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(Ljava/lang/String;Ljava/util/List;)V 1 204 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processPendingReplications()V 1 1284 
org.apache.hadoop.record.Buffer.hashCode()I 1 193 
org.apache.hadoop.io.SequenceFile$Metadata.equals(Lorg/apache/hadoop/io/SequenceFile$Metadata;)Z 1 774 
org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.isSuccess()Z 1 85 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.reinitialize(Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSQueue;Lorg/apache/hadoop/yarn/api/records/Resource;)V 1 381 
org.apache.hadoop.io.MapFile.fix(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Ljava/lang/Class;ZLorg/apache/hadoop/conf/Configuration;)J 1 807 
org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Lorg/apache/hadoop/mapred/RawKeyValueIterator;Lorg/apache/hadoop/mapred/OutputCollector;)V 1 1541 
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl$1.run()V 1 319 
org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue()Z 1 166 
org.apache.hadoop.mapreduce.v2.hs.webapp.dao.JobInfo.countTasksAndAttempts(Lorg/apache/hadoop/mapreduce/v2/app/job/Job;)V 2 253 249 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.removeDecomNodeFromList(Ljava/util/List;)V 1 419 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.configureSinks()V 1 440 
org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.printBlockReport(Ljava/lang/StringBuilder;Z)V 1 222 
org.apache.hadoop.mapreduce.tools.CLI.getTaskTypess()Ljava/lang/String; 1 374 
org.apache.hadoop.mapred.JobQueueClient.displayQueueList()V 1 146 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.datanodeReport(Lorg/apache/hadoop/hdfs/protocol/HdfsConstants$DatanodeReportType;)[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 2751 
org.apache.hadoop.record.compiler.generated.Rcc.RecordList()Ljava/util/ArrayList; 1 229 
org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getPartialJobs(Ljava/util/Collection;Ljava/lang/Long;Ljava/lang/Long;Ljava/lang/String;Ljava/lang/String;Ljava/lang/Long;Ljava/lang/Long;Ljava/lang/Long;Ljava/lang/Long;Lorg/apache/hadoop/mapreduce/v2/api/records/JobState;)Lorg/apache/hadoop/mapreduce/v2/hs/webapp/dao/JobsInfo; 1 181 
org.apache.hadoop.net.NetworkTopology$InnerNode.add(Lorg/apache/hadoop/net/Node;)Z 2 144 157 
org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(Lorg/apache/hadoop/hdfs/server/datanode/DataNode;Lorg/apache/hadoop/hdfs/server/protocol/NamespaceInfo;Ljava/util/Collection;Lorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$StartupOption;)V 2 150 193 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.CounterGroupInfo.<init>(Ljava/lang/String;Lorg/apache/hadoop/mapreduce/CounterGroup;Lorg/apache/hadoop/mapreduce/CounterGroup;Lorg/apache/hadoop/mapreduce/CounterGroup;)V 1 46 
org.apache.hadoop.io.file.tfile.TFile$TFileIndex.write(Ljava/io/DataOutput;)V 1 2276 
org.apache.hadoop.io.SequenceFile$Sorter$SortPass.grow([Lorg/apache/hadoop/io/SequenceFile$ValueBytes;I)[Lorg/apache/hadoop/io/SequenceFile$ValueBytes; 1 2840 
org.apache.hadoop.io.file.tfile.Chunk$ChunkDecoder.close()V 1 190 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.hashCode([BIII)I 1 122 
org.apache.hadoop.io.ArrayPrimitiveWritable.readDoubleArray(Ljava/io/DataInput;)V 1 342 
org.apache.hadoop.hdfs.server.namenode.FileJournalManager.purgeLogsOlderThan(J)V 1 115 
org.apache.hadoop.yarn.util.Self.detect()V 1 43 
org.apache.hadoop.hdfs.server.common.JspHelper.bestNode(Lorg/apache/hadoop/hdfs/protocol/LocatedBlocks;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 2 130 128 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanOldDirsForJob(Lorg/apache/hadoop/mapreduce/v2/api/records/JobId;)Lorg/apache/hadoop/mapreduce/v2/hs/HistoryFileManager$HistoryFileInfo; 1 702 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.bsR(J)J 1 598 
org.apache.hadoop.mapred.JobClient.getAllJobs()[Lorg/apache/hadoop/mapred/JobStatus; 1 862 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.getAndMoveToFrontDecode()V 11 818 862 878 876 841 899 836 921 943 959 957 
org.apache.hadoop.mapred.join.CompositeInputFormat.addUserIdentifiers(Lorg/apache/hadoop/mapred/JobConf;)V 1 100 
org.apache.hadoop.mapred.join.Parser.parse(Ljava/lang/String;Lorg/apache/hadoop/mapred/JobConf;)Lorg/apache/hadoop/mapred/join/Parser$Node; 1 486 
org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(Lorg/apache/hadoop/mapred/JobConf;)V 4 99 108 130 136 
org.apache.hadoop.mapred.ClusterStatus.write(Ljava/io/DataOutput;)V 2 404 414 
org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo.getLiveNodeManagers()Ljava/lang/String; 1 81 
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$1.run()V 1 173 
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.hashCode()I 1 326 
org.apache.hadoop.hdfs.server.balancer.Balancer$Source.isGoodBlockCandidate(Lorg/apache/hadoop/hdfs/server/balancer/Balancer$BalancerBlock;)Z 1 639 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.addToParent([BLorg/apache/hadoop/hdfs/server/namenode/INodeDirectory;Lorg/apache/hadoop/hdfs/server/namenode/INode;Z)Lorg/apache/hadoop/hdfs/server/namenode/INodeDirectory; 1 419 
org.apache.hadoop.io.ArrayWritable.<init>([Ljava/lang/String;)V 1 62 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.getLaunchTime()J 1 434 
org.apache.hadoop.hdfs.server.datanode.FSDataset.getFinalizedBlocks(Ljava/lang/String;)Ljava/util/List; 1 1919 
org.apache.hadoop.mapred.LineRecordReader.next(Lorg/apache/hadoop/io/LongWritable;Lorg/apache/hadoop/io/Text;)Z 1 203 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateFile(Lorg/apache/hadoop/hdfs/server/namenode/INodeFile;Ljava/lang/String;[Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;JJ)V 2 357 391 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector.clear()V 1 240 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.logBlockReplicationInfo(Lorg/apache/hadoop/hdfs/protocol/Block;Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/server/blockmanagement/NumberReplicas;)V 1 2290 
org.apache.hadoop.hdfs.tools.offlineEditsViewer.EditsLoaderCurrent.visit_OP_ADD_or_OP_CLOSE(Lorg/apache/hadoop/hdfs/server/namenode/FSEditLogOpCodes;)V 1 130 
org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils.toAvro([I)Ljava/util/List; 1 40 
org.apache.hadoop.mapreduce.lib.input.InvalidInputException.getMessage()Ljava/lang/String; 1 61 
org.apache.hadoop.hdfs.server.namenode.BackupImage.convergeJournalSpool()V 1 237 
org.apache.hadoop.io.MapWritable.readFields(Ljava/io/DataInput;)V 1 183 
org.apache.hadoop.hdfs.LeaseRenewer.renew()V 1 406 
org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.removeBlock(Lorg/apache/hadoop/hdfs/protocol/Block;)V 1 125 
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.RegisterApplicationMasterResponsePBImpl.initApplicationACLs()V 1 162 
org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$1.run()V 1 248 
org.apache.hadoop.fs.shell.Command.processArguments(Ljava/util/LinkedList;)V 1 246 
org.apache.hadoop.hdfs.DFSUtil.locatedBlocks2Locations(Lorg/apache/hadoop/hdfs/protocol/LocatedBlocks;)[Lorg/apache/hadoop/fs/BlockLocation; 2 301 295 
org.apache.hadoop.mapred.join.CompositeRecordReader.skip(Lorg/apache/hadoop/io/WritableComparable;)V 2 345 348 
org.apache.hadoop.util.UTF8ByteArrayUtils.findByte([BIIB)I 1 36 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.assignContainer(Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerNode;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerApp;Lorg/apache/hadoop/yarn/api/records/Priority;ILorg/apache/hadoop/yarn/api/records/ResourceRequest;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/NodeType;)I 1 530 
org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.getJobsIn(Lorg/apache/hadoop/mapreduce/lib/jobcontrol/ControlledJob$State;)Ljava/util/List; 1 92 
org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.getInputBytes(Ljava/util/List;)J 1 509 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.TimeBucketMetrics.findBucket(J)I 1 60 
org.apache.hadoop.yarn.service.CompositeService.init(Lorg/apache/hadoop/conf/Configuration;)V 1 57 
org.apache.hadoop.util.StringUtils.uriToString([Ljava/net/URI;)Ljava/lang/String; 1 197 
org.apache.hadoop.yarn.webapp.Controller$RequestContext.cookies()Ljava/util/Map; 1 88 
org.apache.hadoop.io.IOUtils.readFully(Ljava/io/InputStream;[BII)V 1 166 
org.apache.hadoop.mapred.Task.setConf(Lorg/apache/hadoop/conf/Configuration;)V 1 1237 
org.apache.hadoop.mapred.MultiFileSplit.getLocations()[Ljava/lang/String; 1 54 
org.apache.hadoop.mapreduce.Job.monitorAndPrintJob()Z 1 1277 
org.apache.hadoop.mapreduce.task.reduce.MergeThread.run()V 2 83 82 
org.apache.hadoop.security.SaslRpcClient.saslConnect(Ljava/io/InputStream;Ljava/io/OutputStream;)Z 1 162 
org.apache.hadoop.hdfs.server.datanode.DataNode.scheduleAllBlockReport(J)V 1 1744 
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.speculationValue(Lorg/apache/hadoop/mapreduce/v2/api/records/TaskId;J)J 1 366 
org.apache.hadoop.record.Utils.fromCSVString(Ljava/lang/String;)Ljava/lang/String; 1 160 
org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.run()V 1 173 
org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Lorg/apache/hadoop/mapreduce/Job;Lorg/apache/hadoop/fs/Path;S)V 3 177 199 210 
org.apache.hadoop.mapred.join.CompositeInputSplit.readFields(Ljava/io/DataInput;)V 2 140 144 
org.apache.hadoop.hdfs.server.balancer.Balancer.dispatchBlockMoves()J 2 1086 1091 
org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.findSeparator([BIIB)I 1 70 
org.apache.hadoop.mapred.Counters.incrAllCounters(Lorg/apache/hadoop/mapred/Counters;)V 2 541 538 
org.apache.hadoop.io.ArrayWritable.toStrings()[Ljava/lang/String; 1 73 
org.apache.hadoop.mapreduce.Reducer.run(Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 1 169 
org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.updateAttrCache()I 3 240 244 239 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobInfo.<init>(Lorg/apache/hadoop/mapreduce/v2/app/job/Job;Ljava/lang/Boolean;)V 2 121 129 
org.apache.hadoop.util.PureJavaCrc32.update([BII)V 2 62 75 
org.apache.hadoop.util.PureJavaCrc32C.update([BII)V 2 59 72 
org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations$BlockWithLocations.write(Ljava/io/DataOutput;)V 1 84 
org.apache.hadoop.hdfs.DFSUtil.setGenericConf(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;[Ljava/lang/String;)V 1 597 
org.apache.hadoop.mapred.ReduceTaskStatus.write(Ljava/io/DataOutput;)V 1 158 
org.apache.hadoop.hdfs.server.namenode.BackupNode.handshake(Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/hdfs/server/protocol/NamespaceInfo; 1 288 
org.apache.hadoop.hdfs.server.namenode.BackupNode.registerWith(Lorg/apache/hadoop/hdfs/server/protocol/NamespaceInfo;)V 1 337 
org.apache.hadoop.hdfs.server.namenode.NameNode.stop()V 1 490 
org.apache.hadoop.mapred.SortedRanges.readFields(Ljava/io/DataInput;)V 1 192 
org.apache.hadoop.hdfs.DistributedFileSystem.concat(Lorg/apache/hadoop/fs/Path;[Lorg/apache/hadoop/fs/Path;)V 1 277 
org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.getAttributes([Ljava/lang/String;)Ljavax/management/AttributeList; 1 124 
org.apache.hadoop.mapreduce.JobSubmitter.printTokens(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/security/Credentials;)V 1 432 
org.apache.hadoop.mapreduce.task.reduce.MergeManager.combineAndSpill(Lorg/apache/hadoop/mapred/RawKeyValueIterator;Lorg/apache/hadoop/mapred/Counters$Counter;)V 1 577 
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(Lorg/apache/hadoop/mapreduce/JobContext;)V 2 302 304 
org.apache.hadoop.io.TwoDArrayWritable.readFields(Ljava/io/DataInput;)V 3 63 69 68 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getQueues(Ljava/util/Set;)Ljava/util/Map; 1 402 
org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter.split(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List; 1 75 
org.apache.hadoop.mapred.join.Parser$CNode.getSplits(Lorg/apache/hadoop/mapred/JobConf;I)[Lorg/apache/hadoop/mapred/InputSplit; 3 379 394 392 
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenCancelThread.run()V 1 221 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$RequestContainerTransition.transition(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl;Lorg/apache/hadoop/mapreduce/v2/app/job/event/TaskAttemptEvent;)V 1 1132 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processLocalNameINodes(Ljava/io/DataInputStream;Lorg/apache/hadoop/hdfs/tools/offlineImageViewer/ImageVisitor;JZ)V 1 389 
org.apache.hadoop.hdfs.protocol.LayoutVersion.initMap()V 1 164 
org.apache.hadoop.mapred.FileInputFormat.getBlockIndex([Lorg/apache/hadoop/fs/BlockLocation;J)I 1 313 
org.apache.hadoop.conf.Configuration.getClasses(Ljava/lang/String;[Ljava/lang/Class;)[Ljava/lang/Class; 1 1514 
org.apache.hadoop.metrics.spi.CompositeContext.emitRecord(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/metrics/spi/OutputRecord;)V 1 86 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.getVolumeMap(Ljava/lang/String;Lorg/apache/hadoop/hdfs/server/datanode/ReplicasMap;Lorg/apache/hadoop/hdfs/server/datanode/FSDataset$FSVolume;)V 1 176 
org.apache.hadoop.hdfs.HsftpFileSystem.openConnection(Ljava/lang/String;Ljava/lang/String;)Ljava/net/HttpURLConnection; 1 161 
org.apache.hadoop.io.UTF8.readChars(Ljava/io/DataInput;Ljava/lang/StringBuilder;I)V 1 228 
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/FileStatus;Lorg/apache/hadoop/fs/Path;)V 1 353 
org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue.enqueue(Ljava/lang/Object;)V 1 879 
org.apache.hadoop.io.compress.CompressorStream.write([BII)V 1 74 
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.reportBadBlocks([Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;)V 2 460 457 
org.apache.hadoop.util.DataChecksum.calculateChunkedSums([BII[BI)V 1 402 
org.apache.hadoop.record.compiler.JRecord$JavaRecord.<init>(Lorg/apache/hadoop/record/compiler/JRecord;Ljava/lang/String;Ljava/util/ArrayList;)V 1 51 
org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager.heartbeatCheck()V 2 213 209 
org.apache.hadoop.mapreduce.task.reduce.Shuffle.run()Lorg/apache/hadoop/mapred/RawKeyValueIterator; 3 110 118 133 
org.apache.hadoop.conf.Configuration.iterator()Ljava/util/Iterator; 1 1779 
org.apache.hadoop.fs.viewfs.InodeTree.createLink(Ljava/lang/String;Ljava/lang/String;ZLorg/apache/hadoop/security/UserGroupInformation;)V 3 217 241 255 
org.apache.hadoop.fs.kfs.KosmosFileSystem.getFileBlockLocations(Lorg/apache/hadoop/fs/FileStatus;JJ)[Lorg/apache/hadoop/fs/BlockLocation; 1 311 
org.apache.hadoop.hdfs.tools.DFSAdmin.report()V 2 338 346 
org.apache.hadoop.fs.shell.CommandUtils.formatDescription(Ljava/lang/String;[Ljava/lang/String;)Ljava/lang/String; 1 23 
org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.<init>(Lorg/apache/hadoop/io/SequenceFile$Sorter;Ljava/util/List;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/util/Progressable;)V 1 3154 
org.apache.hadoop.mapred.BackupStore.clearSegmentList()V 1 362 
org.apache.hadoop.io.file.tfile.Utils.lowerBound(Ljava/util/List;Ljava/lang/Object;)I 1 482 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.constructFinalFullcounters()V 1 1208 
org.apache.hadoop.hdfs.util.LightWeightGSet.get(Ljava/lang/Object;)Ljava/lang/Object; 1 124 
org.apache.hadoop.hdfs.server.namenode.LeaseManager$Lease.findPath(Lorg/apache/hadoop/hdfs/server/namenode/INodeFileUnderConstruction;)Ljava/lang/String; 1 230 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.readFields(Ljava/io/DataInput;)V 5 436 433 445 442 451 
org.apache.hadoop.hdfs.tools.offlineEditsViewer.EditsLoaderCurrent.loadEdits()V 1 550 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 3 231 229 220 
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$OneFileInfo.<init>(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;ZLjava/util/HashMap;Ljava/util/HashMap;Ljava/util/HashMap;Ljava/util/HashMap;J)V 5 517 510 558 573 544 
org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsList.toDataTableArrays(Ljava/util/Collection;Ljava/io/PrintWriter;)V 1 60 
org.apache.hadoop.fs.FileSystem$Cache.closeAll(Z)V 1 2268 
org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.setAggregatorDescriptors(Lorg/apache/hadoop/mapred/JobConf;[Ljava/lang/Class;)V 1 198 
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.writeLaunchEnv(Ljava/io/OutputStream;Ljava/util/Map;Ljava/util/Map;Ljava/util/List;)V 4 556 562 561 572 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor.run()V 1 2590 
org.apache.hadoop.net.NetworkTopology.pseudoSortByDistance(Lorg/apache/hadoop/net/Node;[Lorg/apache/hadoop/net/Node;)V 1 645 
org.apache.hadoop.hdfs.server.namenode.INodeDirectory.getExistingPathINodes([[B[Lorg/apache/hadoop/hdfs/server/namenode/INode;Z)I 1 186 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removePathAndBlocks(Ljava/lang/String;Ljava/util/List;)V 1 1993 
org.apache.hadoop.mapreduce.task.reduce.Fetcher.shuffleToDisk(Lorg/apache/hadoop/mapreduce/task/reduce/MapHost;Lorg/apache/hadoop/mapreduce/task/reduce/MapOutput;Ljava/io/InputStream;J)V 1 548 
org.apache.hadoop.metrics.spi.AbstractMetricsContext.timerEvent()V 1 297 
org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl.initApplicationACLs()V 1 449 
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.JobReportPBImpl.initAMInfos()V 1 297 
org.apache.hadoop.mapreduce.v2.app.webapp.JobBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 102 
org.apache.hadoop.mapreduce.lib.join.Parser$CNode.createRecordReader(Lorg/apache/hadoop/mapreduce/InputSplit;Lorg/apache/hadoop/mapreduce/TaskAttemptContext;)Lorg/apache/hadoop/mapreduce/lib/join/ComposableRecordReader; 1 485 
org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 2 125 102 
org.apache.hadoop.mapreduce.v2.api.records.impl.pb.TaskReportPBImpl.initDiagnostics()V 1 326 
org.apache.hadoop.fs.shell.PathData.expandAsGlob(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/fs/shell/PathData; 1 295 
org.apache.hadoop.mapreduce.task.reduce.MergeManager$OnDiskMerger.merge(Ljava/util/List;)V 1 517 
org.apache.hadoop.io.MD5Hash.quarterDigest()I 1 151 
org.apache.hadoop.mapred.lib.DelegatingInputFormat.getSplits(Lorg/apache/hadoop/mapred/JobConf;I)[Lorg/apache/hadoop/mapred/InputSplit; 5 62 82 108 93 71 
org.apache.hadoop.io.file.tfile.BCFile$MetaIndex.<init>(Ljava/io/DataInput;)V 1 772 
org.apache.hadoop.io.file.tfile.BCFile$DataIndex.<init>(Ljava/io/DataInput;)V 1 867 
org.apache.hadoop.net.NetworkTopology.contains(Lorg/apache/hadoop/net/Node;)Z 1 394 
org.apache.hadoop.record.Utils.fromBinaryString(Ljava/io/DataInput;)Ljava/lang/String; 1 367 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.recvDecodingTables()V 12 694 700 707 704 724 722 731 738 735 754 753 750 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.getAndMoveToFrontDecode0(I)I 2 993 991 
org.apache.hadoop.yarn.server.nodemanager.DirectoryCollection.checkDirs()Z 1 76 
org.apache.hadoop.mapred.join.Parser.reduce(Ljava/util/Stack;Lorg/apache/hadoop/mapred/JobConf;)Lorg/apache/hadoop/mapred/join/Parser$Token; 1 458 
org.apache.hadoop.util.DataChecksum.calculateChunkedSums(Ljava/nio/ByteBuffer;Ljava/nio/ByteBuffer;)V 1 380 
org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(Lorg/apache/hadoop/fs/FileContext;Lorg/apache/hadoop/fs/Path;)Ljava/lang/Object; 1 2333 
org.apache.hadoop.hdfs.server.balancer.Balancer$PendingBlockMove.chooseBlockAndProxy()Z 1 239 
org.apache.hadoop.mapred.IFileInputStream.close()V 1 72 
org.apache.hadoop.hdfs.security.token.block.BlockTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 40 
org.apache.hadoop.metrics.ContextFactory.setAttributes()V 1 200 
org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$TaskInfo.printAll()V 1 556 
org.apache.hadoop.fs.shell.Command.expandArguments(Ljava/util/LinkedList;)Ljava/util/LinkedList; 1 209 
org.apache.hadoop.io.SequenceFile$Sorter$SegmentContainer.<init>(Lorg/apache/hadoop/io/SequenceFile$Sorter;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;)V 1 3554 
org.apache.hadoop.mapred.lib.IdentityReducer.reduce(Ljava/lang/Object;Ljava/util/Iterator;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 44 
org.apache.hadoop.mapred.PeriodicStatsAccumulator.<init>(I)V 1 76 
org.apache.hadoop.hdfs.protocol.LocatedBlock.readFields(Ljava/io/DataInput;)V 1 144 
org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.fromProtos(Ljava/util/List;)[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 149 
org.apache.hadoop.net.NetUtils.getAllStaticResolutions()Ljava/util/List; 1 333 
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenCancelThread.cancelToken(Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/conf/Configuration;)V 1 206 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.hbMakeCodeLengths([B[ILorg/apache/hadoop/io/compress/bzip2/CBZip2OutputStream$Data;II)V 11 376 396 389 413 443 480 403 492 488 504 380 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.hbAssignCodes([I[BIII)V 2 898 897 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCount([Lorg/apache/hadoop/hdfs/server/namenode/INode;IJJZ)V 1 1475 
org.apache.hadoop.yarn.webapp.Router.lookupRoute(Lorg/apache/hadoop/yarn/webapp/WebApp$HTTP;Ljava/lang/String;)Lorg/apache/hadoop/yarn/webapp/Router$Dest; 1 147 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceStorage.recoverTransitionRead(Lorg/apache/hadoop/hdfs/server/datanode/DataNode;Lorg/apache/hadoop/hdfs/server/protocol/NamespaceInfo;Ljava/util/Collection;Lorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$StartupOption;)V 2 100 140 
org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram.getReportDetails()Ljava/lang/String; 1 138 
org.apache.hadoop.hdfs.server.balancer.Balancer.chooseNodes()J 1 899 
org.apache.hadoop.mapred.join.CompositeInputSplit.write(Ljava/io/DataOutput;)V 2 119 122 
org.apache.hadoop.security.SecurityUtil.getTokenInfo(Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/security/token/TokenInfo; 2 374 383 
org.apache.hadoop.mapreduce.Job.printTaskEvents([Lorg/apache/hadoop/mapreduce/TaskCompletionEvent;Lorg/apache/hadoop/mapreduce/Job$TaskStatusFilter;ZLorg/apache/hadoop/conf/Configuration$IntegerRanges;Lorg/apache/hadoop/conf/Configuration$IntegerRanges;)V 2 1379 1361 
org.apache.hadoop.util.Progress.addPhases(I)V 1 109 
org.apache.hadoop.conf.Configuration.asXmlDocument()Lorg/w3c/dom/Document; 2 2038 2061 
org.apache.hadoop.ipc.WritableRpcEngine$Invocation.toString()Ljava/lang/String; 1 150 
org.apache.hadoop.mapreduce.util.ProcfsBasedProcessTree.getProcessTreeDump()Ljava/lang/String; 1 367 
org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run()V 3 1005 984 1085 
org.apache.hadoop.mapreduce.v2.util.MRApps.parseTimeStamps([Ljava/lang/String;)[J 1 248 
org.apache.hadoop.metrics2.impl.SinkQueue.waitForData()Ljava/lang/Object; 1 113 
org.apache.hadoop.mapreduce.v2.util.MRApps.getFileSizes(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)[J 1 372 
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.readFields(Ljava/io/DataInput;)V 1 152 
org.apache.hadoop.mapreduce.filecache.DistributedCache.getArchiveClassPaths(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/fs/Path; 1 374 
org.apache.hadoop.mapreduce.v2.util.MRApps.parseDistributedCacheArtifacts(Lorg/apache/hadoop/conf/Configuration;Ljava/util/Map;Lorg/apache/hadoop/yarn/api/records/LocalResourceType;[Ljava/net/URI;[J[J[Z[Lorg/apache/hadoop/fs/Path;)V 2 320 327 
org.apache.hadoop.hdfs.server.common.Storage.unlockAll()V 1 890 
org.apache.hadoop.fs.viewfs.ViewFs.getMountPoints()[Lorg/apache/hadoop/fs/viewfs/ViewFs$MountPoint; 1 568 
org.apache.hadoop.mapreduce.filecache.DistributedCache.getFileClassPaths(Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/fs/Path; 1 320 
org.apache.hadoop.io.compress.BlockCompressorStream.write([BII)V 3 113 109 130 
org.apache.hadoop.hdfs.DFSClient.getFileChecksum(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ClientProtocol;Ljavax/net/SocketFactory;I)Lorg/apache/hadoop/fs/MD5MD5CRC32FileChecksum; 2 1377 1361 
org.apache.hadoop.hdfs.DFSClient.closeAllFilesBeingWritten(Z)V 1 525 
org.apache.hadoop.hdfs.SocketCache.clear()V 1 118 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.stopMetricsMBeans()V 1 308 
org.apache.hadoop.mapreduce.lib.join.InnerJoinRecordReader.combine([Ljava/lang/Object;Lorg/apache/hadoop/mapreduce/lib/join/TupleWritable;)Z 1 47 
org.apache.hadoop.hdfs.DFSUtil.isValidName(Ljava/lang/String;)Z 1 124 
org.apache.hadoop.hdfs.DFSUtil.getNameServiceId(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)Ljava/lang/String; 1 769 
org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector.next(Lorg/apache/hadoop/mapred/join/TupleWritable;)Z 4 230 244 253 258 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.datanodeDump(Ljava/io/PrintWriter;)V 1 254 
org.apache.hadoop.hdfs.server.namenode.NameNode.activate(Lorg/apache/hadoop/conf/Configuration;)V 1 397 
org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/commons/cli/CommandLine;)V 2 276 305 
org.apache.hadoop.ipc.Server$Responder.waitPending()V 1 904 
org.apache.hadoop.ipc.Server$Responder.doPurge(Lorg/apache/hadoop/ipc/Server$Call;J)V 1 784 
org.apache.hadoop.net.NetUtils.normalizeHostNames(Ljava/util/Collection;)Ljava/util/List; 1 545 
org.apache.hadoop.net.CachedDNSToSwitchMapping.getUncachedHosts(Ljava/util/List;)Ljava/util/List; 1 61 
org.apache.hadoop.net.CachedDNSToSwitchMapping.cacheResolvedHosts(Ljava/util/List;Ljava/util/List;)V 1 81 
org.apache.hadoop.net.CachedDNSToSwitchMapping.getCachedHosts(Ljava/util/List;)Ljava/util/List; 1 95 
org.apache.hadoop.fs.kfs.KFSImpl.readdirplus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 2 75 82 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.TaskCounterGroupInfo.<init>(Ljava/lang/String;Lorg/apache/hadoop/mapreduce/CounterGroup;)V 1 44 
org.apache.hadoop.hdfs.server.namenode.FSImageSerialization.saveINode2Image(Lorg/apache/hadoop/hdfs/server/namenode/INode;Ljava/io/DataOutputStream;)V 1 191 
org.apache.hadoop.mapreduce.lib.db.DateSplitter.split(Lorg/apache/hadoop/conf/Configuration;Ljava/sql/ResultSet;Ljava/lang/String;)Ljava/util/List; 1 92 
org.apache.hadoop.hdfs.server.namenode.FSImageFormat$Saver.saveImage(Ljava/nio/ByteBuffer;Lorg/apache/hadoop/hdfs/server/namenode/INodeDirectory;Ljava/io/DataOutputStream;)V 2 617 621 
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$PathIterator.advance()V 1 470 
org.apache.hadoop.io.ArrayPrimitiveWritable.readCharArray(Ljava/io/DataInput;)V 1 308 
org.apache.hadoop.io.ArrayPrimitiveWritable.writeCharArray(Ljava/io/DataOutput;)V 1 262 
org.apache.hadoop.io.ArrayPrimitiveWritable.writeShortArray(Ljava/io/DataOutput;)V 1 272 
org.apache.hadoop.io.ArrayPrimitiveWritable.writeIntArray(Ljava/io/DataOutput;)V 1 278 
org.apache.hadoop.io.ArrayPrimitiveWritable.writeLongArray(Ljava/io/DataOutput;)V 1 284 
org.apache.hadoop.io.ArrayPrimitiveWritable.writeDoubleArray(Ljava/io/DataOutput;)V 1 296 
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.GetAllApplicationsResponsePBImpl.initLocalApplicationsList()V 1 105 
org.apache.hadoop.mapreduce.lib.partition.InputSampler$IntervalSampler.getSample(Lorg/apache/hadoop/mapreduce/InputFormat;Lorg/apache/hadoop/mapreduce/Job;)[Ljava/lang/Object; 2 293 287 
org.apache.hadoop.record.compiler.JRecord$CppRecord.genCode(Ljava/io/FileWriter;Ljava/io/FileWriter;Ljava/util/ArrayList;)V 11 545 552 581 588 608 631 654 675 707 742 752 
org.apache.hadoop.fs.FileSystem.listStatus(Ljava/util/ArrayList;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)V 1 1360 
org.apache.hadoop.yarn.api.records.impl.pb.QueueInfoPBImpl.initLocalApplicationsList()V 1 169 
org.apache.hadoop.io.DataOutputByteBuffer$Buffer.write([BII)V 1 59 
org.apache.hadoop.fs.s3.INode.deserialize(Ljava/io/InputStream;)Lorg/apache/hadoop/fs/s3/INode; 1 116 
org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.localGlobber(Lorg/apache/hadoop/fs/FileContext;Lorg/apache/hadoop/fs/Path;Ljava/lang/String;Lorg/apache/hadoop/fs/PathFilter;Ljava/util/concurrent/atomic/AtomicBoolean;)Ljava/util/List; 2 409 418 
org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter$FilterRecordReader.nextKeyValue()Z 1 305 
org.apache.hadoop.fs.TrashPolicyDefault$Emptier.run()V 2 254 273 
org.apache.hadoop.io.compress.DecompressorStream.skip(J)J 1 180 
org.apache.hadoop.mapred.pipes.OutputHandler.waitForFinish()Z 1 139 
org.apache.hadoop.fs.GlobExpander.expandLeftmost(Lorg/apache/hadoop/fs/GlobExpander$StringWithOffset;)Ljava/util/List; 2 87 128 
org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.selectFields([Ljava/lang/String;Ljava/util/List;ILjava/lang/String;)Ljava/lang/String; 2 124 135 
org.apache.hadoop.mapred.SequenceFileOutputFormat.getReaders(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/io/SequenceFile$Reader; 1 93 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handleCleanupContainerResources(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/localizer/event/ContainerLocalizationCleanupEvent;)V 3 371 368 381 
org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.close()V 1 962 
org.apache.hadoop.ipc.Server$Listener.run()V 3 508 503 545 
org.apache.hadoop.mapreduce.jobhistory.EventWriter.toAvro(Lorg/apache/hadoop/mapreduce/Counters;Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/jobhistory/JhCounters; 2 106 101 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(Ljava/util/List;)V 1 714 
org.apache.hadoop.fs.FileSystem.getFileStatus([Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 2112 
org.apache.hadoop.hdfs.server.datanode.BPOfferService.register()V 1 571 
org.apache.hadoop.record.compiler.generated.TokenMgrError.addEscapes(Ljava/lang/String;)Ljava/lang/String; 1 70 
org.apache.hadoop.hdfs.protocol.DirectoryListing.write(Ljava/io/DataOutput;)V 1 135 
org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppInitDoneTransition.transition(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationImpl;Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationEvent;)V 1 277 
org.apache.hadoop.security.UserGroupInformation.getTGT()Ljavax/security/auth/kerberos/KerberosTicket; 1 545 
org.apache.hadoop.fs.FSOutputSummer.write([BII)V 1 90 
org.apache.hadoop.record.compiler.generated.Rcc.generateParseException()Lorg/apache/hadoop/record/compiler/generated/ParseException; 5 504 513 511 523 531 
org.apache.hadoop.hdfs.server.datanode.FSDataset.invalidate(Ljava/lang/String;[Lorg/apache/hadoop/hdfs/protocol/Block;)V 1 2007 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.initDirs(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/fs/FileContext;Ljava/util/List;)V 1 377 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogGroup.getBestNonCorruptLog()Lorg/apache/hadoop/hdfs/server/namenode/FileJournalManager$EditLogFile; 2 287 293 
org.apache.hadoop.mapred.lib.Chain.configure(Lorg/apache/hadoop/mapred/JobConf;)V 1 178 
org.apache.hadoop.mapred.LocalContainerLauncher.<init>(Lorg/apache/hadoop/mapreduce/v2/app/AppContext;Lorg/apache/hadoop/mapred/TaskUmbilicalProtocol;)V 1 100 
org.apache.hadoop.fs.FileUtil.stat2Paths([Lorg/apache/hadoop/fs/FileStatus;)[Lorg/apache/hadoop/fs/Path; 1 57 
org.apache.hadoop.hdfs.server.namenode.LeaseManager.checkLeases()V 3 410 426 395 
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.size()I 1 232 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.scan()V 1 633 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$JobListCache.addIfAbsent(Lorg/apache/hadoop/mapreduce/v2/hs/HistoryFileManager$HistoryFileInfo;)Lorg/apache/hadoop/mapreduce/v2/hs/HistoryFileManager$HistoryFileInfo; 1 159 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks$BlockIterator.<init>(Lorg/apache/hadoop/hdfs/server/blockmanagement/UnderReplicatedBlocks;)V 1 330 
org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 2 71 75 
org.apache.hadoop.yarn.applications.distributedshell.Client.monitorApplication(Lorg/apache/hadoop/yarn/api/records/ApplicationId;)Z 1 631 
org.apache.hadoop.fs.s3.MigrationTool$UnversionedStore.listAllPaths()Ljava/util/Set; 1 203 
org.apache.hadoop.security.authorize.AccessControlList.isUserAllowed(Lorg/apache/hadoop/security/UserGroupInformation;)Z 1 221 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getInputPaths(Lorg/apache/hadoop/mapreduce/JobContext;)[Lorg/apache/hadoop/fs/Path; 1 445 
org.apache.hadoop.net.NetworkTopology$InnerNode.getLoc(Ljava/lang/String;)Lorg/apache/hadoop/net/Node; 1 238 
org.apache.hadoop.util.DataChecksum.verifyChunkedSums([BII[BILjava/lang/String;J)V 1 333 
org.apache.hadoop.net.NetworkTopology$InnerNode.getLeaf(ILorg/apache/hadoop/net/Node;)Lorg/apache/hadoop/net/Node; 1 281 
org.apache.hadoop.yarn.webapp.hamlet.HamletGen.echo(I[Ljava/lang/Object;)V 1 393 
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.size()I 1 195 
org.apache.hadoop.hdfs.server.namenode.INode.getPathComponents([Ljava/lang/String;)[[B 1 355 
org.apache.hadoop.http.HtmlQuoting.quoteHtmlChars(Ljava/io/OutputStream;[BII)V 1 80 
org.apache.hadoop.hdfs.server.namenode.INode.compareBytes([B[B)I 1 435 
org.apache.hadoop.hdfs.server.namenode.INode.constructPath([[BII)Ljava/lang/String; 1 382 
org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Lorg/apache/hadoop/mapreduce/task/reduce/MapHost;)V 6 257 269 282 288 301 301 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseReplicaToDelete(Lorg/apache/hadoop/hdfs/server/namenode/FSInodeInfo;Lorg/apache/hadoop/hdfs/protocol/Block;SLjava/util/Collection;Ljava/util/Collection;)Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 565 
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch$ShellScriptBuilder.line([Ljava/lang/String;)V 1 468 
org.apache.hadoop.fs.shell.Stat.processPath(Lorg/apache/hadoop/fs/shell/PathData;)V 1 82 
org.apache.hadoop.hdfs.LeaseRenewer.addClient(Lorg/apache/hadoop/hdfs/DFSClient;)V 1 214 
org.apache.hadoop.metrics.spi.AbstractMetricsContext.emitRecords()V 2 317 313 
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getNodeStatus()Lorg/apache/hadoop/yarn/server/api/records/NodeStatus; 1 247 
org.apache.hadoop.ipc.Client$Connection.setupIOstreams()V 1 556 
org.apache.hadoop.mapred.pipes.Submitter.run([Ljava/lang/String;)I 1 478 
org.apache.hadoop.yarn.server.nodemanager.NodeHealthScriptRunner$NodeHealthMonitorExecutor.hasErrors(Ljava/lang/String;)Z 1 179 
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.trackAppsForKeepAlive(Ljava/util/List;)V 1 290 
org.apache.hadoop.mapred.lib.MultipleOutputs.getNamedOutputsList(Lorg/apache/hadoop/mapred/JobConf;)Ljava/util/List; 1 209 
org.apache.hadoop.fs.shell.PathData.relativize(Ljava/net/URI;Ljava/net/URI;Z)Ljava/lang/String; 1 350 
org.apache.hadoop.fs.ftp.FTPFileSystem.listStatus(Lorg/apache/commons/net/ftp/FTPClient;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 370 
org.apache.hadoop.io.file.tfile.Compression.getCompressionAlgorithmByName(Ljava/lang/String;)Lorg/apache/hadoop/io/file/tfile/Compression$Algorithm; 1 348 
org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.initSplit([Lorg/apache/hadoop/fs/Path;[J[J[Ljava/lang/String;)V 1 84 
org.apache.hadoop.io.file.tfile.TFile$TFileIndex.<init>(ILjava/io/DataInput;Lorg/apache/hadoop/io/file/tfile/CompareUtils$BytesComparator;)V 1 2152 
org.apache.hadoop.metrics2.impl.MetricsCollectorImpl.getRecords()Ljava/util/List; 1 54 
org.apache.hadoop.io.compress.CompressorStream.finish()V 1 89 
org.apache.hadoop.io.Text.utf8Length(Ljava/lang/String;)I 1 588 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.makeMaps()V 1 258 
org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.createHuffmanDecodingTables(II)V 2 781 777 
org.apache.hadoop.io.MapWritable.putAll(Ljava/util/Map;)V 1 126 
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalizerHeartbeatResponsePBImpl.initResources()V 1 117 
org.apache.hadoop.util.bloom.CountingBloomFilter.approximateCount(Lorg/apache/hadoop/util/bloom/Key;)I 1 224 
org.apache.hadoop.mapred.ReduceTask$OldTrackingRecordWriter.getOutputBytes(Ljava/util/List;)J 1 520 
org.apache.hadoop.mapred.JobConf.deleteLocalFiles()V 1 470 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.rampDownReduces(I)V 1 520 
org.apache.hadoop.mapreduce.v2.app.speculate.ExponentiallySmoothedTaskRuntimeEstimator.incorporateReading(Lorg/apache/hadoop/mapreduce/v2/api/records/TaskAttemptId;FJ)V 1 116 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedRenameTo(Ljava/lang/String;Ljava/lang/String;J[Lorg/apache/hadoop/fs/Options$Rename;)Z 1 728 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.getFullPathName([Lorg/apache/hadoop/hdfs/server/namenode/INode;I)Ljava/lang/String; 1 1525 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuota([Lorg/apache/hadoop/hdfs/server/namenode/INode;IJJLorg/apache/hadoop/hdfs/server/namenode/INode;)V 1 1724 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.selectBestAttempt()Lorg/apache/hadoop/mapreduce/v2/app/job/TaskAttempt; 1 493 
org.apache.hadoop.hdfs.tools.DelegationTokenFetcher.getDTfromRemote(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/security/Credentials; 1 224 
org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner.deleteBlocks([Lorg/apache/hadoop/hdfs/protocol/Block;)V 1 296 
org.apache.hadoop.util.bloom.DynamicBloomFilter.readFields(Ljava/io/DataInput;)V 1 265 
org.apache.hadoop.fs.AbstractFileSystem.rename(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;[Lorg/apache/hadoop/fs/Options$Rename;)V 1 643 
org.apache.hadoop.log.LogLevel.process(Ljava/lang/String;)V 1 72 
org.apache.hadoop.mapred.pipes.PipesReducer.reduce(Lorg/apache/hadoop/io/WritableComparable;Ljava/util/Iterator;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 66 
org.apache.hadoop.hdfs.server.datanode.DataStorage.makeBlockPoolDataDir(Ljava/util/Collection;Lorg/apache/hadoop/conf/Configuration;)V 1 259 
org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.write(Ljava/io/DataOutput;)V 3 163 167 171 
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.setKeys(Lorg/apache/hadoop/hdfs/security/token/block/ExportedBlockKeys;)V 1 146 
org.apache.hadoop.metrics.jvm.JvmMetrics.doGarbageCollectionUpdates()V 1 126 
org.apache.hadoop.mapred.SequenceFileInputFormat.listStatus(Lorg/apache/hadoop/mapred/JobConf;)[Lorg/apache/hadoop/fs/FileStatus; 1 46 
org.apache.hadoop.mapred.join.WrappedRecordReader.accept(Lorg/apache/hadoop/mapred/join/CompositeRecordReader$JoinCollector;Lorg/apache/hadoop/io/WritableComparable;)V 1 133 
org.apache.hadoop.hdfs.server.namenode.BackupImage.recoverCreateRead()V 1 101 
org.apache.hadoop.yarn.server.nodemanager.webapp.dao.AppInfo.<init>(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/Application;)V 1 51 
org.apache.hadoop.conf.Configuration.getInstances(Ljava/lang/String;Ljava/lang/Class;)Ljava/util/List; 1 1592 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.getNodes(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;)[Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 2388 
org.apache.hadoop.security.SaslInputStream.read([BII)I 1 248 
org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser$JobInfo.printAll()V 2 466 470 
org.apache.hadoop.util.GenericOptionsParser.validateFiles(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Ljava/lang/String; 1 373 
org.apache.hadoop.util.GenericOptionsParser.getLibJars(Lorg/apache/hadoop/conf/Configuration;)[Ljava/net/URL; 1 345 
org.apache.hadoop.mapreduce.jobhistory.EventReader.fromAvro(Lorg/apache/hadoop/mapreduce/jobhistory/JhCounters;)Lorg/apache/hadoop/mapreduce/Counters; 2 174 171 
org.apache.hadoop.mapreduce.jobhistory.AvroArrayUtils.fromAvro(Ljava/util/List;)[I 1 52 
org.apache.hadoop.hdfs.server.namenode.FSImageStorageInspector$LoadPlan.toString()Ljava/lang/String; 1 90 
org.apache.hadoop.metrics2.sink.FileSink.putMetrics(Lorg/apache/hadoop/metrics2/MetricsRecord;)V 2 65 72 
org.apache.hadoop.hdfs.server.blockmanagement.Host2NodesMap.contains(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)Z 1 47 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$1.run()V 1 174 
org.apache.hadoop.yarn.webapp.hamlet.HamletGen.genFactoryMethods(Ljava/lang/Class;I)V 1 172 
org.apache.hadoop.record.meta.StructTypeID.writeRest(Lorg/apache/hadoop/record/RecordOutput;Ljava/lang/String;)V 1 89 
org.apache.hadoop.util.bloom.DynamicBloomFilter.and(Lorg/apache/hadoop/util/bloom/Filter;)V 1 169 
org.apache.hadoop.io.AbstractMapWritable.write(Ljava/io/DataOutput;)V 1 184 
org.apache.hadoop.ipc.Client$Connection$PingInputStream.read()I 1 353 
org.apache.hadoop.record.Utils.fromXMLString(Ljava/lang/String;)Ljava/lang/String; 1 95 
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.stop()V 1 137 
org.apache.hadoop.util.StringUtils.split(Ljava/lang/String;C)[Ljava/lang/String; 2 417 424 
org.apache.hadoop.io.compress.bzip2.CRC.updateCRC(II)V 1 116 
org.apache.hadoop.ipc.Server$Listener.doAccept(Ljava/nio/channels/SelectionKey;)V 1 571 
org.apache.hadoop.ipc.Server$Listener.cleanupConnections(Z)V 1 477 
org.apache.hadoop.mapred.FileInputFormat.getInputPaths(Lorg/apache/hadoop/mapred/JobConf;)[Lorg/apache/hadoop/fs/Path; 1 441 
org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.readFields(Ljava/io/DataInput;)V 1 118 
org.apache.hadoop.mapred.FileInputFormat.addInputPathRecursively(Ljava/util/List;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/PathFilter;)V 1 163 
org.apache.hadoop.fs.viewfs.ViewFileSystem.setVerifyChecksum(Z)V 1 467 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.getContainerReqToReplace(Lorg/apache/hadoop/yarn/api/records/Container;)Lorg/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor$ContainerRequest; 1 860 
org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.maybeScheduleASpeculation(Lorg/apache/hadoop/mapreduce/v2/api/records/TaskType;)I 2 448 476 
org.apache.hadoop.hdfs.server.datanode.BlockSender.verifyChecksum([BIIII)V 1 549 
org.apache.hadoop.hdfs.util.DataTransferThrottler.throttle(J)V 1 89 
org.apache.hadoop.record.compiler.JRecord$JavaRecord.genCode(Ljava/lang/String;Ljava/util/ArrayList;)V 15 198 207 220 229 251 261 274 289 315 354 377 391 403 427 443 
org.apache.hadoop.io.WritableUtils.readCompressedByteArray(Ljava/io/DataInput;)[B 1 44 
org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.relocalize()V 1 423 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks.contains(Lorg/apache/hadoop/hdfs/protocol/Block;)Z 1 129 
org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner.inBlockAdvance(Lorg/apache/hadoop/io/file/tfile/RawComparable;Z)Z 1 2008 
org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.saveAllKeys(Ljava/io/DataOutputStream;)V 1 246 
org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.saveCurrentTokens(Ljava/io/DataOutputStream;)V 1 231 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.getReport()Lorg/apache/hadoop/mapreduce/v2/api/records/TaskReport; 3 372 382 380 
org.apache.hadoop.util.bloom.CountingBloomFilter.toString()Ljava/lang/String; 1 273 
org.apache.hadoop.ipc.RPC.waitForProtocolProxy(Ljava/lang/Class;JLjava/net/InetSocketAddress;Lorg/apache/hadoop/conf/Configuration;IJ)Lorg/apache/hadoop/ipc/ProtocolProxy; 1 278 
org.apache.hadoop.io.TwoDArrayWritable.toArray()Ljava/lang/Object; 2 49 46 
org.apache.hadoop.mapred.Task$ValuesIterator.nextKey()V 1 1348 
org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._p(Z[Ljava/lang/Object;)V 1 103 
org.apache.hadoop.hdfs.server.datanode.FSDataset.<init>(Lorg/apache/hadoop/hdfs/server/datanode/DataNode;Lorg/apache/hadoop/hdfs/server/datanode/DataStorage;Lorg/apache/hadoop/conf/Configuration;)V 2 1105 1122 
org.apache.hadoop.mapreduce.lib.join.TupleWritable.equals(Ljava/lang/Object;)Z 1 100 
org.apache.hadoop.fs.TrashPolicyDefault.createCheckpoint()V 1 167 
org.apache.hadoop.record.compiler.generated.Rcc.getToken(I)Lorg/apache/hadoop/record/compiler/generated/Token; 1 483 
org.apache.hadoop.hdfs.server.namenode.BackupImage.waitUntilNamespaceFrozen()V 1 368 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.mainSort()V 17 1744 1753 1756 1764 1770 1774 1786 1798 1793 1791 1826 1847 1851 1860 1878 1882 1813 
org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$MRClientProtocolHandler.getTaskReports(Lorg/apache/hadoop/mapreduce/v2/api/protocolrecords/GetTaskReportsRequest;)Lorg/apache/hadoop/mapreduce/v2/api/protocolrecords/GetTaskReportsResponse; 1 296 
org.apache.hadoop.mapred.LocalJobRunner$Job.getCurrentCounters()Lorg/apache/hadoop/mapred/Counters; 1 533 
org.apache.hadoop.yarn.util.Graph.combineEdges(Ljava/util/List;)Ljava/util/List; 2 196 194 
org.apache.hadoop.io.SequenceFile$Metadata.readFields(Ljava/io/DataInput;)V 1 745 
org.apache.hadoop.io.ArrayPrimitiveWritable.readShortArray(Ljava/io/DataInput;)V 1 318 
org.apache.hadoop.mapreduce.tools.CLI.listBlacklistedTrackers(Lorg/apache/hadoop/mapreduce/Cluster;)V 1 525 
org.apache.hadoop.hdfs.util.LightWeightGSet.remove(ILjava/lang/Object;)Ljava/lang/Object; 1 188 
org.apache.hadoop.hdfs.server.balancer.Balancer.initNodes([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)J 2 804 819 
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit()V 1 326 
org.apache.hadoop.ipc.Client$Connection.setupConnection()V 1 435 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsTaskPage$AttemptsBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 112 
org.apache.hadoop.mapred.jobcontrol.JobControl.addJobs(Ljava/util/Collection;)V 1 88 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.reconcile()V 2 316 312 
org.apache.hadoop.mapred.JobClient$NetworkedJob.getTaskCompletionEvents(I)[Lorg/apache/hadoop/mapred/TaskCompletionEvent; 1 373 
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.start()V 1 120 
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.confChanged(Lorg/apache/hadoop/conf/Configuration;)V 1 274 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.incrTaskCounters(Lorg/apache/hadoop/mapreduce/Counters;Ljava/util/Collection;)Lorg/apache/hadoop/mapreduce/Counters; 1 513 
org.apache.hadoop.yarn.server.nodemanager.DeletionService$FileDeletion.run()V 1 139 
org.apache.hadoop.conf.Configuration.toString(Ljava/util/List;Ljava/lang/StringBuilder;)V 1 2149 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.activateApplications()V 1 653 
org.apache.hadoop.mapred.lib.MultipleInputs.getMapperTypeMap(Lorg/apache/hadoop/mapred/JobConf;)Ljava/util/Map; 1 123 
org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices.getNodeApps(Ljava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/yarn/server/nodemanager/webapp/dao/AppsInfo; 1 102 
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$RenameOp.readRenameOptions(Ljava/io/DataInputStream;)[Lorg/apache/hadoop/fs/Options$Rename; 1 1083 
org.apache.hadoop.io.FastByteComparisons$LexicographicalComparerHolder$PureJavaComparer.compareTo([BII[BII)I 1 102 
org.apache.hadoop.mapreduce.TaskReport.readFields(Ljava/io/DataInput;)V 1 221 
org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.write(Ljava/io/DataOutput;)V 1 164 
org.apache.hadoop.metrics.spi.CompositeContext.unregisterUpdater(Lorg/apache/hadoop/metrics/Updater;)V 1 163 
org.apache.hadoop.hdfs.tools.JMXGet.main([Ljava/lang/String;)V 1 331 
org.apache.hadoop.hdfs.server.balancer.Balancer$PendingBlockMove.chooseProxySource()Z 2 282 291 
org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices.getMeta()Ljava/util/Map; 1 77 
org.apache.hadoop.record.Buffer.compareTo(Ljava/lang/Object;)I 1 209 
org.apache.hadoop.io.SequenceFile$Sorter.merge([Lorg/apache/hadoop/fs/Path;ZILorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/io/SequenceFile$Sorter$RawKeyValueIterator; 1 2977 
org.apache.hadoop.record.meta.Utils.skip(Lorg/apache/hadoop/record/RecordInput;Ljava/lang/String;Lorg/apache/hadoop/record/meta/TypeID;)V 3 71 85 94 
org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest.checkState()V 1 57 
org.apache.hadoop.io.DataInputByteBuffer$Buffer.reset([Ljava/nio/ByteBuffer;)V 1 59 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.fetchDatanodes(Ljava/util/List;Ljava/util/List;Z)V 1 760 
org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(Lorg/apache/hadoop/security/Credentials;[Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;)V 2 97 100 
org.apache.hadoop.yarn.webapp.hamlet.HamletGen.indent(I)V 1 406 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.processFirstBlockReport(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Lorg/apache/hadoop/hdfs/protocol/BlockListAsLongs;)V 1 1431 
org.apache.hadoop.hdfs.security.token.block.BlockTokenSecretManager.removeExpiredKeys()V 1 127 
org.apache.hadoop.hdfs.LeaseRenewer.closeFile(Ljava/lang/String;Lorg/apache/hadoop/hdfs/DFSClient;)V 1 335 
org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.getCounters(Lorg/apache/hadoop/mapreduce/v2/app/AppContext;)V 1 190 
org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.createKeepAliveApplicationList()Ljava/util/List; 1 223 
org.apache.hadoop.fs.shell.PathData.findLongestDirPrefix(Ljava/lang/String;Ljava/lang/String;Z)I 1 371 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.mkdirs(Ljava/lang/String;Lorg/apache/hadoop/fs/permission/PermissionStatus;ZJ)Z 2 1582 1623 
org.apache.hadoop.fs.TrashPolicyDefault.deleteCheckpoint()V 1 191 
org.apache.hadoop.conf.Configuration$IntegerRanges.<init>(Ljava/lang/String;)V 1 1204 
org.apache.hadoop.util.bloom.CountingBloomFilter.write(Ljava/io/DataOutput;)V 1 296 
org.apache.hadoop.metrics.ganglia.GangliaContext.emitRecord(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/metrics/spi/OutputRecord;)V 1 146 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.findNextResource()Lorg/apache/hadoop/yarn/api/records/LocalResource; 1 739 
org.apache.hadoop.hdfs.server.namenode.INodeFile.diskspaceConsumed([Lorg/apache/hadoop/hdfs/protocol/Block;)J 1 214 
org.apache.hadoop.fs.FileContext.getDelegationTokens(Lorg/apache/hadoop/fs/Path;Ljava/lang/String;)Ljava/util/List; 1 2401 
org.apache.hadoop.mapreduce.task.reduce.MergeManager.createInMemorySegments(Ljava/util/List;Ljava/util/List;J)J 2 595 598 
org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector.clear()V 1 207 
org.apache.hadoop.security.UserGroupInformation.print()V 1 1244 
org.apache.hadoop.mapred.JobClient.getJobsFromQueue(Ljava/lang/String;)[Lorg/apache/hadoop/mapred/JobStatus; 1 1135 
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.ifExists(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Z 1 529 
org.apache.hadoop.mapred.JobClient.arrayToBlackListInfo([Lorg/apache/hadoop/mapreduce/TaskTrackerInfo;)Ljava/util/Collection; 1 791 
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.getContainerPid(Lorg/apache/hadoop/fs/Path;)Ljava/lang/String; 1 393 
org.apache.hadoop.hdfs.BlockReaderUtil.readFully(Lorg/apache/hadoop/hdfs/BlockReader;[BII)V 1 45 
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.warnForDeprecatedConfigs(Lorg/apache/hadoop/conf/Configuration;)V 1 302 
org.apache.hadoop.metrics2.lib.MutableRates.init(Ljava/lang/Class;)V 1 57 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeListForReport(Lorg/apache/hadoop/hdfs/protocol/HdfsConstants$DatanodeReportType;)Ljava/util/List; 4 798 802 813 838 
org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.lostFoundMove(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/HdfsFileStatus;Lorg/apache/hadoop/hdfs/protocol/LocatedBlocks;)V 1 429 
org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo; 1 70 
org.apache.hadoop.mapred.lib.MultipleOutputs.checkTokenName(Ljava/lang/String;)V 1 170 
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.writeCredentials(Lorg/apache/hadoop/fs/Path;)V 1 900 
org.apache.hadoop.io.compress.BlockDecompressorStream.decompress([BII)I 1 87 
org.apache.hadoop.mapred.MapReduceChildJVM.setVMEnv(Ljava/util/Map;Lorg/apache/hadoop/mapred/Task;)V 1 99 
org.apache.hadoop.mapred.MapTask$SkippingRecordReader.next(Ljava/lang/Object;Ljava/lang/Object;)Z 1 254 
org.apache.hadoop.record.Utils.toBinaryString(Ljava/io/DataOutput;Ljava/lang/String;)V 1 318 
org.apache.hadoop.fs.FSInputChecker.readFully(Ljava/io/InputStream;[BII)I 1 431 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.getDfsUsed()J 1 568 
org.apache.hadoop.hdfs.RemoteBlockReader2.skip(J)J 1 238 
org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.replaceBlock(Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;)Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo; 1 201 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getQueueInfo(ZZ)Lorg/apache/hadoop/yarn/api/records/QueueInfo; 1 305 
org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices.getJobAttempts(Ljava/lang/String;)Lorg/apache/hadoop/mapreduce/v2/app/webapp/dao/AMAttemptsInfo; 1 254 
org.apache.hadoop.record.compiler.generated.Rcc.Record()Lorg/apache/hadoop/record/compiler/JRecord; 1 255 
org.apache.hadoop.mapreduce.counters.AbstractCounters.readFields(Ljava/io/DataInput;)V 2 292 309 
org.apache.hadoop.hdfs.server.balancer.Balancer.chooseTargets(Ljava/util/Iterator;Z)V 2 940 938 
org.apache.hadoop.hdfs.server.balancer.Balancer.chooseSources(Ljava/util/Iterator;Z)V 2 958 956 
org.apache.hadoop.record.compiler.JavaGenerator.genCode(Ljava/lang/String;Ljava/util/ArrayList;Ljava/util/ArrayList;Ljava/lang/String;Ljava/util/ArrayList;)V 1 45 
org.apache.hadoop.mapred.StatisticsCollector$StatUpdater.update()V 1 249 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.getBlocksWithLocations(Lorg/apache/hadoop/hdfs/protocol/DatanodeID;J)Lorg/apache/hadoop/hdfs/server/protocol/BlocksWithLocations; 3 742 748 755 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.getMetrics(Lorg/apache/hadoop/metrics2/MetricsCollector;Z)V 1 519 
org.apache.hadoop.hdfs.server.common.JspHelper.bestNode([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;ZLorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 2 163 160 
org.apache.hadoop.yarn.api.records.impl.pb.QueueUserACLInfoPBImpl.initLocalQueueUserAclsList()V 1 97 
org.apache.hadoop.security.SecurityUtil.getTgtFromSubject()Ljavax/security/auth/kerberos/KerberosTicket; 1 102 
org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run()V 4 426 398 478 532 
org.apache.hadoop.util.StringUtils.arrayToString([Ljava/lang/String;)Ljava/lang/String; 1 143 
org.apache.hadoop.hdfs.tools.offlineEditsViewer.EditsLoaderCurrent.visit_OP_CONCAT_DELETE()V 1 319 
org.apache.hadoop.mapreduce.lib.input.MultipleInputs.getMapperTypeMap(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/Map; 1 137 
org.apache.hadoop.util.bloom.DynamicBloomFilter.or(Lorg/apache/hadoop/util/bloom/Filter;)V 1 210 
org.apache.hadoop.util.bloom.BloomFilter.readFields(Ljava/io/DataInput;)V 1 224 
org.apache.hadoop.metrics2.filter.AbstractPatternFilter.accepts(Ljava/lang/Iterable;)Z 2 124 131 
org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner.inBlockAdvance(J)V 1 1979 
org.apache.hadoop.io.compress.DecompressorStream.decompress([BII)I 1 89 
org.apache.hadoop.mapreduce.lib.map.RegexMapper.map(Ljava/lang/Object;Lorg/apache/hadoop/io/Text;Lorg/apache/hadoop/mapreduce/Mapper$Context;)V 1 54 
org.apache.hadoop.mapred.pipes.PipesMapRunner.run(Lorg/apache/hadoop/mapred/RecordReader;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 89 
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/fs/Path; 1 436 
org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.FifoSchedulerInfo.<init>(Lorg/apache/hadoop/yarn/server/resourcemanager/ResourceManager;)V 1 80 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignToFailedMap(Lorg/apache/hadoop/yarn/api/records/Container;)Lorg/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor$ContainerRequest; 1 895 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.removeNode(Lorg/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNode;)V 1 731 
org.apache.hadoop.mapreduce.util.CountersStrings.toEscapedCompactString(Lorg/apache/hadoop/mapreduce/counters/AbstractCounters;)Ljava/lang/String; 2 160 169 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assignToMap(Lorg/apache/hadoop/yarn/api/records/Container;)Lorg/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor$ContainerRequest; 3 929 950 926 
org.apache.hadoop.ipc.ProtocolSignature.write(Ljava/io/DataOutput;)V 1 90 
org.apache.hadoop.ipc.Server.start()V 1 1758 
org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppFinishTriggeredTransition.transition(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationImpl;Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationEvent;)Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/ApplicationState; 1 331 
org.apache.hadoop.io.AbstractMapWritable.readFields(Ljava/io/DataInput;)V 1 199 
org.apache.hadoop.mapred.ResourceMgrDelegate.getChildQueues(Lorg/apache/hadoop/yarn/api/records/QueueInfo;Ljava/util/List;Z)V 1 214 
org.apache.hadoop.mapreduce.TypeConverter.fromYarnQueueInfo(Ljava/util/List;Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/mapreduce/QueueInfo; 1 477 
org.apache.hadoop.fs.shell.FsUsage$TableBuilder.addRow([Ljava/lang/Object;)V 1 217 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader.readAContainerLogsForALogType(Ljava/io/DataInputStream;Ljava/io/DataOutputStream;)V 1 529 
org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.readFields(Ljava/io/DataInput;)V 1 63 
org.apache.hadoop.mapred.LocalJobRunner.setupChildMapredLocalDirs(Lorg/apache/hadoop/mapred/Task;Lorg/apache/hadoop/mapred/JobConf;)V 1 836 
org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.getOutputBytes(Ljava/util/List;)J 1 577 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources()Ljava/util/List; 2 588 596 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedConcat(Ljava/lang/String;[Ljava/lang/String;J)V 2 1065 1074 
org.apache.hadoop.mapred.TaskLog.getLogFileDetail(Lorg/apache/hadoop/mapred/TaskAttemptID;Lorg/apache/hadoop/mapred/TaskLog$LogName;Z)Lorg/apache/hadoop/mapred/TaskLog$LogFileDetail; 1 142 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.mainQSort3(Lorg/apache/hadoop/io/compress/bzip2/CBZip2OutputStream$Data;III)V 3 1658 1672 1638 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processBlocks(Ljava/io/DataInputStream;Lorg/apache/hadoop/hdfs/tools/offlineImageViewer/ImageVisitor;IZ)V 1 323 
org.apache.hadoop.mapreduce.v2.hs.CompletedJob.loadAllTasks()V 1 274 
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.ApplicationMasterLauncher$LauncherThread.run()V 1 96 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader$JoinCollector.close()V 1 324 
org.apache.hadoop.hdfs.server.datanode.BPOfferService.offerService()V 1 471 
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.write(Ljava/io/DataOutput;)V 2 260 256 
org.apache.hadoop.hdfs.server.balancer.Balancer.shuffleArray([Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)V 1 781 
org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerLogsPage$ContainersLogsBlock.printLogs(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;Lorg/apache/hadoop/yarn/api/records/ContainerId;Lorg/apache/hadoop/yarn/api/records/ApplicationId;Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/application/Application;)V 4 241 251 282 279 
org.apache.hadoop.mapreduce.TypeConverter.toYarn(Lorg/apache/hadoop/mapred/Counters;)Lorg/apache/hadoop/mapreduce/v2/api/records/Counters; 2 249 244 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNameDirStatuses()Ljava/lang/String; 2 4445 4454 
org.apache.hadoop.ipc.Client$Connection.cleanupCalls()V 1 901 
org.apache.hadoop.mapreduce.Reducer.reduce(Ljava/lang/Object;Ljava/lang/Iterable;Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 1 149 
org.apache.hadoop.ipc.WritableRpcEngine.call(Ljava/lang/reflect/Method;[[Ljava/lang/Object;[Ljava/net/InetSocketAddress;Lorg/apache/hadoop/security/UserGroupInformation;Lorg/apache/hadoop/conf/Configuration;)[Ljava/lang/Object; 2 258 271 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.removeBlockPool(Ljava/lang/String;)V 1 924 
org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase.getAggregatorDescriptors(Lorg/apache/hadoop/mapred/JobConf;)Ljava/util/ArrayList; 1 67 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobInfo.countTasksAndAttempts(Lorg/apache/hadoop/mapreduce/v2/app/job/Job;)V 2 305 277 
org.apache.hadoop.fs.s3.S3InputStream.blockSeekTo(J)V 1 151 
org.apache.hadoop.hdfs.server.namenode.NameNode.parseArguments([Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$StartupOption; 1 645 
org.apache.hadoop.hdfs.tools.JMXGet.init()V 2 183 202 
org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest.write(Ljava/io/DataOutput;)V 1 83 
org.apache.hadoop.hdfs.tools.JMXGet.printAllValues()V 2 104 99 
org.apache.hadoop.hdfs.tools.JMXGet.getValue(Ljava/lang/String;)Ljava/lang/String; 1 118 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobTaskAttemptCounterInfo.<init>(Lorg/apache/hadoop/mapreduce/v2/app/job/TaskAttempt;)V 1 52 
org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter.split(Ljava/math/BigDecimal;Ljava/math/BigDecimal;Ljava/math/BigDecimal;)Ljava/util/List; 1 137 
org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager.loadCurrentTokens(Ljava/io/DataInputStream;)V 1 258 
org.apache.hadoop.mapreduce.v2.util.MRApps.setMRFrameworkClasspath(Ljava/util/Map;Lorg/apache/hadoop/conf/Configuration;)V 1 179 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.resolveHosts([Ljava/lang/String;)[Ljava/lang/String; 1 1145 
org.apache.hadoop.net.NetUtils.verifyHostnames([Ljava/lang/String;)V 1 558 
org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/security/Credentials;Lorg/apache/hadoop/conf/Configuration;)V 1 125 
org.apache.hadoop.hdfs.SocketCache.get(Ljava/net/SocketAddress;)Ljava/net/Socket; 1 64 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoader$LoaderFactory.getLoader(I)Lorg/apache/hadoop/hdfs/tools/offlineImageViewer/ImageLoader; 1 75 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.getBlockPoolUsed(Ljava/lang/String;)J 1 827 
org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.buildTrieRec([Lorg/apache/hadoop/io/BinaryComparable;II[BILorg/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner$CarriedTrieNodeRef;)Lorg/apache/hadoop/mapreduce/lib/partition/TotalOrderPartitioner$TrieNode; 2 394 391 
org.apache.hadoop.mapreduce.counters.AbstractCounters.incrAllCounters(Lorg/apache/hadoop/mapreduce/counters/AbstractCounters;)V 1 340 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getCompleteBlocksTotal()J 3 3386 3400 3385 
org.apache.hadoop.hdfs.tools.offlineEditsViewer.EditsLoaderCurrent.canLoadVersion(I)Z 1 64 
org.apache.hadoop.mapred.Merger$MergeQueue.merge(Ljava/lang/Class;Ljava/lang/Class;IILorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/mapred/Counters$Counter;Lorg/apache/hadoop/util/Progress;)Lorg/apache/hadoop/mapred/RawKeyValueIterator; 6 589 587 620 635 663 575 
org.apache.hadoop.ipc.Server$Connection.readAndProcess()I 1 1178 
org.apache.hadoop.metrics.ganglia.GangliaContext.emitMetric(Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)V 1 176 
org.apache.hadoop.mapreduce.v2.app.webapp.dao.TaskAttemptInfo.<init>(Lorg/apache/hadoop/mapreduce/v2/app/job/TaskAttempt;Lorg/apache/hadoop/mapreduce/v2/api/records/TaskType;Ljava/lang/Boolean;)V 1 82 
org.apache.hadoop.fs.viewfs.ViewFs.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 407 
org.apache.hadoop.hdfs.server.namenode.LeaseManager.removeLeaseWithPrefixPath(Ljava/lang/String;)V 1 326 
org.apache.hadoop.hdfs.server.protocol.BlockCommand.<init>(ILjava/lang/String;Ljava/util/List;)V 1 64 
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.toString()Ljava/lang/String; 1 104 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolumeSet.getVolumeMap(Lorg/apache/hadoop/hdfs/server/datanode/ReplicasMap;)V 1 851 
org.apache.hadoop.mapreduce.v2.hs.webapp.HsAttemptsPage$FewAttemptsBlock.getTaskAttempts()Ljava/util/Collection; 2 79 77 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.bsW(II)V 1 922 
org.apache.hadoop.mapred.lib.MultipleInputs.getInputFormatMap(Lorg/apache/hadoop/mapred/JobConf;)Ljava/util/Map; 1 94 
org.apache.hadoop.mapreduce.util.CountersStrings.parseEscapedCompactString(Ljava/lang/String;Lorg/apache/hadoop/mapreduce/counters/AbstractCounters;)Lorg/apache/hadoop/mapreduce/counters/AbstractCounters; 2 253 233 
org.apache.hadoop.mapred.ClusterStatus.readFields(Ljava/io/DataInput;)V 2 431 439 
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp.readFields(Ljava/io/DataInputStream;I)V 1 429 
org.apache.hadoop.yarn.state.StateMachineFactory.makeStateMachineTable()V 2 325 330 
org.apache.hadoop.mapreduce.lib.chain.Chain$ChainBlockingQueue.dequeue()Ljava/lang/Object; 1 890 
org.apache.hadoop.mapreduce.tools.CLI.listActiveTrackers(Lorg/apache/hadoop/mapreduce/Cluster;)V 1 511 
org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorCombiner.reduce(Lorg/apache/hadoop/io/Text;Ljava/lang/Iterable;Lorg/apache/hadoop/mapreduce/Reducer$Context;)V 2 55 60 
org.apache.hadoop.security.token.Token.addBinaryBuffer(Ljava/lang/StringBuilder;[B)V 1 250 
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$AddCloseOp.readDatanodeDescriptorArray(Ljava/io/DataInput;)[Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 278 
org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 4 368 382 396 389 
org.apache.hadoop.mapred.JobQueueClient.expandQueueList([Lorg/apache/hadoop/mapred/JobQueueInfo;)Ljava/util/List; 1 159 
org.apache.hadoop.fs.HarFileSystem.fileStatusesInIndex(Lorg/apache/hadoop/fs/HarFileSystem$HarStatus;Ljava/util/List;Ljava/util/List;)V 1 458 
org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler$Referee.run()V 1 415 
org.apache.hadoop.hdfs.server.namenode.LeaseManager.countPath()I 1 102 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.deleteBPDirectories(Ljava/lang/String;Z)V 2 765 773 
org.apache.hadoop.mapred.InvalidInputException.getMessage()Ljava/lang/String; 1 62 
org.apache.hadoop.util.bloom.Key.hashCode()I 1 148 
org.apache.hadoop.ipc.Server$Connection.saslReadAndProcess([B)V 1 1096 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.skip(Lorg/apache/hadoop/io/WritableComparable;)V 2 382 385 
org.apache.hadoop.yarn.webapp.log.AggregatedLogsBlock.readContainerLogs(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;Lorg/apache/hadoop/yarn/logaggregation/AggregatedLogFormat$ContainerLogsReader;Lorg/apache/hadoop/yarn/webapp/log/AggregatedLogsBlock$LogLimits;Ljava/lang/String;)Z 3 207 220 174 
org.apache.hadoop.mapreduce.lib.join.Parser$WNode.parse(Ljava/util/List;Lorg/apache/hadoop/conf/Configuration;)V 1 299 
org.apache.hadoop.hdfs.DFSOutputStream.waitForAckedSeqno(J)V 1 1578 
org.apache.hadoop.util.bloom.DynamicBloomFilter.not()V 1 191 
org.apache.hadoop.io.SequenceFile$Metadata.write(Ljava/io/DataOutput;)V 1 734 
org.apache.hadoop.security.SecurityUtil$QualifiedHostResolver.getByNameWithSearch(Ljava/lang/String;)Ljava/net/InetAddress; 1 583 
org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount.getCombinerOutput()Ljava/util/ArrayList; 1 126 
org.apache.hadoop.yarn.webapp.view.JQueryUI.initDialogs(Ljava/util/List;)V 1 157 
org.apache.hadoop.ipc.ProtocolSignature.readFields(Ljava/io/DataInput;)V 1 76 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$CounterUpdateTransition.transition(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl;Lorg/apache/hadoop/mapreduce/v2/app/job/event/JobEvent;)V 1 1457 
org.apache.hadoop.io.EnumSetWritable.readFields(Ljava/io/DataInput;)V 1 125 
org.apache.hadoop.net.SocketIOWithTimeout.connect(Ljava/nio/channels/SocketChannel;Ljava/net/SocketAddress;I)V 1 203 
org.apache.hadoop.ipc.Client.call([Lorg/apache/hadoop/io/Writable;[Ljava/net/InetSocketAddress;Ljava/lang/Class;Lorg/apache/hadoop/security/UserGroupInformation;Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/io/Writable; 2 1137 1151 
org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader.accept(Lorg/apache/hadoop/mapreduce/lib/join/CompositeRecordReader$JoinCollector;Lorg/apache/hadoop/io/WritableComparable;)V 1 167 
org.apache.hadoop.fs.GlobExpander.expand(Ljava/lang/String;)Ljava/util/List; 1 53 
org.apache.hadoop.yarn.util.Graph.generateGraphViz(Ljava/lang/String;)Ljava/lang/String; 3 157 169 162 
org.apache.hadoop.util.bloom.DynamicBloomFilter.xor(Lorg/apache/hadoop/util/bloom/Filter;)V 1 229 
org.apache.hadoop.metrics.spi.CompositeContext.close()V 1 147 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.clean()V 2 820 817 
org.apache.hadoop.security.JniBasedUnixGroupsNetgroupMapping.cacheGroupsAdd(Ljava/util/List;)V 1 91 
org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorMapper.map(Lorg/apache/hadoop/io/WritableComparable;Lorg/apache/hadoop/io/Writable;Lorg/apache/hadoop/mapreduce/Mapper$Context;)V 2 59 55 
org.apache.hadoop.hdfs.tools.GetConf.printList(Ljava/util/List;)V 1 238 
org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop()V 3 394 399 390 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner$ReportCompiler.call()Lorg/apache/hadoop/hdfs/server/datanode/DirectoryScanner$ScanInfoPerBlockPool; 1 486 
org.apache.hadoop.mapred.ReduceTaskStatus.readFields(Ljava/io/DataInput;)V 1 145 
org.apache.hadoop.io.EnumSetWritable.write(Ljava/io/DataOutput;)V 1 145 
org.apache.hadoop.mapred.QueueManager.setQueues([Lorg/apache/hadoop/mapred/Queue;)V 1 502 
org.apache.hadoop.hdfs.tools.offlineImageViewer.NameDistributionVisitor.finish()V 3 64 62 77 
org.apache.hadoop.mapred.MultiFileSplit.toString()Ljava/lang/String; 1 74 
org.apache.hadoop.util.ReflectionUtils.printThreadInfo(Ljava/io/PrintWriter;Ljava/lang/String;)V 2 187 161 
org.apache.hadoop.mapreduce.TaskReport.write(Ljava/io/DataOutput;)V 1 200 
org.apache.hadoop.fs.viewfs.InodeTree.resolve(Ljava/lang/String;Z)Lorg/apache/hadoop/fs/viewfs/InodeTree$ResolveResult; 4 400 413 396 437 
org.apache.hadoop.http.HtmlQuoting.needsQuoting([BII)Z 1 42 
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork()V 1 363 
org.apache.hadoop.hdfs.server.datanode.DataNode.startPlugins(Lorg/apache/hadoop/conf/Configuration;)V 1 497 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(Ljava/lang/String;JJZZ)Lorg/apache/hadoop/hdfs/protocol/LocatedBlocks; 1 746 
org.apache.hadoop.io.WritableUtils.writeCompressedStringArray(Ljava/io/DataOutput;[Ljava/lang/String;)V 1 154 
org.apache.hadoop.yarn.webapp.hamlet.HamletGen.initLut(Ljava/lang/Class;)V 2 137 131 
org.apache.hadoop.util.MergeSort.mergeSort([I[III)V 3 48 47 73 
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReceived(Lorg/apache/hadoop/hdfs/server/protocol/DatanodeRegistration;Ljava/lang/String;[Lorg/apache/hadoop/hdfs/protocol/Block;[Ljava/lang/String;)V 1 801 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.stop(Lorg/apache/hadoop/yarn/server/resourcemanager/rmapp/attempt/RMAppAttemptState;)V 1 353 
org.apache.hadoop.ipc.ProtocolProxy.fetchServerMethods(Ljava/lang/reflect/Method;)V 1 82 
org.apache.hadoop.io.ArrayWritable.readFields(Ljava/io/DataInput;)V 1 93 
org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.ensureCurrentDirExists()V 1 834 
org.apache.hadoop.yarn.server.resourcemanager.webapp.AppBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 135 
org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getReaders(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/io/MapFile$Reader; 1 97 
org.apache.hadoop.mapred.pipes.BinaryProtocol$UplinkReaderThread.run()V 1 122 
org.apache.hadoop.fs.FileSystem.getUsed()J 1 2009 
org.apache.hadoop.mapreduce.lib.join.TupleWritable.readBitSet(Ljava/io/DataInput;ILjava/util/BitSet;)V 3 283 291 289 
org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner.readPartitions(Lorg/apache/hadoop/fs/FileSystem;Lorg/apache/hadoop/fs/Path;Ljava/lang/Class;Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/io/WritableComparable; 1 306 
org.apache.hadoop.hdfs.server.namenode.FileJournalManager.getRemoteEditLogs(J)Ljava/util/List; 1 143 
org.apache.hadoop.fs.FileSystem.getStatistics()Ljava/util/Map; 1 2516 
org.apache.hadoop.mapreduce.lib.chain.Chain.interruptAllThreads()V 2 533 536 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.addDirectoryToJobListCache(Lorg/apache/hadoop/fs/Path;)V 1 523 
org.apache.hadoop.util.ProgramDriver.printUsage(Ljava/util/Map;)V 1 88 
org.apache.hadoop.yarn.state.StateMachineFactory.generateStateGraph(Ljava/lang/String;)Lorg/apache/hadoop/yarn/util/Graph; 3 473 461 457 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush()V 1 1392 
org.apache.hadoop.mapreduce.v2.app.webapp.JobsBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 58 
org.apache.hadoop.mapred.join.Parser$CNode.toString()Ljava/lang/String; 1 448 
org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector.reset(Lorg/apache/hadoop/io/WritableComparable;)V 1 196 
org.apache.hadoop.mapred.join.CompositeInputSplit.getLocations()[Ljava/lang/String; 2 96 93 
org.apache.hadoop.util.AsyncDiskService.shutdown()V 1 114 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.addNewQueues(Ljava/util/Map;Ljava/util/Map;)V 1 283 
org.apache.hadoop.mapreduce.lib.partition.InputSampler$SplitSampler.getSample(Lorg/apache/hadoop/mapreduce/InputFormat;Lorg/apache/hadoop/mapreduce/Job;)[Ljava/lang/Object; 2 140 134 
org.apache.hadoop.yarn.server.api.records.impl.pb.NodeStatusPBImpl.initContainers()V 1 240 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler$1.getQueueAcls()Ljava/util/Map; 1 151 
org.apache.hadoop.io.SortedMapWritable.readFields(Ljava/io/DataInput;)V 1 175 
org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge()Lorg/apache/hadoop/io/SequenceFile$Sorter$RawKeyValueIterator; 6 3259 3257 3282 3291 3303 3249 
org.apache.hadoop.metrics.spi.CompositeContext.isMonitoring()Z 1 138 
org.apache.hadoop.io.Text.validateUTF8([BII)V 1 464 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.initBlock()V 1 774 
org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector$LogGroup.planMixedLogRecovery()V 1 368 
org.apache.hadoop.mapreduce.TypeConverter.fromYarn(Lorg/apache/hadoop/yarn/api/records/QueueInfo;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/mapreduce/QueueInfo; 1 466 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTasks(Lorg/apache/hadoop/mapreduce/v2/api/records/TaskType;)Ljava/util/Map; 1 631 
org.apache.hadoop.util.ProgramDriver.driver([Ljava/lang/String;)I 1 141 
org.apache.hadoop.record.compiler.generated.Rcc.<init>(Ljava/io/InputStream;Ljava/lang/String;)V 1 410 
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run()V 1 320 
org.apache.hadoop.mapreduce.filecache.DistributedCache.parseBooleans([Ljava/lang/String;)[Z 1 408 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.mainSimpleSort(Lorg/apache/hadoop/io/compress/bzip2/CBZip2OutputStream$Data;III)Z 6 1407 1470 1448 1429 1427 1423 
org.apache.hadoop.hdfs.server.balancer.Balancer.chooseTarget(Lorg/apache/hadoop/hdfs/server/balancer/Balancer$Source;Ljava/util/Iterator;Z)Z 1 978 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.vswap([IIII)V 1 1585 
org.apache.hadoop.io.WritableUtils.toByteArray([Lorg/apache/hadoop/io/Writable;)[B 1 419 
org.apache.hadoop.mapreduce.counters.FileSystemCounterGroup.numSetCounters([Ljava/lang/Object;)I 1 272 
org.apache.hadoop.mapred.QueueManager.getJobQueueInfoMapping()Ljava/util/Map; 1 445 
org.apache.hadoop.security.Credentials.addAll(Lorg/apache/hadoop/security/Credentials;Z)V 2 264 270 
org.apache.hadoop.io.ArrayWritable.write(Ljava/io/DataOutput;)V 1 102 
org.apache.hadoop.mapreduce.v2.hs.JobHistory.stop()V 1 142 
org.apache.hadoop.util.StringUtils.unEscapeString(Ljava/lang/String;C[C)Ljava/lang/String; 1 543 
org.apache.hadoop.security.ShellBasedUnixGroupsNetgroupMapping.getUsersForNetgroup(Ljava/lang/String;)Ljava/util/List; 1 118 
org.apache.hadoop.fs.HarFileSystem.fixBlockLocations([Lorg/apache/hadoop/fs/BlockLocation;JJJ)[Lorg/apache/hadoop/fs/BlockLocation; 1 355 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.nodeUpdate(Lorg/apache/hadoop/yarn/server/resourcemanager/rmnode/RMNode;Ljava/util/List;Ljava/util/List;)V 2 577 582 
org.apache.hadoop.fs.DF.getOSType(Ljava/lang/String;)Lorg/apache/hadoop/fs/DF$OSType; 1 71 
org.apache.hadoop.hdfs.web.WebHdfsFileSystem.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 714 
org.apache.hadoop.mapred.FileInputFormat$MultiPathFilter.accept(Lorg/apache/hadoop/fs/Path;)Z 1 94 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.newStorageID()Ljava/lang/String; 1 539 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader.readAcontainerLogs(Ljava/io/DataInputStream;Ljava/io/Writer;)V 2 494 476 
org.apache.hadoop.metrics2.impl.MetricsSystemImpl.startMetricsMBeans()V 1 301 
org.apache.hadoop.mapred.pipes.OutputHandler.waitForAuthentication()V 1 182 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue(Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacitySchedulerContext;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacitySchedulerConfiguration;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSQueue;Ljava/lang/String;Ljava/util/Map;Ljava/util/Map;Ljava/util/Comparator;Ljava/util/Comparator;Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CapacityScheduler$QueueHook;)Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/capacity/CSQueue; 1 324 
org.apache.hadoop.hdfs.DFSInputStream.read([BII)I 1 539 
org.apache.hadoop.mapreduce.v2.hs.CompletedJob.getAMInfos()Ljava/util/List; 1 412 
org.apache.hadoop.net.SocketIOWithTimeout.doIO(Ljava/nio/ByteBuffer;I)I 1 136 
org.apache.hadoop.io.BytesWritable.toString()Ljava/lang/String; 1 207 
org.apache.hadoop.mapreduce.lib.chain.Chain.getChainElementConf(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;)Lorg/apache/hadoop/conf/Configuration; 1 594 
org.apache.hadoop.hdfs.server.datanode.BPOfferService.retrieveNamespaceInfo()Lorg/apache/hadoop/hdfs/server/protocol/NamespaceInfo; 1 197 
org.apache.hadoop.mapred.Merger$MergeQueue.computeBytesInMerges(II)J 3 768 785 779 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyQuotaForRename([Lorg/apache/hadoop/hdfs/server/namenode/INode;[Lorg/apache/hadoop/hdfs/server/namenode/INode;)V 1 1757 
org.apache.hadoop.mapred.Merger$MergeQueue.getSegmentDescriptors(I)Ljava/util/List; 1 745 
org.apache.hadoop.util.PriorityQueue.clear()V 1 119 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.addBlocksToBeInvalidated(Ljava/util/List;)V 1 356 
org.apache.hadoop.hdfs.server.datanode.DataNode$BlockPoolManager$1.run()Ljava/lang/Object; 1 299 
org.apache.hadoop.mapred.Merger.writeFile(Lorg/apache/hadoop/mapred/RawKeyValueIterator;Lorg/apache/hadoop/mapred/IFile$Writer;Lorg/apache/hadoop/util/Progressable;Lorg/apache/hadoop/conf/Configuration;)V 1 199 
org.apache.hadoop.mapred.Merger$MergeQueue.close()V 1 458 
org.apache.hadoop.security.SaslRpcServer$SaslDigestCallbackHandler.handle([Ljavax/security/auth/callback/Callback;)V 1 204 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$ContainerLogsReader.nextLog()Ljava/lang/String; 1 562 
org.apache.hadoop.fs.GlobExpander.leftmostOuterCurlyContainingSlash(Ljava/lang/String;I)I 1 147 
org.apache.hadoop.mapred.StatisticsCollector.removeStat(Ljava/lang/String;)Lorg/apache/hadoop/mapred/StatisticsCollector$Stat; 1 136 
org.apache.hadoop.fs.shell.PathData.getDirectoryContents()[Lorg/apache/hadoop/fs/shell/PathData; 1 215 
org.apache.hadoop.record.meta.StructTypeID.findStruct(Ljava/lang/String;)Lorg/apache/hadoop/record/meta/StructTypeID; 1 67 
org.apache.hadoop.hdfs.server.datanode.DataNode$BlockPoolManager.shutDownAll()V 2 285 289 
org.apache.hadoop.ipc.Client$Connection$PingInputStream.read([BII)I 1 369 
org.apache.hadoop.hdfs.BlockReaderLocal.readIntoBuffer(Ljava/io/FileInputStream;Ljava/nio/ByteBuffer;)I 1 315 
org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.stopAggregators()V 4 146 150 149 162 
org.apache.hadoop.util.ProtoUtil.readRawVarint32(Ljava/io/DataInput;)I 1 53 
org.apache.hadoop.mapreduce.lib.join.Parser.parse(Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/mapreduce/lib/join/Parser$Node; 1 549 
org.apache.hadoop.mapreduce.lib.db.TextSplitter.split(ILjava/lang/String;Ljava/lang/String;Ljava/lang/String;)Ljava/util/List; 1 154 
org.apache.hadoop.mapred.StatisticsCollector.createStat(Ljava/lang/String;[Lorg/apache/hadoop/mapred/StatisticsCollector$TimeWindow;)Lorg/apache/hadoop/mapred/StatisticsCollector$Stat; 1 113 
org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(Ljava/lang/String;)Ljava/util/List; 1 94 
org.apache.hadoop.yarn.logaggregation.LogDumper.dumpAllContainersLogs(Lorg/apache/hadoop/yarn/api/records/ApplicationId;Ljava/lang/String;Ljava/io/DataOutputStream;)I 3 221 218 207 
org.apache.hadoop.hdfs.tools.GetConf$NNRpcAddressesCommandHandler.doWorkInternal(Lorg/apache/hadoop/hdfs/tools/GetConf;)I 1 205 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.decContainerReq(Lorg/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor$ContainerRequest;)V 2 284 288 
org.apache.hadoop.metrics2.impl.MBeanInfoBuilder.get()Ljavax/management/MBeanInfo; 3 100 104 99 
org.apache.hadoop.fs.s3.S3FileSystem.listStatus(Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 191 
org.apache.hadoop.fs.BlockLocation.toString()Ljava/lang/String; 1 286 
org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorMapper.map(Lorg/apache/hadoop/io/WritableComparable;Lorg/apache/hadoop/io/Writable;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 2 54 50 
org.apache.hadoop.mapreduce.lib.db.DBRecordReader.getSelectQuery()Ljava/lang/String; 1 120 
org.apache.hadoop.mapreduce.util.LinuxResourceCalculatorPlugin.readProcMemInfoFile(Z)V 1 168 
org.apache.hadoop.metrics2.lib.UniqueNames.uniqueName(Ljava/lang/String;)Ljava/lang/String; 1 56 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(Lorg/apache/hadoop/mapreduce/JobContext;)Ljava/util/List; 2 281 270 
org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.createReduceTasks(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/JobImpl;)V 1 1087 
org.apache.hadoop.util.RunJar.main([Ljava/lang/String;)V 1 192 
org.apache.hadoop.security.authorize.ServiceAuthorizationManager.refresh(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/security/authorize/PolicyProvider;)V 1 130 
org.apache.hadoop.fs.DU$DURefreshThread.run()V 1 81 
org.apache.hadoop.mapreduce.Job.shouldDownloadProfile()Z 2 1347 1339 
org.apache.hadoop.mapreduce.v2.app.MRAppMaster.start()V 1 837 
org.apache.hadoop.mapreduce.lib.join.Parser.reduce(Ljava/util/Stack;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/mapreduce/lib/join/Parser$Token; 1 521 
org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(Ljava/nio/channels/SelectableChannel;IJ)I 1 332 
org.apache.hadoop.fs.FsShell.displayError(Ljava/lang/String;Ljava/lang/String;)V 1 271 
org.apache.hadoop.mapreduce.task.reduce.MergeThread.waitForMerge()V 1 73 
org.apache.hadoop.io.TwoDArrayWritable.write(Ljava/io/DataOutput;)V 3 86 90 89 
org.apache.hadoop.mapred.lib.Chain.close()V 1 282 
org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.isValid(Lorg/apache/hadoop/hdfs/server/datanode/FSDatasetInterface;Lorg/apache/hadoop/hdfs/server/datanode/FSDatasetInterface$FSVolumeInterface;)Z 1 416 
org.apache.hadoop.hdfs.server.datanode.DataNode.transferBlocks(Ljava/lang/String;[Lorg/apache/hadoop/hdfs/protocol/Block;[[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)V 1 1299 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.containerFailedOnHost(Ljava/lang/String;)V 2 229 224 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.setChildQueues(Ljava/util/Collection;)V 1 201 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(Lorg/apache/hadoop/yarn/server/nodemanager/containermanager/container/Container;Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/Path;Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/fs/Path;Ljava/util/List;Ljava/util/List;)I 1 120 
org.apache.hadoop.io.SequenceFile$Reader.sync(J)V 2 2533 2531 
org.apache.hadoop.mapred.lib.NLineInputFormat.getSplits(Lorg/apache/hadoop/mapred/JobConf;I)[Lorg/apache/hadoop/mapred/InputSplit; 2 82 80 
org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.initServiceResponse()V 1 100 
org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKStore$ZKRMState.load()V 2 465 498 
org.apache.hadoop.security.Credentials.write(Ljava/io/DataOutput;)V 2 201 208 
org.apache.hadoop.fs.viewfs.ViewFileSystem.getChildFileSystems()[Lorg/apache/hadoop/fs/FileSystem; 1 537 
org.apache.hadoop.hdfs.server.datanode.DataBlockScanner.run()V 1 67 
org.apache.hadoop.mapreduce.task.reduce.EventFetcher.getMapCompletionEvents()I 1 148 
org.apache.hadoop.mapreduce.v2.app.webapp.SingleCounterBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 82 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.assignContainers(Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/SchedulerNode;)V 3 353 347 380 
org.apache.hadoop.yarn.util.VisualizeStateMachine.main([Ljava/lang/String;)V 1 64 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.handleHeartbeat(Lorg/apache/hadoop/hdfs/server/protocol/DatanodeRegistration;Ljava/lang/String;JJJJIII)[Lorg/apache/hadoop/hdfs/server/protocol/DatanodeCommand; 1 886 
org.apache.hadoop.mapred.CleanupQueue$PathCleanupThread.run()V 1 130 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSDir.recoverTempUnlinkedBlock()V 1 192 
org.apache.hadoop.hdfs.server.datanode.FSDataset$FSVolume.getVolumeMap(Lorg/apache/hadoop/hdfs/server/datanode/ReplicasMap;)V 1 667 
org.apache.hadoop.fs.shell.CommandFormat.getOpts()Ljava/util/Set; 1 132 
org.apache.hadoop.mapreduce.security.token.JobTokenSelector.selectToken(Lorg/apache/hadoop/io/Text;Ljava/util/Collection;)Lorg/apache/hadoop/security/token/Token; 1 45 
org.apache.hadoop.mapred.JobClient.getJobQueueInfo(Lorg/apache/hadoop/mapreduce/QueueInfo;)Lorg/apache/hadoop/mapred/JobQueueInfo; 1 1038 
org.apache.hadoop.fs.Options$CreateOpts.getOpt(Ljava/lang/Class;[Lorg/apache/hadoop/fs/Options$CreateOpts;)Lorg/apache/hadoop/fs/Options$CreateOpts; 1 164 
org.apache.hadoop.fs.Options$CreateOpts.setOpt(Lorg/apache/hadoop/fs/Options$CreateOpts;[Lorg/apache/hadoop/fs/Options$CreateOpts;)[Lorg/apache/hadoop/fs/Options$CreateOpts; 1 183 
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTreeDump()Ljava/lang/String; 1 265 
org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.clear()V 1 243 
org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogReader.getApplicationOwner()Ljava/lang/String; 1 310 
org.apache.hadoop.hdfs.server.blockmanagement.Host2NodesMap.getDatanodeByName(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 184 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill()V 3 1544 1556 1535 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts()V 6 1747 1766 1788 1815 1811 1867 
org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineCacheVisibilities(Lorg/apache/hadoop/conf/Configuration;)V 2 132 142 
org.apache.hadoop.mapreduce.TypeConverter.fromYarnQueueUserAclsInfo(Ljava/util/List;)[Lorg/apache/hadoop/mapreduce/QueueAclsInfo; 2 488 486 
org.apache.hadoop.mapred.LocalDistributedCacheManager.close()V 3 242 249 252 
org.apache.hadoop.conf.Configuration$DeprecatedKeyInfo.getWarningMessage(Ljava/lang/String;)Ljava/lang/String; 1 261 
org.apache.hadoop.mapred.join.Parser$CNode.getRecordReader(Lorg/apache/hadoop/mapred/InputSplit;Lorg/apache/hadoop/mapred/JobConf;Lorg/apache/hadoop/mapred/Reporter;)Lorg/apache/hadoop/mapred/join/ComposableRecordReader; 1 424 
org.apache.hadoop.hdfs.server.datanode.FSDatasetAsyncDiskService.shutdown()V 1 136 
org.apache.hadoop.fs.shell.CommandFactory.addClass(Ljava/lang/Class;[Ljava/lang/String;)V 1 82 
org.apache.hadoop.mapreduce.TypeConverter.fromYarn(Ljava/util/List;)Ljava/util/List; 1 375 
org.apache.hadoop.mapred.LocalJobRunner$Job.initCounters(I)V 1 276 
org.apache.hadoop.util.bloom.DynamicBloomFilter.write(Ljava/io/DataOutput;)V 1 253 
org.apache.hadoop.hdfs.server.datanode.DataNode$BlockPoolManager.<init>(Lorg/apache/hadoop/hdfs/server/datanode/DataNode;Lorg/apache/hadoop/conf/Configuration;)V 1 241 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.numericalCompare([BII[BII)I 5 166 172 181 206 213 
org.apache.hadoop.http.HtmlQuoting.main([Ljava/lang/String;)V 1 198 
org.apache.hadoop.fs.s3.S3FileSystem$S3FileStatus.findLength(Lorg/apache/hadoop/fs/s3/INode;)J 1 360 
org.apache.hadoop.mapred.join.CompositeRecordReader.createKey()Lorg/apache/hadoop/io/WritableComparable; 1 412 
org.apache.hadoop.mapred.join.OverrideRecordReader.fillJoinCollector(Lorg/apache/hadoop/io/WritableComparable;)V 3 74 85 89 
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.run()Z 4 473 500 428 558 
org.apache.hadoop.mapred.ClusterStatus.getBlacklistedTrackerNames()Ljava/util/Collection; 1 311 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer$AnalyzedJob.<init>(Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$JobInfo;)V 2 719 716 
org.apache.hadoop.hdfs.tools.DFSAdmin.setSafeMode([Ljava/lang/String;I)V 1 389 
org.apache.hadoop.metrics2.impl.SinkQueue.clear()V 1 157 
org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.<init>(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/hdfs/server/namenode/NameNode;Lorg/apache/hadoop/net/NetworkTopology;Ljava/util/Map;Ljava/io/PrintWriter;ISLjava/net/InetAddress;)V 1 146 
org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(Ljava/lang/Object;Ljava/lang/reflect/Method;[Ljava/lang/Object;)Ljava/lang/Object; 1 67 
org.apache.hadoop.yarn.webapp.view.DefaultPage.render()V 4 35 39 50 57 
org.apache.hadoop.mapred.StatisticsCollector.update()V 1 89 
org.apache.hadoop.mapred.join.CompositeRecordReader$JoinCollector.replay(Lorg/apache/hadoop/mapred/join/TupleWritable;)Z 1 278 
org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.getProxyAddresses()Ljava/util/Set; 1 66 
org.apache.hadoop.tools.GetGroupsBase.run([Ljava/lang/String;)I 2 71 68 
org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.hashCode()I 1 102 
org.apache.hadoop.security.token.Token.getRenewer()Lorg/apache/hadoop/security/token/TokenRenewer; 1 285 
org.apache.hadoop.fs.BlockLocation.write(Ljava/io/DataOutput;)V 3 230 235 240 
org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor.run()V 2 257 248 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.createContainerLaunchContext(Ljava/util/Map;Lorg/apache/hadoop/yarn/api/records/ContainerId;Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/security/token/Token;Lorg/apache/hadoop/mapred/Task;Lorg/apache/hadoop/mapred/JobID;Lorg/apache/hadoop/yarn/api/records/Resource;Lorg/apache/hadoop/mapred/WrappedJvmID;Lorg/apache/hadoop/mapreduce/v2/app/TaskAttemptListener;Lorg/apache/hadoop/security/Credentials;)Lorg/apache/hadoop/yarn/api/records/ContainerLaunchContext; 1 737 
org.apache.hadoop.fs.FileSystem$Cache.closeAll(Lorg/apache/hadoop/security/UserGroupInformation;)V 2 2307 2316 
org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.isReplicationInProgress(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)Z 1 2336 
org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.createTupleWritable()Lorg/apache/hadoop/mapreduce/lib/join/TupleWritable; 1 460 
org.apache.hadoop.util.bloom.CountingBloomFilter.or(Lorg/apache/hadoop/util/bloom/Filter;)V 1 258 
org.apache.hadoop.hdfs.server.namenode.Checkpointer.run()V 1 137 
org.apache.hadoop.fs.FSInputChecker.readChecksumChunk([BII)I 1 270 
org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processDelegationTokens(Ljava/io/DataInputStream;Lorg/apache/hadoop/hdfs/tools/offlineImageViewer/ImageVisitor;)V 2 211 221 
org.apache.hadoop.ipc.Server$Handler.run()V 1 1502 
org.apache.hadoop.metrics.spi.AbstractMetricsContext.getAttributeTable(Ljava/lang/String;)Ljava/util/Map; 1 142 
org.apache.hadoop.mapreduce.v2.hs.CompletedJob.constructTaskAttemptCompletionEvents()V 3 195 193 227 
org.apache.hadoop.mapreduce.lib.join.Parser$CNode.parse(Ljava/util/List;Lorg/apache/hadoop/conf/Configuration;)V 1 497 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getQueueUserAclInfo(Lorg/apache/hadoop/security/UserGroupInformation;)Ljava/util/List; 1 341 
org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase.getAggregatorDescriptors(Lorg/apache/hadoop/conf/Configuration;)Ljava/util/ArrayList; 1 68 
org.apache.hadoop.ipc.WritableRpcEngine$Invocation.readFields(Ljava/io/DataInput;)V 1 128 
org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager$Monitor.check()V 1 87 
org.apache.hadoop.fs.LocalFileSystem.reportChecksumFailure(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/FSDataInputStream;JLorg/apache/hadoop/fs/FSDataInputStream;J)Z 1 94 
org.apache.hadoop.mapred.join.Parser$CNode.parse(Ljava/util/List;Lorg/apache/hadoop/mapred/JobConf;)V 1 435 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.refreshDatanodes()V 1 689 
org.apache.hadoop.util.PriorityQueue.upHeap()V 1 128 
org.apache.hadoop.hdfs.server.namenode.FSEditLog.setOutputBufferCapacity(I)V 1 946 
org.apache.hadoop.metrics.ganglia.GangliaContext.pad()V 1 241 
org.apache.hadoop.fs.shell.Ls.adjustColumnWidths([Lorg/apache/hadoop/fs/shell/PathData;)V 1 126 
org.apache.hadoop.fs.shell.Command.processPaths(Lorg/apache/hadoop/fs/shell/PathData;[Lorg/apache/hadoop/fs/shell/PathData;)V 1 308 
org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.addDirsToCheck(Ljava/util/Collection;)V 1 85 
org.apache.hadoop.hdfs.server.namenode.FSNamesystem.concat(Ljava/lang/String;[Ljava/lang/String;)V 1 815 
org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(Lorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$StartupOption;)Z 1 245 
org.apache.hadoop.mapreduce.lib.join.Parser$CNode.setKeyComparator(Ljava/lang/Class;)V 1 424 
org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.<init>([Lorg/apache/hadoop/fs/Path;[J)V 2 67 71 
org.apache.hadoop.mapred.MultiFileSplit.addToSet(Ljava/util/Set;[Ljava/lang/String;)V 1 67 
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl$AttemptSucceededTransition.transition(Lorg/apache/hadoop/mapreduce/v2/app/job/impl/TaskImpl;Lorg/apache/hadoop/mapreduce/v2/app/job/event/TaskEvent;)V 1 770 
org.apache.hadoop.mapreduce.util.LinuxResourceCalculatorPlugin.readProcStatFile()V 1 273 
org.apache.hadoop.record.compiler.generated.RccTokenManager.jjCheckNAddStates(II)V 1 68 
org.apache.hadoop.mapred.lib.LongSumReducer.reduce(Ljava/lang/Object;Ljava/util/Iterator;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 48 
org.apache.hadoop.security.authorize.ProxyUsers.authorize(Lorg/apache/hadoop/security/UserGroupInformation;Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)V 2 132 151 
org.apache.hadoop.conf.Configuration.write(Ljava/io/DataOutput;)V 1 2195 
org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.close()V 1 3173 
org.apache.hadoop.mapred.TaskLog.addCommand(Ljava/util/List;Z)Ljava/lang/String; 1 599 
org.apache.hadoop.mapred.LocalJobRunner$Job.getMapTaskRunnables([Lorg/apache/hadoop/mapreduce/split/JobSplit$TaskSplitMetaInfo;Lorg/apache/hadoop/mapred/JobID;Ljava/util/Map;)Ljava/util/List; 1 259 
org.apache.hadoop.yarn.util.Graph.getNode(Ljava/lang/String;)Lorg/apache/hadoop/yarn/util/Graph$Node; 1 117 
org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.registerDelegationTokensForRenewal(Lorg/apache/hadoop/mapreduce/JobID;Lorg/apache/hadoop/security/Credentials;Lorg/apache/hadoop/conf/Configuration;)V 1 191 
org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat$MultiPathFilter.accept(Lorg/apache/hadoop/fs/Path;)Z 1 678 
org.apache.hadoop.fs.FileContext$Util.getFileStatus([Lorg/apache/hadoop/fs/Path;)[Lorg/apache/hadoop/fs/FileStatus; 1 1545 
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.listSubPaths(Lorg/apache/hadoop/fs/Path;)Ljava/util/Set; 1 260 
org.apache.hadoop.mapreduce.TypeConverter.fromYarnApps(Ljava/util/List;Lorg/apache/hadoop/conf/Configuration;)[Lorg/apache/hadoop/mapreduce/JobStatus; 1 445 
org.apache.hadoop.mapreduce.v2.app.webapp.ConfBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 2 91 85 
org.apache.hadoop.util.Progress.addPhase(F)Lorg/apache/hadoop/util/Progress; 1 97 
org.apache.hadoop.yarn.server.nodemanager.webapp.ApplicationPage$ApplicationBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 89 
org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.get(Ljava/nio/channels/SelectableChannel;)Lorg/apache/hadoop/net/SocketIOWithTimeout$SelectorPool$SelectorInfo; 1 394 
org.apache.hadoop.ipc.RemoteException.unwrapRemoteException([Ljava/lang/Class;)Ljava/io/IOException; 1 53 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.verifyBlockPlacement(Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/LocatedBlock;I)I 1 545 
org.apache.hadoop.fs.FileContext$Util$2.hasNext()Z 1 1769 
org.apache.hadoop.hdfs.server.blockmanagement.PendingReplicationBlocks$PendingReplicationMonitor.run()V 1 188 
org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelayedTokenRemovalRunnable.run()V 3 459 465 455 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(ILorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;Ljava/util/List;ZLjava/util/HashMap;J)[Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 1 136 
org.apache.hadoop.hdfs.server.datanode.DataNode.checkWriteAccess(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;)V 1 2068 
org.apache.hadoop.fs.s3.Jets3tFileSystemStore.listDeepSubPaths(Lorg/apache/hadoop/fs/Path;)Ljava/util/Set; 1 281 
org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData()V 3 1025 1053 1049 
org.apache.hadoop.io.compress.CompressionCodecFactory.setCodecClasses(Lorg/apache/hadoop/conf/Configuration;Ljava/util/List;)V 1 144 
org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat.addUserIdentifiers(Lorg/apache/hadoop/conf/Configuration;)V 1 107 
org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.createContainerLogDirs(Ljava/lang/String;Ljava/lang/String;Ljava/util/List;)V 1 463 
org.apache.hadoop.mapreduce.lib.join.TupleWritable.toString()Ljava/lang/String; 1 151 
org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(Ljava/lang/String;Ljava/lang/String;Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)Lorg/apache/hadoop/hdfs/protocol/LocatedBlock; 1 386 
org.apache.hadoop.util.StringUtils.hexStringToByte(Ljava/lang/String;)[B 1 183 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration.getAcls(Ljava/lang/String;)Ljava/util/Map; 1 250 
org.apache.hadoop.hdfs.DFSOutputStream.completeFile(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;)V 1 1670 
org.apache.hadoop.yarn.logaggregation.LogDumper.dumpAContainerLogs(Ljava/lang/String;Lorg/apache/hadoop/yarn/logaggregation/AggregatedLogFormat$LogReader;Ljava/io/DataOutputStream;)I 2 163 177 
org.apache.hadoop.util.hash.MurmurHash.hash([BII)I 1 48 
org.apache.hadoop.fs.shell.Tail.processPath(Lorg/apache/hadoop/fs/shell/PathData;)V 1 74 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.getFilteredContainerRequest(Lorg/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor$ContainerRequest;)Lorg/apache/hadoop/mapreduce/v2/app/rm/RMContainerRequestor$ContainerRequest; 1 393 
org.apache.hadoop.util.bloom.Filter.add(Ljava/util/List;)V 1 163 
org.apache.hadoop.hdfs.server.protocol.BlockCommand.write(Ljava/io/DataOutput;)V 3 111 117 115 
org.apache.hadoop.record.compiler.generated.Rcc.<init>(Ljava/io/Reader;)V 1 431 
org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader.getSelectQuery()Ljava/lang/String; 1 98 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.addFalsePositive([Lorg/apache/hadoop/util/bloom/Key;)V 1 189 
org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(Lorg/apache/hadoop/metrics2/MetricsRecord;)V 2 140 170 
org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run()V 1 133 
org.apache.hadoop.mapreduce.JobStatus.write(Ljava/io/DataOutput;)V 1 444 
org.apache.hadoop.hdfs.tools.DFSck.listCorruptFileBlocks(Ljava/lang/String;Ljava/lang/String;)Ljava/lang/Integer; 2 164 151 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedAddFile(Ljava/lang/String;Lorg/apache/hadoop/fs/permission/PermissionStatus;[Lorg/apache/hadoop/hdfs/server/blockmanagement/BlockInfo;SJJJLjava/lang/String;Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/namenode/INode; 1 321 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanDirectory(Lorg/apache/hadoop/fs/Path;Lorg/apache/hadoop/fs/FileContext;Lorg/apache/hadoop/fs/PathFilter;)Ljava/util/List; 1 545 
org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getBlockIndex([Lorg/apache/hadoop/fs/BlockLocation;J)I 1 314 
org.apache.hadoop.hdfs.tools.offlineImageViewer.DelimitedImageVisitor.writeLine()V 1 122 
org.apache.hadoop.yarn.server.api.records.impl.pb.HeartbeatResponsePBImpl.initContainersToCleanup()V 1 172 
org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetTaskAttemptCompletionEventsResponsePBImpl.initCompletionEvents()V 1 106 
org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getQueueInfo(Lorg/apache/hadoop/yarn/api/protocolrecords/GetQueueInfoRequest;)Lorg/apache/hadoop/yarn/api/protocolrecords/GetQueueInfoResponse; 1 391 
org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorReducer.reduce(Lorg/apache/hadoop/io/Text;Ljava/util/Iterator;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 60 
org.apache.hadoop.hdfs.server.datanode.DataNode.transferBlock(Lorg/apache/hadoop/hdfs/protocol/ExtendedBlock;[Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo;)V 1 1284 
org.apache.hadoop.mapred.lib.MultipleOutputFormat$1.close(Lorg/apache/hadoop/mapred/Reporter;)V 1 112 
org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.getBlockArray(Ljava/util/Collection;I)[Lorg/apache/hadoop/hdfs/protocol/Block; 1 413 
org.apache.hadoop.record.meta.StructTypeID.genericReadTypeID(Lorg/apache/hadoop/record/RecordInput;Ljava/lang/String;)Lorg/apache/hadoop/record/meta/TypeID; 1 142 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.getChildQueuesToPrint()Ljava/lang/String; 1 643 
org.apache.hadoop.fs.HarFileSystem.getPathInHar(Lorg/apache/hadoop/fs/Path;)Lorg/apache/hadoop/fs/Path; 1 287 
org.apache.hadoop.mapred.Merger$MergeQueue.<init>(Lorg/apache/hadoop/conf/Configuration;Lorg/apache/hadoop/fs/FileSystem;[Lorg/apache/hadoop/fs/Path;ZLorg/apache/hadoop/io/compress/CompressionCodec;Lorg/apache/hadoop/io/RawComparator;Lorg/apache/hadoop/util/Progressable;Lorg/apache/hadoop/mapred/Counters$Counter;)V 1 418 
org.apache.hadoop.io.MD5Hash.digest(Ljava/io/InputStream;)Lorg/apache/hadoop/io/MD5Hash; 1 111 
org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.write(Ljava/io/DataOutput;)V 1 58 
org.apache.hadoop.yarn.server.resourcemanager.webapp.NodesPage$NodesBlock.render(Lorg/apache/hadoop/yarn/webapp/view/HtmlBlock$Block;)V 1 97 
org.apache.hadoop.mapred.JobQueueInfo.setChildren(Ljava/util/List;)V 1 97 
org.apache.hadoop.security.authorize.ProxyUsers.refreshSuperUserGroupsConfiguration(Lorg/apache/hadoop/conf/Configuration;)V 2 68 76 
org.apache.hadoop.io.compress.bzip2.CBZip2OutputStream.randomiseBlock()V 2 1900 1905 
org.apache.hadoop.hdfs.server.protocol.RemoteEditLogManifest.readFields(Ljava/io/DataInput;)V 1 92 
org.apache.hadoop.mapred.ClientServiceDelegate.invoke(Ljava/lang/String;Ljava/lang/Class;Ljava/lang/Object;)Ljava/lang/Object; 1 296 
org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.initExisting()V 1 474 
org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$ConcatDeleteOp.writeFields(Ljava/io/DataOutputStream;)V 1 403 
org.apache.hadoop.util.bloom.BloomFilter.membershipTest(Lorg/apache/hadoop/util/bloom/Key;)Z 1 150 
org.apache.hadoop.hdfs.server.blockmanagement.UnderReplicatedBlocks.clear()V 1 97 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.minimumFnRemove([I)I 1 254 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.maximumFpRemove([I)I 1 276 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.sourceName(Ljava/lang/String;)Ljava/lang/StringBuilder; 1 110 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.ratioRemove([I)I 1 299 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.clearBit(I)V 2 323 332 
org.apache.hadoop.hdfs.RemoteBlockReader2.readChannelFully(Ljava/nio/channels/ReadableByteChannel;Ljava/nio/ByteBuffer;)V 1 207 
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo.findDatanode(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)I 1 204 
org.apache.hadoop.yarn.server.security.ApplicationACLsManager.addApplication(Lorg/apache/hadoop/yarn/api/records/ApplicationId;Ljava/util/Map;)V 1 62 
org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo.numNodes()I 1 154 
org.apache.hadoop.hdfs.tools.HDFSConcat.main([Ljava/lang/String;)V 1 50 
org.apache.hadoop.mapred.lib.MultithreadedMapRunner.run(Lorg/apache/hadoop/mapred/RecordReader;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 2 144 168 
org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.sendContainerAskToRM(Ljava/util/List;)Lorg/apache/hadoop/yarn/api/records/AMResponse; 2 827 830 
org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$1.run()V 1 274 
org.apache.hadoop.hdfs.server.namenode.FSDirectory.updateCountForINodeWithQuota(Lorg/apache/hadoop/hdfs/server/namenode/INodeDirectory;Lorg/apache/hadoop/hdfs/server/namenode/INode$DirCounts;Ljava/util/ArrayList;)V 2 1944 1966 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.decimalCompare([BII[BII)I 1 244 
org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.addJobCollection(Ljava/util/Collection;)V 1 155 
org.apache.hadoop.mapreduce.lib.partition.KeyFieldHelper.parseOption(Ljava/lang/String;)V 2 165 185 
org.apache.hadoop.io.file.tfile.BCFile$MetaIndex.write(Ljava/io/DataOutput;)V 1 789 
org.apache.hadoop.mapreduce.split.JobSplit$SplitMetaInfo.readFields(Ljava/io/DataInput;)V 1 115 
org.apache.hadoop.fs.FsShell$Help.processRawArguments(Ljava/util/LinkedList;)V 1 148 
org.apache.hadoop.mapred.QueueManager.dumpConfiguration(Lorg/codehaus/jackson/JsonGenerator;Ljava/util/Set;)V 2 684 655 
org.apache.hadoop.hdfs.server.namenode.Checkpointer.doCheckpoint()V 1 236 
org.apache.hadoop.fs.FSInputChecker.verifySums([BII)V 1 312 
org.apache.hadoop.hdfs.DFSInputStream.blockSeekTo(J)Lorg/apache/hadoop/hdfs/protocol/DatanodeInfo; 1 398 
org.apache.hadoop.mapred.pipes.BinaryProtocol.setJobConf(Lorg/apache/hadoop/mapred/JobConf;)V 2 284 289 
org.apache.hadoop.record.CsvRecordInput.readField(Ljava/lang/String;)Ljava/lang/String; 1 61 
org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl.getApplicationResourceUsageReport()Lorg/apache/hadoop/yarn/api/records/ApplicationResourceUsageReport; 2 510 516 
org.apache.hadoop.fs.viewfs.ViewFileSystem.getMountPoints()[Lorg/apache/hadoop/fs/viewfs/ViewFileSystem$MountPoint; 1 549 
org.apache.hadoop.hdfs.server.datanode.DataNode.getDNRegistrationByMachineName(Ljava/lang/String;)Lorg/apache/hadoop/hdfs/server/protocol/DatanodeRegistration; 1 935 
org.apache.hadoop.hdfs.server.namenode.NNStorage.determineClusterId()Ljava/lang/String; 1 940 
org.apache.hadoop.util.ShutdownHookManager.getShutdownHooksInOrder()Ljava/util/List; 1 133 
org.apache.hadoop.mapred.IndexCache.getIndexInformation(Ljava/lang/String;ILorg/apache/hadoop/fs/Path;Ljava/lang/String;)Lorg/apache/hadoop/mapred/IndexRecord; 1 71 
org.apache.hadoop.fs.AbstractFileSystem.getAllStatistics()Ljava/util/Map; 1 207 
org.apache.hadoop.io.MD5Hash.halfDigest()J 1 140 
org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry.getValue(Lorg/apache/hadoop/io/BytesWritable;)J 1 1706 
org.apache.hadoop.mapreduce.counters.AbstractCounters.countCounters()I 1 247 
org.apache.hadoop.hdfs.protocol.LayoutVersion.getString()Ljava/lang/String; 2 192 199 
org.apache.hadoop.metrics.spi.CompositeContext$MetricsRecordDelegator.<init>(Ljava/lang/String;Ljava/util/ArrayList;)V 1 184 
org.apache.hadoop.hdfs.LeaseRenewer.clientsRunning()Z 1 233 
org.apache.hadoop.yarn.server.api.records.impl.pb.HeartbeatResponsePBImpl.initApplicationsToCleanup()V 1 257 
org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.getSegmentDescriptors(I)[Lorg/apache/hadoop/io/SequenceFile$Sorter$SegmentDescriptor; 1 3362 
org.apache.hadoop.mapred.IFile$Reader.readData([BII)I 1 381 
org.apache.hadoop.fs.kfs.KosmosFileSystem.delete(Lorg/apache/hadoop/fs/Path;Z)Z 1 252 
org.apache.hadoop.util.bloom.RetouchedBloomFilter.createVector()V 1 398 
org.apache.hadoop.util.PriorityQueue.downHeap()V 1 144 
org.apache.hadoop.mapred.lib.RegexMapper.map(Ljava/lang/Object;Lorg/apache/hadoop/io/Text;Lorg/apache/hadoop/mapred/OutputCollector;Lorg/apache/hadoop/mapred/Reporter;)V 1 60 
org.apache.hadoop.yarn.webapp.hamlet.HamletImpl.indent(Ljava/util/EnumSet;)V 1 284 
org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.readFields(Ljava/io/DataInput;)V 3 145 150 155 
org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.getVolumesLowOnSpace()Ljava/util/Collection; 1 118 
org.apache.hadoop.hdfs.server.namenode.NNStorage.format(Ljava/lang/String;)V 1 524 
org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImageInAllDirs(J)V 1 837 
org.apache.hadoop.mapred.TaskLog.syncLogs(Ljava/lang/String;Lorg/apache/hadoop/mapred/TaskAttemptID;Z)V 2 257 254 
org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(Lorg/apache/hadoop/hdfs/server/common/HdfsServerConstants$StartupOption;Ljava/util/Map;)Z 1 291 
org.apache.hadoop.mapreduce.task.reduce.Fetcher.run()V 1 144 
org.apache.hadoop.hdfs.server.namenode.FSImage.doUpgrade()V 3 338 357 391 
org.apache.hadoop.hdfs.server.namenode.FSImage.doRollback()V 2 428 458 
org.apache.hadoop.hdfs.server.namenode.NNStorage.attemptRestoreRemovedStorage()V 1 225 
org.apache.hadoop.hdfs.server.common.Storage.writeAll()V 1 880 
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.allocate(Lorg/apache/hadoop/yarn/api/records/ApplicationAttemptId;Ljava/util/List;Ljava/util/List;)Lorg/apache/hadoop/yarn/server/resourcemanager/scheduler/Allocation; 1 467 
org.apache.hadoop.hdfs.server.namenode.NNStorage.writeTransactionIdFileToStorage(J)V 1 460 
org.apache.hadoop.mapred.MapTask$TrackedRecordReader.getInputBytes(Ljava/util/List;)J 1 216 
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.getPipeline(Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;[Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor;)[Lorg/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor; 2 511 507 
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$AssignedRequests.preemptReduce(I)V 1 1018 
org.apache.hadoop.fs.shell.SetReplication.waitForReplication()V 3 108 102 96 
org.apache.hadoop.yarn.util.FSDownload.call()Lorg/apache/hadoop/fs/Path; 1 143 
org.apache.hadoop.hdfs.HftpFileSystem.getEncodedUgiParameter()Ljava/lang/String; 1 291 
org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getCumulativeVmem(I)J 1 310 
org.apache.hadoop.mapred.TaskLog.buildDebugScriptCommandLine(Ljava/util/List;Ljava/lang/String;)Ljava/lang/String; 1 570 
org.apache.hadoop.io.DefaultStringifier.loadArray(Lorg/apache/hadoop/conf/Configuration;Ljava/lang/String;Ljava/lang/Class;)[Ljava/lang/Object; 1 191 
org.apache.hadoop.mapreduce.TypeConverter.fromYarn(Lorg/apache/hadoop/mapreduce/v2/api/records/Counters;)Lorg/apache/hadoop/mapreduce/Counters; 2 228 226 
org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler$LogDeleterRunnable.run()V 1 156 
org.apache.hadoop.mapred.lib.MultipleOutputFormat.getInputFileBasedOutputFileName(Lorg/apache/hadoop/mapred/JobConf;Ljava/lang/String;)Ljava/lang/String; 1 207 
org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.checkAndSkipBytesUntilNull()Z 1 529 
org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.printAnalysis([Lorg/apache/hadoop/mapreduce/jobhistory/JobHistoryParser$TaskAttemptInfo;Ljava/util/Comparator;Ljava/lang/String;JI)V 1 344 
org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.trimIdleSelectors(J)V 2 446 442 
